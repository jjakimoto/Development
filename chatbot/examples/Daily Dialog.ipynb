{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dialogs(path=\"../../datasets/ijcnlp_dailydialog/dialogues_text.txt\"):\n",
    "    dialogs = []\n",
    "    file = open(path, \"r\")\n",
    "    text = file.read()\n",
    "    # Text finishes with '\\n' and we do not need the last element\n",
    "    for sentence in text.split(\"\\n\")[:-1]:\n",
    "        # sentence finishes with '__eou__' and we do not need the last element\n",
    "        dialogs.append(sentence.split(\"__eou__\")[:-1])\n",
    "    return dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs = make_dialogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The kitchen stinks . ', \" I'll throw out the garbage . \"],\n",
       " ['So Dick , how about getting some coffee for tonight ? ',\n",
       "  ' Coffee ? I don ’ t honestly like that kind of stuff . ',\n",
       "  ' Come on , you can at least try a little , besides your cigarette . ',\n",
       "  ' What ’ s wrong with that ? Cigarette is the thing I go crazy for . ',\n",
       "  ' Not for me , Dick . '],\n",
       " ['Are things still going badly with your houseguest ? ',\n",
       "  ' Getting worse . Now he ’ s eating me out of house and home . I ’ Ve tried talking to him but it all goes in one ear and out the other . He makes himself at home , which is fine . But what really gets me is that yesterday he walked into the living room in the raw and I had company over ! That was the last straw . ',\n",
       "  ' Leo , I really think you ’ re beating around the bush with this guy . I know he used to be your best friend in college , but I really think it ’ s time to lay down the law . ',\n",
       "  ' You ’ re right . Everything is probably going to come to a head tonight . I ’ ll keep you informed . '],\n",
       " ['Would you mind waiting a while ? ',\n",
       "  ' Well , how long will it be ? ',\n",
       "  \" I'm not sure . But I'll get a table ready as fast as I can . \",\n",
       "  \" OK . We'll wait . \"],\n",
       " ['Are you going to the annual party ? I can give you a ride if you need one . ',\n",
       "  \" Thanks a lot . That's the favor I was going to ask you for . \",\n",
       "  ' The pleasure is mine . '],\n",
       " ['Isn ’ t he the best instructor ? I think he ’ s so hot . Wow ! I really feel energized , don ’ t you ? ',\n",
       "  ' I swear , I ’ m going to kill you for this . ',\n",
       "  ' What ’ s wrong ? Didn ’ t you think it was fun ? ! ',\n",
       "  ' Oh , yeah ! I had a blast ! I love sweating like a pig with a bunch of pot bellies who all smell bad . Sorry , I ’ m just not into this health kick . ',\n",
       "  ' Oh , no , get off it . It wasn ’ t such a killer class . You just have to get into it . Like they say , no pain , no gain . ',\n",
       "  ' I am wiped out . Thank you . ',\n",
       "  ' Look , next time get yourself some comfy shoes . You ’ re gonna come back again with me , aren ’ t you ? ',\n",
       "  ' Never ! But thank you for inviting me . ',\n",
       "  ' Come on . You ’ ll feel better after we hit the showers . '],\n",
       " ['Can I take your order now or do you still want to look at the menu ? ',\n",
       "  \" Well , I want a fillet steak , medium , but my little girl doesn't care for steak . Could she have something else instead ? \",\n",
       "  ' Certainly . How about spaghetti with clams and shrimps . ',\n",
       "  \" Sounds delicious . OK . She'll try that . \"],\n",
       " ['Can you manage chopsticks ? ',\n",
       "  ' Why not ? See . ',\n",
       "  ' Good mastery . How do you like our Chinese food ? ',\n",
       "  \" Oh , great ! It's delicious . You see , I am already putting on weight . There is one thing I don't like however , MSG . \",\n",
       "  \" What's wrong with MSG ? It helps to bring out the taste of the food . \",\n",
       "  ' According to some studies it may cause cancer . ',\n",
       "  \" Oh , don't let that worry you . If that were true , China wouldn't have such a large population . \",\n",
       "  ' I just happen to have a question for you guys . Why do the Chinese cook the vegetables ? You see what I mean is that most vitamin are destroyed when heated . ',\n",
       "  \" I don't know exactly . It's a tradition . Maybe it's for sanitary reasons . \"],\n",
       " [\"I'm exhausted . \", \" Okay , let's go home . \"],\n",
       " [\"Good evening . Welcome to Cherry's . Do you have a reservation ? \",\n",
       "  \" No , we don't . \",\n",
       "  ' How many of you , please ? ',\n",
       "  ' Six , including two kids . ',\n",
       "  \" I'm afraid all the big tables are taken . \"]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"../../datasets/ijcnlp_dailydialog/readme.txt\", \"r\")\n",
    "text = file.read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here are some explanations about the files:',\n",
       " '',\n",
       " '1) dialogues_text.txt: The DailyDialog dataset which contains 11,318 transcribed dialogues.',\n",
       " '2) dialogues_topic.txt: Each line in dialogues_topic.txt corresponds to the topic of that in dialogues_text.txt.',\n",
       " '                        The topic number represents: {1: Ordinary Life, 2: School Life, 3: Culture & Education,',\n",
       " '                        4: Attitude & Emotion, 5: Relationship, 6: Tourism , 7: Health, 8: Work, 9: Politics, 10: Finance}',\n",
       " '3) dialogues_act.txt: Each line in dialogues_act.txt corresponds to the dialog act annotations in dialogues_text.txt.',\n",
       " '                      The dialog act number represents: { 1: inform，2: question, 3: directive, 4: commissive }',\n",
       " '4) dialogues_emotion.txt: Each line in dialogues_emotion.txt corresponds to the emotion annotations in dialogues_text.txt.',\n",
       " '                          The emotion number represents: { 0: no emotion, 1: anger, 2: disgust, 3: fear, 4: happiness, 5: sadness, 6: surprise}',\n",
       " '5) train.zip, validation.zip and test.zip are two different segmentations of the whole dataset. ',\n",
       " '']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26721"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"../../datasets/ijcnlp_dailydialog/dialogues_topic.txt\", \"r\")\n",
    "text = file.read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219076"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"../../datasets/ijcnlp_dailydialog/dialogues_act.txt\", \"r\")\n",
    "text = file.read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 4 \\n3 4 3 1 1 \\n2 1 3 4 \\n3 2 1 1 \\n3 4 1 \\n2 1 2 1 3 4 3 4 3 \\n2 2 3 4 \\n2 1 2 1 2 1 1 2 1 \\n3 4 \\n2 1 2 1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219076"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"../../datasets/ijcnlp_dailydialog/dialogues_emotion.txt\", \"r\")\n",
    "text = file.read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 0 \\n4 2 0 1 0 \\n0 1 0 0 \\n0 0 0 4 \\n0 4 4 \\n4 2 6 2 0 0 0 0 0 \\n0 0 0 4 \\n0 0 4 4 6 0 0 0 0 \\n0 0 \\n0 0 0 0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchbot.preprocessing import clean_texts\n",
    "\n",
    "data = [clean_texts(dialog) for dialog in dialogs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['the', 'kitchen', 'stink', '.'],\n",
       "  ['i', 'will', 'throw', 'out', 'the', 'garbag', '.']],\n",
       " [['so',\n",
       "   'dick',\n",
       "   ',',\n",
       "   'how',\n",
       "   'about',\n",
       "   'get',\n",
       "   'some',\n",
       "   'coffe',\n",
       "   'for',\n",
       "   'tonight',\n",
       "   '?'],\n",
       "  ['coffe',\n",
       "   '?',\n",
       "   'i',\n",
       "   'do',\n",
       "   'not',\n",
       "   'honestli',\n",
       "   'like',\n",
       "   'that',\n",
       "   'kind',\n",
       "   'of',\n",
       "   'stuff',\n",
       "   '.'],\n",
       "  ['come',\n",
       "   'on',\n",
       "   ',',\n",
       "   'you',\n",
       "   'can',\n",
       "   'at',\n",
       "   'least',\n",
       "   'tri',\n",
       "   'a',\n",
       "   'littl',\n",
       "   ',',\n",
       "   'besid',\n",
       "   'your',\n",
       "   'cigarett',\n",
       "   '.'],\n",
       "  ['what',\n",
       "   'is',\n",
       "   'wrong',\n",
       "   'with',\n",
       "   'that',\n",
       "   '?',\n",
       "   'cigarett',\n",
       "   'is',\n",
       "   'the',\n",
       "   'thing',\n",
       "   'i',\n",
       "   'go',\n",
       "   'crazi',\n",
       "   'for',\n",
       "   '.'],\n",
       "  ['not', 'for', 'me', ',', 'dick', '.']]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
