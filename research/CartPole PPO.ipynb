{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Implement PPO. I use the repository, https://github.com/lcswillems/pytorch-a2c-ppo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Delete old tensorboard log\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/work/library/gym/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293ff23b4acc46ddb217d2a1250b6603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyboardInterupt\n",
      "KeyboardInterupt\n",
      "KeyboardInterupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f489fb47dc4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0moptimized_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/rltorch-0.1-py3.6.egg/rltorch/runner.py\u001b[0m in \u001b[0;36msimulate\u001b[0;34m(self, n_frames, training, render_freq, notebook, render_all)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrender_freq\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrender_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParallelEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/rltorch-0.1-py3.6.egg/rltorch/env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, render_all)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/library/gym/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/library/gym/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mglClearColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36mclear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mThe\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mactive\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         '''\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglClear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGL_COLOR_BUFFER_BIT\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGL_DEPTH_BUFFER_BIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdispatch_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/gl/lib.py\u001b[0m in \u001b[0;36merrcheck\u001b[0;34m(result, func, arguments)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0merrcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_debug_gl_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from rltorch import Runner\n",
    "from rltorch.agents import PPOAgent\n",
    "from rltorch.processors import AtariProcessor\n",
    "from rltorch.layers import ACModel, Flatten\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "\n",
    "class CartPoleAgent(PPOAgent):\n",
    "    def build_model(self, config=None):\n",
    "        model = nn.Sequential()\n",
    "        model.add_module('flatten', Flatten())\n",
    "        in_features = np.prod(self.state_shape)\n",
    "        print(in_features)\n",
    "        model.add_module('conv2', nn.Linear(in_features, 16))\n",
    "        model.add_module('relu2', nn.ReLU())\n",
    "        model.add_module('conv3', nn.Linear(16, 16))\n",
    "        model.add_module('relu3', nn.ReLU())\n",
    "\n",
    "        # Actor layer\n",
    "        actor_model = nn.Sequential()\n",
    "        actor_model.add_module('actor_fc', nn.Linear(16, self.action_config['n_action']))\n",
    "        actor_model.add_module('actor_softmax', nn.Softmax())\n",
    "\n",
    "        # Value layer\n",
    "        value_model = nn.Sequential()\n",
    "        value_model.add_module('value_fc', nn.Linear(16, 1))\n",
    "        # Combine all models\n",
    "        ac_model = ACModel(model, actor_model, value_model, self.action_dist)\n",
    "        return ac_model\n",
    "    \n",
    "\n",
    "FRAME_WIDTH = 84\n",
    "FRAME_HEIGHT = 84\n",
    "WINDOW_LENGTH = 3\n",
    "lr = 2.5e-4\n",
    "# lr = 10\n",
    "# state_shape = env.observation_space.shape\n",
    "# state_shape = (WINDOW_LENGTH, FRAME_WIDTH, FRAME_HEIGHT)\n",
    "state_shape = (WINDOW_LENGTH,) + env.observation_space.shape\n",
    "action_config = {'n_action': env.action_space.n, 'type': 'integer'}\n",
    "processor = AtariProcessor(FRAME_WIDTH, FRAME_HEIGHT)\n",
    "processor = None\n",
    "agent = CartPoleAgent(state_shape, action_config, processor=processor,\n",
    "                 window_length=WINDOW_LENGTH, n_epochs=3,\n",
    "                 lr=lr, entropy_coef=0.01, value_loss_coef=1,\n",
    "                 batch_size=32 * 4, num_frames_per_proc=128, debug=False)\n",
    "\n",
    "runner = Runner(env, agent, num_workers=4, multi=True)\n",
    "\n",
    "optimized_agent = runner.simulate(training=True, notebook=True, render_freq=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchviz import make_dot, make_dot_from_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"696pt\" height=\"493pt\"\n",
       " viewBox=\"0.00 0.00 696.00 493.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 489)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-489 692,-489 692,4 -4,4\"/>\n",
       "<!-- 140393309571896 -->\n",
       "<g id=\"node1\" class=\"node\"><title>140393309571896</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"514,-21 410,-21 410,-0 514,-0 514,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"462\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140393309572736 -->\n",
       "<g id=\"node2\" class=\"node\"><title>140393309572736</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"377,-78 275,-78 275,-57 377,-57 377,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"326\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140393309572736&#45;&gt;140393309571896 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>140393309572736&#45;&gt;140393309571896</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M349.689,-56.9197C371.592,-48.0622 404.357,-34.8115 428.853,-24.9052\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"430.167,-28.1489 438.126,-21.155 427.543,-21.6595 430.167,-28.1489\"/>\n",
       "</g>\n",
       "<!-- 140393309571560 -->\n",
       "<g id=\"node3\" class=\"node\"><title>140393309571560</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"391.5,-148 248.5,-148 248.5,-114 391.5,-114 391.5,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\">value_model.value_fc.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140393309571560&#45;&gt;140393309572736 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>140393309571560&#45;&gt;140393309572736</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M321.576,-113.842C322.349,-105.923 323.285,-96.3241 324.098,-88.0006\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"327.581,-88.3345 325.069,-78.0419 320.615,-87.6548 327.581,-88.3345\"/>\n",
       "</g>\n",
       "<!-- 140393309572120 -->\n",
       "<g id=\"node4\" class=\"node\"><title>140393309572120</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"521.5,-78 402.5,-78 402.5,-57 521.5,-57 521.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"462\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">ThresholdBackward0</text>\n",
       "</g>\n",
       "<!-- 140393309572120&#45;&gt;140393309571896 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>140393309572120&#45;&gt;140393309571896</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M462,-56.9197C462,-49.9083 462,-40.1442 462,-31.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"465.5,-31.3408 462,-21.3408 458.5,-31.3409 465.5,-31.3408\"/>\n",
       "</g>\n",
       "<!-- 140393309571448 -->\n",
       "<g id=\"node5\" class=\"node\"><title>140393309571448</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"514,-141.5 410,-141.5 410,-120.5 514,-120.5 514,-141.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"462\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140393309571448&#45;&gt;140393309572120 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>140393309571448&#45;&gt;140393309572120</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M462,-120.391C462,-111.866 462,-99.1392 462,-88.4235\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"465.5,-88.2448 462,-78.2449 458.5,-88.2449 465.5,-88.2448\"/>\n",
       "</g>\n",
       "<!-- 140393309571224 -->\n",
       "<g id=\"node6\" class=\"node\"><title>140393309571224</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"384,-205 282,-205 282,-184 384,-184 384,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"333\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140393309571224&#45;&gt;140393309571448 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>140393309571224&#45;&gt;140393309571448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M353.156,-183.891C374.551,-173.691 408.562,-157.476 432.87,-145.887\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"434.465,-149.005 441.985,-141.542 431.452,-142.686 434.465,-149.005\"/>\n",
       "</g>\n",
       "<!-- 140393309570776 -->\n",
       "<g id=\"node7\" class=\"node\"><title>140393309570776</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"378,-275 262,-275 262,-241 378,-241 378,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\">share_model.fc1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (512)</text>\n",
       "</g>\n",
       "<!-- 140393309570776&#45;&gt;140393309571224 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>140393309570776&#45;&gt;140393309571224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M323.416,-240.842C325.089,-232.923 327.118,-223.324 328.878,-215.001\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"332.339,-215.55 330.983,-205.042 325.49,-214.102 332.339,-215.55\"/>\n",
       "</g>\n",
       "<!-- 140393309571112 -->\n",
       "<g id=\"node8\" class=\"node\"><title>140393309571112</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"508,-205 416,-205 416,-184 508,-184 508,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"462\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 140393309571112&#45;&gt;140393309571448 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>140393309571112&#45;&gt;140393309571448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M462,-183.891C462,-175.366 462,-162.639 462,-151.923\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"465.5,-151.745 462,-141.745 458.5,-151.745 465.5,-151.745\"/>\n",
       "</g>\n",
       "<!-- 140393309570664 -->\n",
       "<g id=\"node9\" class=\"node\"><title>140393309570664</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"528,-268.5 396,-268.5 396,-247.5 528,-247.5 528,-268.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"462\" y=\"-254.9\" font-family=\"Times,serif\" font-size=\"12.00\">ThnnConv2DBackward</text>\n",
       "</g>\n",
       "<!-- 140393309570664&#45;&gt;140393309571112 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>140393309570664&#45;&gt;140393309571112</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M462,-247.391C462,-238.866 462,-226.139 462,-215.423\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"465.5,-215.245 462,-205.245 458.5,-215.245 465.5,-215.245\"/>\n",
       "</g>\n",
       "<!-- 140393309570440 -->\n",
       "<g id=\"node10\" class=\"node\"><title>140393309570440</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"372,-338.5 240,-338.5 240,-317.5 372,-317.5 372,-338.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"306\" y=\"-324.9\" font-family=\"Times,serif\" font-size=\"12.00\">ThnnConv2DBackward</text>\n",
       "</g>\n",
       "<!-- 140393309570440&#45;&gt;140393309570664 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>140393309570440&#45;&gt;140393309570664</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.02,-317.401C354.848,-305.707 400.35,-285.873 430.783,-272.607\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.323,-275.754 440.092,-268.55 429.526,-269.337 432.323,-275.754\"/>\n",
       "</g>\n",
       "<!-- 140393309570216 -->\n",
       "<g id=\"node11\" class=\"node\"><title>140393309570216</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"216,-408.5 84,-408.5 84,-387.5 216,-387.5 216,-408.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"150\" y=\"-394.9\" font-family=\"Times,serif\" font-size=\"12.00\">ThnnConv2DBackward</text>\n",
       "</g>\n",
       "<!-- 140393309570216&#45;&gt;140393309570440 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>140393309570216&#45;&gt;140393309570440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.02,-387.401C198.848,-375.707 244.35,-355.873 274.783,-342.607\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"276.323,-345.754 284.092,-338.55 273.526,-339.337 276.323,-345.754\"/>\n",
       "</g>\n",
       "<!-- 140393309572568 -->\n",
       "<g id=\"node12\" class=\"node\"><title>140393309572568</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"144,-485 0,-485 0,-451 144,-451 144,-485\"/>\n",
       "<text text-anchor=\"middle\" x=\"72\" y=\"-471.4\" font-family=\"Times,serif\" font-size=\"12.00\">share_model.conv1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"72\" y=\"-458.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (32, 4, 8, 8)</text>\n",
       "</g>\n",
       "<!-- 140393309572568&#45;&gt;140393309570216 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>140393309572568&#45;&gt;140393309570216</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.4849,-450.885C102.637,-440.291 118.504,-426.458 130.799,-415.739\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.413,-418.104 138.65,-408.895 128.813,-412.828 133.413,-418.104\"/>\n",
       "</g>\n",
       "<!-- 140393309569992 -->\n",
       "<g id=\"node13\" class=\"node\"><title>140393309569992</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"293.5,-485 162.5,-485 162.5,-451 293.5,-451 293.5,-485\"/>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-471.4\" font-family=\"Times,serif\" font-size=\"12.00\">share_model.conv1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-458.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (32)</text>\n",
       "</g>\n",
       "<!-- 140393309569992&#45;&gt;140393309570216 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>140393309569992&#45;&gt;140393309570216</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M209.515,-450.885C197.363,-440.291 181.496,-426.458 169.201,-415.739\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.187,-412.828 161.35,-408.895 166.587,-418.104 171.187,-412.828\"/>\n",
       "</g>\n",
       "<!-- 140393309572960 -->\n",
       "<g id=\"node14\" class=\"node\"><title>140393309572960</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"378,-415 234,-415 234,-381 378,-381 378,-415\"/>\n",
       "<text text-anchor=\"middle\" x=\"306\" y=\"-401.4\" font-family=\"Times,serif\" font-size=\"12.00\">share_model.conv2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"306\" y=\"-388.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64, 32, 4, 4)</text>\n",
       "</g>\n",
       "<!-- 140393309572960&#45;&gt;140393309570440 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>140393309572960&#45;&gt;140393309570440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M306,-380.885C306,-371.309 306,-359.088 306,-348.912\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"309.5,-348.895 306,-338.895 302.5,-348.895 309.5,-348.895\"/>\n",
       "</g>\n",
       "<!-- 140393309572624 -->\n",
       "<g id=\"node15\" class=\"node\"><title>140393309572624</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"527.5,-415 396.5,-415 396.5,-381 527.5,-381 527.5,-415\"/>\n",
       "<text text-anchor=\"middle\" x=\"462\" y=\"-401.4\" font-family=\"Times,serif\" font-size=\"12.00\">share_model.conv2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"462\" y=\"-388.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 140393309572624&#45;&gt;140393309570440 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>140393309572624&#45;&gt;140393309570440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M425.03,-380.885C398.463,-369.305 363.019,-353.854 337.733,-342.832\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"338.81,-339.484 328.245,-338.696 336.013,-345.901 338.81,-339.484\"/>\n",
       "</g>\n",
       "<!-- 140393309570328 -->\n",
       "<g id=\"node16\" class=\"node\"><title>140393309570328</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"534,-345 390,-345 390,-311 534,-311 534,-345\"/>\n",
       "<text text-anchor=\"middle\" x=\"462\" y=\"-331.4\" font-family=\"Times,serif\" font-size=\"12.00\">share_model.conv3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"462\" y=\"-318.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64, 64, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140393309570328&#45;&gt;140393309570664 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>140393309570328&#45;&gt;140393309570664</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M462,-310.885C462,-301.309 462,-289.088 462,-278.912\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"465.5,-278.895 462,-268.895 458.5,-278.895 465.5,-278.895\"/>\n",
       "</g>\n",
       "<!-- 140393309572848 -->\n",
       "<g id=\"node17\" class=\"node\"><title>140393309572848</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"683.5,-345 552.5,-345 552.5,-311 683.5,-311 683.5,-345\"/>\n",
       "<text text-anchor=\"middle\" x=\"618\" y=\"-331.4\" font-family=\"Times,serif\" font-size=\"12.00\">share_model.conv3.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"618\" y=\"-318.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 140393309572848&#45;&gt;140393309570664 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>140393309572848&#45;&gt;140393309570664</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M581.03,-310.885C554.463,-299.305 519.019,-283.854 493.733,-272.832\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"494.81,-269.484 484.245,-268.696 492.013,-275.901 494.81,-269.484\"/>\n",
       "</g>\n",
       "<!-- 140393309571000 -->\n",
       "<g id=\"node18\" class=\"node\"><title>140393309571000</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"623.5,-205 550.5,-205 550.5,-184 623.5,-184 623.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"587\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140393309571000&#45;&gt;140393309571448 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>140393309571000&#45;&gt;140393309571448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M567.469,-183.891C546.829,-173.736 514.072,-157.62 490.54,-146.042\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"491.912,-142.816 481.394,-141.542 488.822,-149.097 491.912,-142.816\"/>\n",
       "</g>\n",
       "<!-- 140393309570552 -->\n",
       "<g id=\"node19\" class=\"node\"><title>140393309570552</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"676,-275 546,-275 546,-241 676,-241 676,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"611\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\">share_model.fc1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"611\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (512, 3136)</text>\n",
       "</g>\n",
       "<!-- 140393309570552&#45;&gt;140393309571000 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>140393309570552&#45;&gt;140393309571000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M604.694,-240.842C601.535,-232.745 597.689,-222.892 594.392,-214.441\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"597.62,-213.085 590.724,-205.042 591.099,-215.63 597.62,-213.085\"/>\n",
       "</g>\n",
       "<!-- 140393309571784 -->\n",
       "<g id=\"node20\" class=\"node\"><title>140393309571784</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"629.5,-78 556.5,-78 556.5,-57 629.5,-57 629.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"593\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140393309571784&#45;&gt;140393309571896 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>140393309571784&#45;&gt;140393309571896</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M570.182,-56.9197C549.178,-48.1014 517.803,-34.9287 494.242,-25.0369\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"495.572,-21.7991 484.997,-21.155 492.862,-28.2533 495.572,-21.7991\"/>\n",
       "</g>\n",
       "<!-- 140393309571336 -->\n",
       "<g id=\"node21\" class=\"node\"><title>140393309571336</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"688,-148 532,-148 532,-114 688,-114 688,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"610\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\">value_model.value_fc.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"610\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1, 512)</text>\n",
       "</g>\n",
       "<!-- 140393309571336&#45;&gt;140393309571784 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>140393309571336&#45;&gt;140393309571784</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M605.533,-113.842C603.32,-105.834 600.632,-96.1082 598.313,-87.7205\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"601.675,-86.7479 595.638,-78.0419 594.928,-88.613 601.675,-86.7479\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fafdd588cc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.tensor(agent.memory.get_state_idx(5), dtype=torch.float)\n",
    "\n",
    "make_dot(agent.ac_model(state)[1], params=dict(agent.ac_model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv1d in module torch.nn.modules.conv:\n",
      "\n",
      "class Conv1d(_ConvNd)\n",
      " |  Applies a 1D convolution over an input signal composed of several input\n",
      " |  planes.\n",
      " |  \n",
      " |  In the simplest case, the output value of the layer with input size\n",
      " |  :math:`(N, C_{in}, L)` and output :math:`(N, C_{out}, L_{out})` can be\n",
      " |  precisely described as:\n",
      " |  \n",
      " |  .. math::\n",
      " |  \n",
      " |      \\begin{equation*}\n",
      " |      \\text{out}(N_i, C_{out_j}) = \\text{bias}(C_{out_j}) +\n",
      " |                              \\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{out_j}, k) \\star \\text{input}(N_i, k)\n",
      " |      \\end{equation*},\n",
      " |  \n",
      " |  where :math:`\\star` is the valid `cross-correlation`_ operator,\n",
      " |  :math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
      " |  :math:`L` is a length of signal sequence.\n",
      " |  \n",
      " |  * :attr:`stride` controls the stride for the cross-correlation, a single\n",
      " |    number or a one-element tuple.\n",
      " |  \n",
      " |  * :attr:`padding` controls the amount of implicit zero-paddings on both sides\n",
      " |    for :attr:`padding` number of points.\n",
      " |  \n",
      " |  * :attr:`dilation` controls the spacing between the kernel points; also\n",
      " |    known as the Ã  trous algorithm. It is harder to describe, but this `link`_\n",
      " |    has a nice visualization of what :attr:`dilation` does.\n",
      " |  \n",
      " |  * :attr:`groups` controls the connections between inputs and outputs.\n",
      " |    :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
      " |    :attr:`groups`. For example,\n",
      " |  \n",
      " |      * At groups=1, all inputs are convolved to all outputs.\n",
      " |      * At groups=2, the operation becomes equivalent to having two conv\n",
      " |        layers side by side, each seeing half the input channels,\n",
      " |        and producing half the output channels, and both subsequently\n",
      " |        concatenated.\n",
      " |      * At groups= :attr:`in_channels`, each input channel is convolved with\n",
      " |        its own set of filters (of size\n",
      " |        :math:`\\left\\lfloor \\frac{\\text{out_channels}}{\\text{in_channels}} \\right\\rfloor`).\n",
      " |  \n",
      " |  .. note::\n",
      " |  \n",
      " |       Depending of the size of your kernel, several (of the last)\n",
      " |       columns of the input might be lost, because it is a valid\n",
      " |       `cross-correlation`_, and not a full `cross-correlation`_.\n",
      " |       It is up to the user to add proper padding.\n",
      " |  \n",
      " |  .. note::\n",
      " |  \n",
      " |       The configuration when `groups == in_channels` and `out_channels == K * in_channels`\n",
      " |       where `K` is a positive integer is termed in literature as depthwise convolution.\n",
      " |  \n",
      " |       In other words, for an input of size :math:`(N, C_{in}, L_{in})`, if you want a\n",
      " |       depthwise convolution with a depthwise multiplier `K`,\n",
      " |       then you use the constructor arguments\n",
      " |       :math:`(\\text{in_channels}=C_{in}, \\text{out_channels}=C_{in} * K, ..., \\text{groups}=C_{in})`\n",
      " |  \n",
      " |  Args:\n",
      " |      in_channels (int): Number of channels in the input image\n",
      " |      out_channels (int): Number of channels produced by the convolution\n",
      " |      kernel_size (int or tuple): Size of the convolving kernel\n",
      " |      stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
      " |      padding (int or tuple, optional): Zero-padding added to both sides of\n",
      " |          the input. Default: 0\n",
      " |      dilation (int or tuple, optional): Spacing between kernel\n",
      " |          elements. Default: 1\n",
      " |      groups (int, optional): Number of blocked connections from input\n",
      " |          channels to output channels. Default: 1\n",
      " |      bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(N, C_{in}, L_{in})`\n",
      " |      - Output: :math:`(N, C_{out}, L_{out})` where\n",
      " |  \n",
      " |        .. math::\n",
      " |            L_{out} = \\left\\lfloor\\frac{L_{in} + 2 * \\text{padding} - \\text{dilation}\n",
      " |                      * (\\text{kernel_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight (Tensor): the learnable weights of the module of shape\n",
      " |          (out_channels, in_channels, kernel_size)\n",
      " |      bias (Tensor):   the learnable bias of the module of shape\n",
      " |          (out_channels)\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> m = nn.Conv1d(16, 33, 3, stride=2)\n",
      " |      >>> input = torch.randn(20, 16, 50)\n",
      " |      >>> output = m(input)\n",
      " |  \n",
      " |  .. _cross-correlation:\n",
      " |      https://en.wikipedia.org/wiki/Cross-correlation\n",
      " |  \n",
      " |  .. _link:\n",
      " |      https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv1d\n",
      " |      _ConvNd\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  forward(self, input)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _ConvNd:\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  reset_parameters(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          parameter (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`torch-nn-init`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> def init_weights(m):\n",
      " |                  print(m)\n",
      " |                  if type(m) == nn.Linear:\n",
      " |                      m.weight.data.fill_(1.0)\n",
      " |                      print(m.weight)\n",
      " |      \n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          )\n",
      " |          1 -> Linear (2 -> 2)\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear (2 -> 2))\n",
      " |  \n",
      " |  named_parameters(self, memo=None, prefix='')\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None\n",
      " |      \n",
      " |      The hook should not modify the input or output.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None\n",
      " |      \n",
      " |      The hook should not modify the input.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          parameter (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device)\n",
      " |      \n",
      " |      .. function:: to(dtype)\n",
      " |      \n",
      " |      .. function:: to(device, dtype)\n",
      " |      \n",
      " |      It has similar signature as :meth:`torch.Tensor.to`, but does not take\n",
      " |      a Tensor and only takes in floating point :attr:`dtype` s. In\n",
      " |      particular, this method will only cast the floating point parameters and\n",
      " |      buffers to :attr:`dtype`. It will still move the integral parameters and\n",
      " |      buffers to :attr:`device`, if that is given. See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.Conv1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 84, 84)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5716,  0.7730, -0.9750,  1.1229]], dtype=torch.float64),\n",
       " tensor([[-1.2867,  0.6309,  1.0654, -0.8968]], dtype=torch.float64),\n",
       " tensor([[ 2.1899, -0.0554,  0.0463,  0.5020]], dtype=torch.float64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(x, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function detach:\n",
      "\n",
      "detach(...) method of torch.Tensor instance\n",
      "    Returns a new Tensor, detached from the current graph.\n",
      "    \n",
      "    The result will never require gradient.\n",
      "    \n",
      "    .. note::\n",
      "    \n",
      "      Returned Tensor uses the same data tensor as the original one.\n",
      "      In-place modifications on either of them will be seen, and may trigger\n",
      "      errors in correctness checks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(b.detach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dist.Normal(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = x.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4189)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdc923e7198>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdca000fd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "gray_state = processor.process(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 84)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdc9203dbe0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc9223bb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(gray_state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6013647058823529"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.max(gray_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(gray_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/work/library/gym/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0').unwrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight[16, 4, 2], so expected input[1, 16, 4] to have 4 channels, but got 16 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f01c7ffbd444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/rltorch-0.1-py3.6.egg/rltorch/agents/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, obs, training)\u001b[0m\n\u001b[1;32m    176\u001b[0m             state_tensor = torch.tensor(state, dtype=torch.float,\n\u001b[1;32m    177\u001b[0m                                         device=self.experience_device)\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mac_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/rltorch-0.1-py3.6.egg/rltorch/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 176\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight[16, 4, 2], so expected input[1, 16, 4] to have 4 channels, but got 16 channels instead"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "agent.predict(np.array([[obs for _ in range(4)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
