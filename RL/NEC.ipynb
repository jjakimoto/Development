{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class HashDND(object):\n",
    "    \"\"\"differentiable neural dictionary, using LSH for approximate\n",
    "    nearest neighbour lookup. Assumes keys are vectors. Also assumes we only\n",
    "    use float32 and doesn't handle batched operations :(\"\"\"\n",
    "\n",
    "    sentinel_value = np.inf\n",
    "\n",
    "    @classmethod\n",
    "    def _setup_variables(cls, hash_bits, max_neighbours, key_size, value_shape):\n",
    "        \"\"\"setup variables with appropriate initializers given the shapes\"\"\"\n",
    "        init = tf.constant_initializer(cls.sentinel_value)\n",
    "        if value_shape is None:\n",
    "            value_shape = [2**hash_bits * max_neighbours,]\n",
    "        else:\n",
    "            value_shape = [2**hash_bits * max_neighbours,] + list(value_shape)\n",
    "        values = tf.get_variable(name='values',\n",
    "                                  shape=value_shape,\n",
    "                                  initializer=init)\n",
    "        keys = tf.get_variable(name='keys',\n",
    "                           shape=[2**hash_bits * max_neighbours, key_size],\n",
    "                           initializer=init)\n",
    "        return keys, values\n",
    "\n",
    "    def __init__(self, hash_bits, max_neighbours, key_size,\n",
    "                 similarity_measure=None, value_shape=None,  scope_name='dnd'):\n",
    "        \"\"\"Set up the dnd.\n",
    "\n",
    "        Args:\n",
    "            hash_bits (int): how many bits for the hash. There will be\n",
    "                `2**num_bits` individual buckets.\n",
    "            max_neighbours (int): how many entries to store in each bucket.\n",
    "                This controls the number of neighbours we check against.\n",
    "                Operations will be linear in this value and it will likely\n",
    "                effect learning performance significantly as well.\n",
    "            key_size (int): size of the key vectors. We use the unhashed key\n",
    "                vectors to compute similarities between keys we find from the\n",
    "                nearest neighbour lookup.\n",
    "            value_shapes (list): list of shapes for the values stored in the\n",
    "                dictionary.\n",
    "            similarity_measure (Optional[callable]): function which adds ops\n",
    "                to compare a query key with all of the other keys in the\n",
    "                bucket. If unspecified, the cosine similarity is used. Should\n",
    "                be a callable which takes two input tensors: the query key\n",
    "                (shaped `[key_size]`) and a  `[max_neighbours, key_size]`\n",
    "                tensor  of keys to compare against. Should return a\n",
    "                `[max_neighbours]` tensor of similarities, between 0 and 1\n",
    "                where 1 means the two keys were identical.\n",
    "            name (Optional[str]): a name under which to group ops and\n",
    "                variables. Defaults to `dnd`.\n",
    "        \"\"\"\n",
    "        self._name = scope_name\n",
    "        self._hash_size = hash_bits\n",
    "        self._key_size = key_size\n",
    "        self._bucket_size = max_neighbours\n",
    "        with tf.variable_scope(self._name):\n",
    "            self._keys, self._values = HashDND._setup_variables(hash_bits,\n",
    "                                                                max_neighbours,\n",
    "                                                                key_size,\n",
    "                                                                value_shape)\n",
    "            self._hash_config = get_simhash_config(self._key_size, self._hash_size)\n",
    "\n",
    "        if not similarity_measure:\n",
    "            similarity_measure = cosine_similarity\n",
    "        self._similarity_measure = similarity_measure\n",
    "\n",
    "    def store(self, query, value):\n",
    "        \"\"\"Gets an op which will store the key-value pair.\n",
    "        \n",
    "        Args:\n",
    "            query: tensor, shape=(key_size,)\n",
    "            value: tensor, shape=(value_shape,)\n",
    "\n",
    "        Returns:\n",
    "            operation to store\n",
    "        \"\"\"\n",
    "        with tf.name_scope(self._name + '/store'):\n",
    "            bucket_keys, bucket_values, idx = self._get_bucket(tf.expand_dims(query, 0))\n",
    "            bucket_keys = bucket_keys[0]\n",
    "            bucket_values = bucket_values[0]\n",
    "            idx = idx[0]\n",
    "            # is there space?\n",
    "            can_store = tf.reduce_any(tf.equal(bucket_keys[:, 0], self.sentinel_value))\n",
    "\n",
    "            def _empty_store():\n",
    "                return self._get_store_op_empty(query, value, idx, bucket_keys)\n",
    "\n",
    "            def _full_store():\n",
    "                return self._get_store_op_full(query, value, idx, bucket_keys)\n",
    "\n",
    "            store_op = tf.cond(can_store, _empty_store, _full_store)\n",
    "        return store_op\n",
    "\n",
    "    def _flatten_index(self, index, bucket_index):\n",
    "        \"\"\"turn a bucket-level index into a global index\"\"\"\n",
    "        return index + (bucket_index * self._bucket_size)\n",
    "\n",
    "    def _update_at_index(self, index, new_key, new_val):\n",
    "        \"\"\"make update ops to insert at the appropriate (flattened) index\"\"\"\n",
    "        # update the keys\n",
    "        keys_update = tf.scatter_update(self._keys, index, new_key)\n",
    "        # and update the values\n",
    "        values_update = tf.scatter_update(self._values, index, new_val)\n",
    "        # make sure they all happen at once\n",
    "        return tf.group(keys_update, values_update)\n",
    "\n",
    "    def _get_store_op_empty(self, store_key, store_val, bucket_index,\n",
    "                            bucket_keys):\n",
    "        \"\"\"get an op to store given key and values in the first empty space.\n",
    "\n",
    "        Returns an op with no output that will run all of the required updates.\n",
    "        \"\"\"\n",
    "        # first find the first empty spot (assuming there is one)\n",
    "        with tf.name_scope('empty_store'):\n",
    "            empty_indices = tf.where(tf.equal(bucket_keys[:, 0], self.sentinel_value))\n",
    "            empty_indices = tf.cast(empty_indices, tf.int32)\n",
    "            store_idx = self._flatten_index(empty_indices[0][0], bucket_index)\n",
    "            return self._update_at_index(store_idx, store_key, store_val)\n",
    "\n",
    "    def _get_store_op_full(self, store_key, store_vals, bucket_index,\n",
    "                           bucket_keys):\n",
    "        \"\"\"get an op to store given keys and values when there are no empty\n",
    "        slots.\n",
    "\n",
    "        Returns an op with no output that will run all of the require updates.\n",
    "        \"\"\"\n",
    "        with tf.name_scope('store_full'):\n",
    "            idx = tf.random_uniform([], minval=0, maxval=self._bucket_size,\n",
    "                                    dtype=tf.int32)\n",
    "            store_idx = self._flatten_index(idx, bucket_index)\n",
    "            return self._update_at_index(store_idx, store_key, store_vals)\n",
    "\n",
    "    def _get_averaged_value(self, values, similarities):\n",
    "        \"\"\"get a weighted sum of values.\"\"\"\n",
    "        weighted_values = similarities * values\n",
    "        all_values = tf.reduce_sum(weighted_values, axis=1)\n",
    "        return all_values\n",
    "\n",
    "    def get(self, queries):\n",
    "        \"\"\"Get the values in the dictionary corresponding to a particular key,\n",
    "        or zeros if the key is not present.\n",
    "\n",
    "        The default similarity is the cosine distance.\n",
    "\n",
    "        Args:\n",
    "            queries: tensor, shape=(batch_size, key_size)\n",
    "\n",
    "        Returns:\n",
    "            value (tuple): associated values.\n",
    "        \"\"\"\n",
    "        # TODO: what to return when the bucket is empty?\n",
    "        # at the moment it is all zeros\n",
    "        with tf.name_scope(self._name + '/get'):\n",
    "            bucket_keys, bucket_values, indices = self._get_bucket(queries)\n",
    "            # for the index where the keys are sentinel, mask it out, shape=(batch_size, bucket_size)\n",
    "            used_positions = tf.not_equal(bucket_keys[:, :, 0], self.sentinel_value)\n",
    "            # if used 1, otherwise 0\n",
    "            used_mask = tf.cast(used_positions, tf.float32)\n",
    "            # set 0 value for non stored key\n",
    "            zero_keys = tf.zeros_like(bucket_keys)\n",
    "            _used_positions = tf.tile(tf.expand_dims(used_positions, 2), [1, 1, self._key_size])\n",
    "            masked_keys = tf.where(_used_positions, bucket_keys, zero_keys) # shape=(batch_size, bucket_size, key_size)\n",
    "            similarities = self._similarity_measure(queries, masked_keys)\n",
    "            # Take only True values\n",
    "            zero_mask = tf.zeros_like(used_positions, dtype=tf.float32)\n",
    "            values = tf.where(used_positions, bucket_values, zero_mask)\n",
    "            # Get rid of zero masked positions, shape=(batch_size, bucket_size)\n",
    "            similarities = tf.where(used_positions, similarities, zero_mask)\n",
    "            sim_shape = tf.shape(similarities)\n",
    "            # normalise them to sum to one, and maybe give them a kick\\\n",
    "            sum_tensor = tf.tile(tf.reduce_sum(similarities, axis=1, keep_dims=True), [1, sim_shape[1]])\n",
    "            # avoid zero division\n",
    "            sum_tensor += tf.constant(1e-8, dtype=tf.float32)\n",
    "            similarities /= sum_tensor\n",
    "            # self.used_positions = similarities\n",
    "            self.values = values\n",
    "            results = self._get_averaged_value(values, similarities)\n",
    "            self.results = results\n",
    "        return results\n",
    "    \n",
    "    def _get_bucket(self, queries):\n",
    "        \"\"\"look up the contents of a bucket by hash. Also return the bucket\n",
    "        index so we can create updates to the storage variables.\n",
    "        Args:\n",
    "            queries: tensor, shape=[batch_size, key_size]\n",
    "        Returns:\n",
    "            keys: tensor, shape=(batch_size, key_size)\n",
    "            values: tensor, shape=(batch_size, value shape)\n",
    "            idx: tensor, shape=(batch_size,)\n",
    "        \"\"\"\n",
    "        # shape = (batch_size,)\n",
    "        idx = simhash(queries, self._hash_config)\n",
    "        # Get idx th key and value \n",
    "        keys, values = self._get_keys_values_by_idx(idx)\n",
    "        return keys, values, idx\n",
    "    \n",
    "    def _get_keys_values_by_idx(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx: tensor, shape=(batch_size,)\n",
    "        \n",
    "        Returns:\n",
    "            keys, values: tensors\n",
    "        \"\"\"\n",
    "        bucket_start = idx * self._bucket_size\n",
    "        bucket_end = (idx + 1) * self._bucket_size\n",
    "        st_end = tf.stack((bucket_start, bucket_end), axis=1)\n",
    "        key_idx = tf.map_fn(lambda x: tf.range(x[0], x[1]), st_end)\n",
    "        # tensor with shape=(batch_size, bucket_size, key_size)\n",
    "        keys = tf.gather(self._keys, key_idx)\n",
    "        # tensor with shape=(batch_size, bucket_size, value_shape)\n",
    "        values = tf.gather(self._values, key_idx)\n",
    "        return keys, values\n",
    "    \n",
    "    \n",
    "def cosine_similarity(query, bucket):\n",
    "    \"\"\"Cosine similarity: the cosine of the angle between two vectors.\n",
    "    Also the dot product, if the vectors are normalised in the l2 norm,\n",
    "    which is how it is implemented here.\n",
    "    \n",
    "    Args:\n",
    "        query: tensor, shape=(batch_size, key_size)\n",
    "        bucket: tensor, shape=(batch_size, bucket_size, key_size)\n",
    "    Returns:\n",
    "        similarities: tensor, shape=(batch_size, bucket_size)\n",
    "    \"\"\"\n",
    "    query = tf.expand_dims(query, 2) #(batch_size, key_size, 1)\n",
    "    query = tf.nn.l2_normalize(query, dim=0)\n",
    "    bucket = tf.nn.l2_normalize(bucket, dim=1)\n",
    "    return tf.squeeze(tf.matmul(bucket, query), 2, name='cos_sim')\n",
    "\n",
    "\n",
    "def get_simhash_config(key_size, hash_bits):\n",
    "    \"\"\"Gets any necessary configuration and data structures necessary for\n",
    "    consistent hashing.\n",
    "\n",
    "    Args:\n",
    "        key_size: int, size of the key size\n",
    "        hash_bits: int, the number of bits we output.\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary with two keys: \"matrix\" corresponding to a variable\n",
    "            used for the random projection and \"bases\" used in the conversion\n",
    "            to integers.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('simhash_config'):\n",
    "        mat = tf.get_variable(\n",
    "            'projection_matrix',\n",
    "            shape=[key_size, hash_bits],\n",
    "            initializer=tf.random_normal_initializer())\n",
    "        bases = 2 ** tf.range(hash_bits)\n",
    "        return {'matrix': mat, 'bases': bases}\n",
    "\n",
    "\n",
    "def simhash(inputs, config):\n",
    "    \"\"\"SimHash the inputs into an integer with `num_bits` used bits.\n",
    "    \n",
    "    Args:\n",
    "        inputs: tensor, shape=(batch_size, key_size)\n",
    "        config: dict, config[\"matrix\"] is tensor with shape=(key_size, hash_bits)\n",
    "            config[\"bases\"] is tensor with shape=(log2(num_bucket,))\n",
    "    Returns:\n",
    "        index, tensor, shape=(batch_size)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('simhash'):\n",
    "        #shape=(batch_size, hash_bits)\n",
    "        projected = tf.matmul(inputs, config['matrix'])\n",
    "        bits = costum_sign(projected) * 0.5 + 0.5\n",
    "        # return bits\n",
    "        bits = tf.cast(bits, tf.int32)\n",
    "        # convert to single bits size integer\n",
    "        # shape = (batch_size,)\n",
    "        index = tf.reduce_sum(bits * tf.expand_dims(config['bases'], 0), axis=1)\n",
    "        return index\n",
    "\n",
    "def costum_sign(x, dtype=tf.float32):\n",
    "    return tf.cast((x>=0), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from logging import getLogger\n",
    "import random\n",
    "from collections import deque\n",
    "from rltensor.networks.ff import MLPModel\n",
    "\n",
    "from rltensor.agents.agent import Agent\n",
    "from rltensor.utils import get_shape\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "class NEC(Agent):\n",
    "    def __init__(self, env, conf, controller_cls=MLPModel,\n",
    "                 diff_memory_cls=HashDND, default_conf=None, sess=None):\n",
    "        self.controller_cls = controller_cls\n",
    "        self.diff_memory_cls = diff_memory_cls\n",
    "        self.key_dim = conf[\"key_dim\"]\n",
    "        self.delay = conf[\"delay\"]\n",
    "        self.recent_rewards = deque(maxlen=self.delay)\n",
    "        self.recent_terminals = deque(maxlen=self.delay)\n",
    "        super(NEC, self).__init__(env, conf, default_conf, sess)\n",
    "        \n",
    "    def _build_graph(self):\n",
    "        \"\"\"Build all of the network and optimizations\n",
    "        \n",
    "        just for conveninece of trainig, seprate placehoder for train and target network\n",
    "        critic network input: [raw_data, smoothed, downsampled]\n",
    "        \"\"\"\n",
    "        # state shape has to be (batch, length,) + input_dim\n",
    "        self.state = tf.placeholder(tf.float32,\n",
    "                                     get_shape(self.state_dim, maxlen=self.window_length),\n",
    "                                     name='state')\n",
    "        _state = self.processor.tensor_process(self.state)\n",
    "        # Employ maximal strategy\n",
    "        self.controller = self.controller_cls(self.key_dim,\n",
    "                                              self.conf[\"controller\"],\n",
    "                                              scope_name=\"controller\")\n",
    "        self.diff_memories = []\n",
    "        for i in range(self.action_dim):\n",
    "            memory = self.diff_memory_cls(key_size=self.key_dim,\n",
    "                                          **self.conf[\"diff_memory\"],\n",
    "                                           scope_name=\"diff_memory_{}\".format(i))\n",
    "            self.diff_memories.append(memory)\n",
    "        self.query = self.controller(_state, self.training)\n",
    "        # returned q_val is tuple \n",
    "        self.q_val_list = [memory.get(self.query) for memory in self.diff_memories]\n",
    "        self.q_val = tf.stack(self.q_val_list, axis=1)\n",
    "        self.max_action = tf.argmax(self.q_val, axis=1)\n",
    "        self.max_q_val = tf.reduce_max(self.q_val, axis=1)\n",
    "        # Build action graph\n",
    "        self.action = tf.placeholder(tf.int32, (None,), name='action')\n",
    "        action_one_hot = tf.one_hot(self.action, depth=self.action_dim)\n",
    "        self.action_q_val = tf.reduce_sum(self.q_val * action_one_hot, axis=1)\n",
    "        # Build target\n",
    "        self.target = tf.placeholder(tf.float32, (None,), name=\"target\")\n",
    "        self.terminal = tf.placeholder(tf.bool, (None,), name=\"terminal\")\n",
    "        # Store values to differentiable memory\n",
    "        self.store_ops = [memory.store(self.query[0], self.target[0]) for memory in self.diff_memories]\n",
    "        # Clip error to stabilize learning\n",
    "        self.error = self.target - self.action_q_val\n",
    "        clipped_error = tf.where(tf.abs(self.error) < self.error_clip,\n",
    "                                    0.5 * tf.square(self.error),\n",
    "                                    tf.abs(self.error), name='clipped_error')\n",
    "        self.loss = tf.reduce_mean(clipped_error, name='loss')\n",
    "        # Build optimization\n",
    "        # self.update_op = self._get_update_op()\n",
    "        self.learning_rate_op = self._get_learning_rate()\n",
    "        self.optimizer = self._get_optimizer(self.optimizer_name,\n",
    "                                             self.learning_rate_op,\n",
    "                                             self.optimizer_conf)\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            grads_vars = self.optimizer.compute_gradients(self.loss)\n",
    "            if \"grad_clip\" in self.conf and self.conf[\"grad_clip\"] is not None:\n",
    "                grads_vars = [\n",
    "                    (tf.clip_by_norm(gv[0], clip_norm=self.conf[\"grad_clip\"]), gv[1]) \n",
    "                        for gv in grads_vars]\n",
    "            self.q_optim = self.optimizer.apply_gradients(grads_vars)\n",
    "\n",
    "    def observe(self, observation, action, reward, terminal, training):\n",
    "        # clip reward into  (min_r, max_r)\n",
    "        reward = max(self.min_r, min(self.max_r, reward))\n",
    "        # assert len(self.memory.observations) == len(self.recent_rewards)\n",
    "        # We always keep data\n",
    "        self.recent_rewards.append(reward)\n",
    "        self.recent_terminals.append(terminal)\n",
    "        target_val = self._calc_target(observation)\n",
    "        # we keep target value instead of reward directly\n",
    "        self.memory.append(observation, action, target_val, terminal, is_store=True)\n",
    "        delay_state = self.memory.get_delay_state()\n",
    "        action = self.memory.delay_actions[0]\n",
    "        self._diff_memories_append(delay_state, target_val, action)\n",
    "        step = self.global_step.eval(session=self.sess)\n",
    "        if (step + 1) % self.t_train_freq == 0:\n",
    "            is_update = True\n",
    "        else:\n",
    "            is_update = False\n",
    "        # print(is_update, step)\n",
    "        if training:\n",
    "            experiences = self.memory.sample(self.batch_size)\n",
    "            weights = np.ones(self.batch_size)\n",
    "            result = self.q_learning_minibatch(experiences, weights, is_update)\n",
    "            return result\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def q_learning_minibatch(self, experiences, batch_weights, is_update=True):\n",
    "        feed_dict = {\n",
    "            self.state: [experience.state for experience in experiences],\n",
    "            self.target: [experience.q_val for experience in experiences],\n",
    "            self.action: [experience.action for experience in experiences],\n",
    "            self.training: True,\n",
    "        }\n",
    "        query, q_val = self.sess.run([self.query, self.q_val], feed_dict=feed_dict)\n",
    "        # print(\"length\", len(experiences))\n",
    "        # print(\"query\", query[0])\n",
    "        # print(\"query\", query.shape)\n",
    "        print(\"q_val\", q_val[0][0])\n",
    "        # print(\"q_val\", q_val.shape)\n",
    "        if is_update:\n",
    "            self.sess.run(self.q_optim, feed_dict=feed_dict);\n",
    "        q_t, loss, error = self.sess.run([self.action_q_val, self.loss, self.error],\n",
    "                                     feed_dict=feed_dict)\n",
    "        return q_t, loss, error, is_update\n",
    "    \n",
    "    def predict(self, state, ep=None):\n",
    "        if ep is None:\n",
    "            ep = self.epsilon.eval(session=self.sess)\n",
    "        if random.random() < ep:\n",
    "            action = np.random.randint(0, self.action_dim)\n",
    "        else:\n",
    "            action = self.sess.run(self.max_action, \n",
    "                                   feed_dict={self.state: [state],\n",
    "                                              self.training: False})[0]\n",
    "        return action\n",
    "    \n",
    "    def _calc_target(self, observation):\n",
    "        target_val = 0\n",
    "        backward = self.delay - 1\n",
    "        for i in range(len(self.recent_rewards)):\n",
    "            target_val += (self.gamma) ** i * self.recent_rewards[i]\n",
    "            backward -= 1\n",
    "            if self.recent_terminals[i]:\n",
    "                break\n",
    "        state = self.memory.get_delay_state(observation, backward)\n",
    "        feed_dict = {\n",
    "            self.state: [state],\n",
    "            self.training: False}\n",
    "        max_q_val = self.sess.run(self.max_q_val, feed_dict=feed_dict)[0]\n",
    "        target_val += self.gamma**(self.delay - backward) * max_q_val\n",
    "        return target_val\n",
    "    \n",
    "    def update_target_q_network(self):\n",
    "        # We have no operations for updating target network\n",
    "        pass\n",
    "    \n",
    "    def _get_update_op(self):\n",
    "        pass\n",
    "    \n",
    "    def _get_memory(self, window_length, limit, *args, **kwargs):\n",
    "        return DelayMemory(self.delay, window_length, limit)\n",
    "    \n",
    "    def _diff_memories_append(self, state, value, action):\n",
    "        feed_dict = {\n",
    "            self.state: [state],\n",
    "            self.target:[value],\n",
    "            self.training: True,\n",
    "        }\n",
    "        self.sess.run(self.store_ops[action], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from copy import deepcopy\n",
    "from six.moves import xrange \n",
    "\n",
    "from rltensor.memories import SequentialMemory\n",
    "\n",
    "DelayExperience = namedtuple('DelayExperience', 'state, action, q_val')\n",
    "\n",
    "class DelayMemory(SequentialMemory):\n",
    "    def __init__(self, delay, window_length, limit, *args, **kwargs):\n",
    "        self.delay = delay\n",
    "        # Take more observations to make state\n",
    "        self.delay_observations = deque(maxlen=self.delay+window_length)\n",
    "        self.delay_actions = deque(maxlen=self.delay)\n",
    "        self.delay_terminals = deque(maxlen=self.delay)\n",
    "        super(DelayMemory, self).__init__(window_length, limit, *args, **kwargs)\n",
    "        \n",
    "    def sample(self, batch_size, weights=None, batch_idxs=None):\n",
    "        if batch_idxs is None:\n",
    "            if weights is not None:\n",
    "                _weights = weights[1:]\n",
    "                _weights /= np.sum(_weights)\n",
    "            else:\n",
    "                _weights = None\n",
    "            # Draw random indexes such that we have at least a single entry before each\n",
    "            # index. Thus, draw samples from [1, self.nb_entries)\n",
    "            batch_idxs = self._sample_batch_indexes(1, self.nb_entries, batch_size, _weights)\n",
    "        assert np.min(batch_idxs) >= 1\n",
    "        assert np.max(batch_idxs) < self.nb_entries\n",
    "        assert len(batch_idxs) == batch_size\n",
    "\n",
    "        # Create experiences\n",
    "        if weights is not None:\n",
    "            _weights = weights[:-1]\n",
    "            _weights /= np.sum(_weights)\n",
    "        else:\n",
    "            _weights = None\n",
    "        experiences = []\n",
    "        # Each idx is index for state1\n",
    "        for i, idx in enumerate(batch_idxs):\n",
    "            # Observatio and terminal happens at the same time, so \n",
    "            # previous index has to keep terminal==False.\n",
    "            s0_i = idx - 1\n",
    "            terminal0 = self.terminals[s0_i]\n",
    "            while terminal0:\n",
    "                # Repeat sampling until getting proper idx\n",
    "                s0_i  = self._sample_batch_indexes(0, self.nb_entries-1, 1, _weights)[0]\n",
    "                terminal0 = self.terminals[s0_i]\n",
    "                batch_idxs[i] = s0_i + 1\n",
    "            assert 0 <= s0_i < self.nb_entries - 1\n",
    "\n",
    "            # This code is slightly complicated by the fact that subsequent observations might be\n",
    "            # from different episodes. We ensure that an experience never spans multiple episodes.\n",
    "            # This is probably not that important in practice but it seems cleaner.\n",
    "            state = [self.observations[s0_i],]\n",
    "            for offset in xrange(1, self.window_length):\n",
    "                current_idx = s0_i - offset\n",
    "                current_terminal = self.terminals[current_idx] if current_idx >= 0 else False\n",
    "                if current_idx < 0 or (not self.ignore_episode_boundaries and current_terminal):\n",
    "                    # The previously handled observation was terminal, don't add the current one.\n",
    "                    # Otherwise we would leak into a different episode.\n",
    "                    break\n",
    "                state.insert(0, self.observations[current_idx])\n",
    "            # Complete unobserved state with 0\n",
    "            while len(state) < self.window_length:\n",
    "                state.insert(0, np.zeros_like(state[0]))\n",
    "            action = self.actions[idx]\n",
    "            if action is None:\n",
    "                print(\"action\", action, idx, self.nb_entries)\n",
    "            q_val = self.rewards[idx]\n",
    "            assert len(state) == self.window_length\n",
    "            experiences.append(DelayExperience(state=state, action=action, q_val=q_val))\n",
    "        assert len(experiences) == batch_size\n",
    "        # Keep sampled sampled idx for prioritized sampling\n",
    "        self.sampled_idx = batch_idxs\n",
    "        return experiences\n",
    "\n",
    "    \n",
    "    def append(self, observation, action, reward, terminal, is_store=True):\n",
    "        # Reward means Q value just for keeping compatibility\n",
    "        self.recent_observations.append(observation)\n",
    "        self.recent_terminals.append(terminal)\n",
    "        if is_store:\n",
    "            self.delay_observations.append(observation)\n",
    "            self.delay_actions.append(action)\n",
    "            self.delay_terminals.append(terminal)\n",
    "            self.observations.append(self.delay_observations[0])\n",
    "            self.actions.append(self.delay_actions[0])\n",
    "            self.rewards.append(reward)\n",
    "            self.terminals.append(self.delay_terminals[0])\n",
    "            \n",
    "    \n",
    "    def get_delay_state(self, observation=None, backward=0):\n",
    "        _observations = deepcopy(self.delay_observations)\n",
    "        if observation is not None:\n",
    "            _observations.append(observation)\n",
    "        if backward > 1:\n",
    "            _observations = deque(list(_observations)[:-backward])\n",
    "        if observation is not None:\n",
    "            padding = np.zeros_like(observation)\n",
    "        else:\n",
    "            padding = np.zeros_like(self.delay_observations[0])\n",
    "        while len(_observations) < self.window_length:\n",
    "            _observations.insert(0, padding)\n",
    "        # Make sure window length observations\n",
    "        return np.array(_observations)[-self.window_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-20 18:29:13,778] Making new env: Breakout-v0\n",
      "[2017-08-20 18:29:15,632] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/tomoaki/work/Development/RL/videos')\n",
      "[2017-08-20 18:29:19,415] Clearing 6 monitor files from previous run (because force=True was provided)\n",
      "[2017-08-20 18:29:19,423] Starting new video recorder writing to /home/tomoaki/work/Development/RL/videos/openaigym.video.8.10153.video000000.mp4\n",
      "\n",
      "\n",
      "  0%|          | 0/10000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: params/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  0%|          | 1/10000000 [00:00<342:41:39,  8.11it/s]\u001b[A\n",
      "  0%|          | 3/10000000 [00:00<292:46:14,  9.49it/s]\u001b[A\n",
      "  0%|          | 5/10000000 [00:00<259:35:43, 10.70it/s]\u001b[A\n",
      "  0%|          | 7/10000000 [00:00<237:04:55, 11.72it/s]\u001b[A\n",
      "  0%|          | 9/10000000 [00:00<222:23:00, 12.49it/s]\u001b[A\n",
      "  0%|          | 11/10000000 [00:00<218:05:44, 12.74it/s]\u001b[A\n",
      "  0%|          | 13/10000000 [00:00<209:27:55, 13.26it/s]\u001b[A\n",
      "  0%|          | 15/10000000 [00:01<202:14:52, 13.73it/s]\u001b[A\n",
      "  0%|          | 17/10000000 [00:01<198:37:37, 13.98it/s]\u001b[A\n",
      "  0%|          | 19/10000000 [00:01<198:37:21, 13.99it/s]\u001b[A\n",
      "  0%|          | 21/10000000 [00:01<199:42:30, 13.91it/s]\u001b[A\n",
      "  0%|          | 23/10000000 [00:01<197:18:20, 14.08it/s]\u001b[A\n",
      "  0%|          | 25/10000000 [00:01<201:01:46, 13.82it/s]\u001b[A\n",
      "  0%|          | 27/10000000 [00:01<201:11:27, 13.81it/s]\u001b[A\n",
      "  0%|          | 29/10000000 [00:02<197:39:20, 14.05it/s]\u001b[A\n",
      "  0%|          | 31/10000000 [00:02<197:58:54, 14.03it/s]\u001b[A\n",
      "  0%|          | 33/10000000 [00:02<198:12:47, 14.01it/s]\u001b[A\n",
      "  0%|          | 35/10000000 [00:02<193:56:19, 14.32it/s]\u001b[A\n",
      "  0%|          | 37/10000000 [00:02<190:11:30, 14.61it/s]\u001b[A\n",
      "  0%|          | 39/10000000 [00:02<185:28:16, 14.98it/s]\u001b[A\n",
      "  0%|          | 41/10000000 [00:02<182:04:49, 15.26it/s]\u001b[A\n",
      "  0%|          | 43/10000000 [00:02<182:01:36, 15.26it/s]\u001b[A\n",
      "  0%|          | 45/10000000 [00:03<182:01:12, 15.26it/s]\u001b[A\n",
      "  0%|          | 47/10000000 [00:03<185:06:14, 15.01it/s]\u001b[A\n",
      "  0%|          | 49/10000000 [00:03<192:15:35, 14.45it/s]\u001b[A\n",
      "  0%|          | 51/10000000 [00:03<191:15:00, 14.52it/s]\u001b[A\n",
      "  0%|          | 53/10000000 [00:03<191:53:45, 14.48it/s]\u001b[A\n",
      "  0%|          | 55/10000000 [00:03<190:01:45, 14.62it/s]\u001b[A\n",
      "  0%|          | 57/10000000 [00:03<194:42:29, 14.27it/s]\u001b[A\n",
      "  0%|          | 59/10000000 [00:04<198:30:24, 13.99it/s]\u001b[A\n",
      "  0%|          | 61/10000000 [00:04<199:30:22, 13.92it/s]\u001b[A\n",
      "  0%|          | 63/10000000 [00:04<198:25:59, 14.00it/s]\u001b[A\n",
      "  0%|          | 65/10000000 [00:04<198:48:50, 13.97it/s]\u001b[A\n",
      "  0%|          | 67/10000000 [00:04<190:40:06, 14.57it/s]\u001b[A\n",
      "  0%|          | 69/10000000 [00:04<184:46:27, 15.03it/s]\u001b[A\n",
      "  0%|          | 71/10000000 [00:04<187:00:48, 14.85it/s]\u001b[A\n",
      "  0%|          | 73/10000000 [00:05<188:30:42, 14.74it/s]\u001b[A\n",
      "  0%|          | 75/10000000 [00:05<190:15:30, 14.60it/s]\u001b[A\n",
      "  0%|          | 77/10000000 [00:05<189:05:54, 14.69it/s]\u001b[A\n",
      "  0%|          | 79/10000000 [00:05<190:36:32, 14.57it/s]\u001b[A\n",
      "  0%|          | 81/10000000 [00:05<192:15:41, 14.45it/s]\u001b[A\n",
      "  0%|          | 83/10000000 [00:05<196:48:19, 14.11it/s]\u001b[A\n",
      "  0%|          | 85/10000000 [00:05<195:09:22, 14.23it/s]\u001b[A\n",
      "  0%|          | 430/10000000 [00:50<323:19:21,  8.59it/s][A\n",
      "  0%|          | 99/10000000 [00:06<209:19:42, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 101/10000000 [00:07<362:45:14,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 103/10000000 [00:08<475:59:25,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 104/10000000 [00:08<558:28:35,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 105/10000000 [00:08<616:33:35,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 106/10000000 [00:08<668:01:43,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 107/10000000 [00:09<713:03:59,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 108/10000000 [00:09<757:35:30,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 109/10000000 [00:09<760:16:42,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 110/10000000 [00:09<733:22:31,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 111/10000000 [00:10<722:46:30,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 112/10000000 [00:10<716:29:30,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 113/10000000 [00:10<707:05:43,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n",
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 115/10000000 [00:11<862:38:05,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 116/10000000 [00:11<833:41:08,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 117/10000000 [00:12<864:12:34,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 118/10000000 [00:12<880:45:21,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 119/10000000 [00:12<926:29:59,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n",
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 121/10000000 [00:13<1023:06:55,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 122/10000000 [00:13<1001:18:22,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 123/10000000 [00:14<932:13:22,  2.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n",
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 124/10000000 [00:14<969:47:08,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 126/10000000 [00:15<945:00:43,  2.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 127/10000000 [00:15<890:40:56,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n",
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 128/10000000 [00:15<977:56:52,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 129/10000000 [00:16<1013:26:53,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 131/10000000 [00:17<1023:09:38,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 132/10000000 [00:17<974:38:27,  2.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 133/10000000 [00:17<980:03:12,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n",
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 135/10000000 [00:18<960:02:35,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 136/10000000 [00:18<897:26:15,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 137/10000000 [00:19<856:23:54,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 138/10000000 [00:19<823:34:24,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 139/10000000 [00:19<803:21:42,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 140/10000000 [00:19<782:08:05,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 141/10000000 [00:20<771:29:09,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 142/10000000 [00:20<766:55:24,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 143/10000000 [00:20<762:04:23,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 144/10000000 [00:20<788:52:20,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 145/10000000 [00:21<855:31:51,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 146/10000000 [00:21<895:23:01,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_val 0.0\n",
      "q_val 0.0\n",
      "Model saved in file: params/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "from rltensor.agents import DQN\n",
    "from rltensor.processors import AtariProcessor\n",
    "from rltensor.networks import MLPModel\n",
    "\n",
    "\n",
    "conf = {\"controller\":[\n",
    "            {\"name\": \"conv2d\", \"kernel_size\":(8, 8), \"num_filter\":32, \"stride\":4,\n",
    "             \"padding\": 'SAME', \"is_batch\":False, 'activation': tf.nn.relu},\n",
    "            {\"name\": \"conv2d\", \"kernel_size\":(5, 5), \"num_filter\":64, \"stride\":2,\n",
    "             \"padding\": 'SAME', \"is_batch\":True, 'activation': tf.nn.relu},\n",
    "           {\"name\": \"conv2d\", \"kernel_size\": (3, 3), \"num_filter\":64, \"stride\":1,\n",
    "             \"padding\": 'SAME', \"is_batch\":True, 'activation': tf.nn.relu},\n",
    "            {\"name\": \"dense\", \"is_flatten\":True, \"is_batch\":True, \"num_hidden\": 512, 'activation': tf.nn.relu},\n",
    "        ],\n",
    "        \"diff_memory\":{\n",
    "            \"hash_bits\":10,\n",
    "            \"max_neighbours\":50,\n",
    "        },\n",
    "        \"key_dim\":300,\n",
    "        \"delay\":100,\n",
    "        \"memory_limit\": 100000,\n",
    "        \"window_length\": 4,\n",
    "        \"gamma\": 0.99,\n",
    "        \"learning_rate\": 2.5e-4,\n",
    "        \"learning_rate_minimum\": 2.5e-4,\n",
    "        \"learning_rate_decay\": 0.9,\n",
    "        \"learning_rate_decay_step\": 100,\n",
    "        \"ep\": 1e-3,\n",
    "        \"min_r\": -1,\n",
    "        \"max_r\": 1,\n",
    "        \"batch_size\": 32,\n",
    "        \"error_clip\": 1.0,\n",
    "        \"processor\": AtariProcessor(84, 84),\n",
    "        \"t_learn_start\": 100,\n",
    "        \"t_train_freq\": 1,\n",
    "        \"t_target_q_update_freq\": 10000,\n",
    "        \"ep_start\": 1.0,\n",
    "        \"ep_end\": 0.1,\n",
    "        \"t_ep_end\": int(1e6),\n",
    "        \"model_dir\": \"./logs\",\n",
    "        \"log_freq\": 1000,\n",
    "        \"avg_length\": 10000,\n",
    "        \"env_name\": 'Breakout-v0',\n",
    "        \"processor\": AtariProcessor(84, 84),\n",
    "        \"optimizer\":\"rmsp\",\n",
    "}\n",
    "\n",
    "env = gym.make('Breakout-v0')\n",
    "tf.reset_default_graph()\n",
    "nec = NEC(env, conf, controller_cls=MLPModel, diff_memory_cls=HashDND)\n",
    "nec.fit(int(1e7), render_freq=None, save_video_path=\"./videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nec.store_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "x_val = np.random.randint(0, 2, (3, 4), dtype=bool)\n",
    "x = tf.Variable(x_val)\n",
    "y = tf.where(x)\n",
    "tf.global_variables_initializer().run()\n",
    "z = y.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 3],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 ** 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
