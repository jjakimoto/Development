{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDEA\n",
    "* Multi-Task RL, e.g., optimize both drawdown and returns\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "## Deep Reinforcement Learning in High Frequency Trading\n",
    "* https://arxiv.org/pdf/1809.01506.pdf\n",
    "* Ensemble three one-vs-one MLP, each of which predict binary labels\n",
    "* Ensemble weight keeps updating through Reinforcement Learning\n",
    "* 500 trailing tick history and label for 100 forward\n",
    "* MLP has (10, 10) hidden layers\n",
    "* Accuracy will be around 70 %\n",
    "* Only when confidence level is over the threshold, execute trading\n",
    "* The perticipant percentage is around 10%\n",
    "\n",
    "## A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem\n",
    "* https://arxiv.org/pdf/1706.10059.pdf\n",
    "* Use Close, High, and Low as input\n",
    "* Use replay memory and portfolio vector memory for training\n",
    "* Use 50 trailing history\n",
    "\n",
    "## Deep Hedging\n",
    "* https://arxiv.org/pdf/1802.03042.pdf\n",
    "* Find the hedging strategy through Neural Network\n",
    "* Optimize convex measure\n",
    "* Show the experiments over numerically sampled Heston model\n",
    "* Use (2d, d+15, d+ 15, d) MLP Model, where d is the number of assets\n",
    "\n",
    "## Agent Inspired Trading Using Recurrent Reinforcement Learning and LSTM Neural Networks\n",
    "* https://arxiv.org/pdf/1707.07338.pdf\n",
    "* Direct reinforcement(Not required value function)\n",
    "* Recurrent Reinforcement Learning using LSTM or RNN\n",
    "* Optimize Sharp Ratio or Downside Deviation\n",
    "* Input:\n",
    "    * Trailing history of price difference\n",
    "    * Previous position\n",
    "    * Bias parameter\n",
    "* Previous position is fed into the input of the output layer\n",
    "* Validation is done on a single period, which is not trustable\n",
    "\n",
    "\n",
    "## QLBS: Q-Learner in the Black-Scholes(-Merton) Worlds\n",
    "* https://arxiv.org/pdf/1712.04609.pdf\n",
    "* Derive pricing through Q-Learning format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
