{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_ = {}\n",
    "\n",
    "for filename in os.listdir(\"data/Top100Cryptos/\"):\n",
    "    path = os.path.join(\"data/Top100Cryptos/\", filename)\n",
    "    try:\n",
    "        name = filename.split(\".\")[0]\n",
    "        data_[name] = pd.read_csv(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "num_data = []\n",
    "for name in data_.keys():\n",
    "    num_data.append(data_[name].shape[0])\n",
    "name_list = np.array(list(data_.keys()))[np.argsort(num_data)[::-1]]\n",
    "big_names = name_list[:10]\n",
    "\n",
    "data = dict()\n",
    "for name in big_names:\n",
    "    data[name] = data_[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_time(t):\n",
    "    m = {\n",
    "        'Jan' : \"01\",\n",
    "        'Feb' : \"02\",\n",
    "        'Mar' : \"03\",\n",
    "        'Apr' : \"04\",\n",
    "        'May' : \"05\",\n",
    "        'Jun' : \"06\",\n",
    "        'June' : \"06\",\n",
    "        'Jul' : \"07\",\n",
    "        'Aug' : \"08\",\n",
    "        'Sep' : \"09\", \n",
    "        'Oct' : \"10\",\n",
    "        'Nov' : \"11\",\n",
    "        'Dec' : \"12\"\n",
    "    }\n",
    "    t_list = t.replace(\",\", \"\").split()\n",
    "    t_list[0] = m[t_list[0]]\n",
    "    return \"-\".join([t_list[2], t_list[0], t_list[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rltensor.environments.core import Env\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class TradeEnvironment(Env):\n",
    "    \"\"\"Environment only for close prices\"\"\"\n",
    "    def __init__(self, data, start=None, end=None, add_cash=True, keys=[\"Close\", \"Open\", \"High\"]):\n",
    "        self.keys = keys\n",
    "        time_index = set()\n",
    "        impute_data = {}\n",
    "        data = deepcopy(data)\n",
    "        for key, val in data.items():\n",
    "            dates = val[\"Date\"].values\n",
    "            dates = [convert_time(d) for d in dates]\n",
    "            impute_data[key] = dict(time_range=(dates[-1], dates[0]),\n",
    "                                    impute_val=(val.iloc[-1], val.iloc[0]))\n",
    "            data[key].index = dates\n",
    "            time_index = time_index.union(set(dates))\n",
    "        self.time_index = sorted(list(time_index))\n",
    "        if add_cash:\n",
    "            val = np.ones(len(self.time_index))\n",
    "            cash_df = pd.DataFrame({\"Open\" : val,\n",
    "                                    \"High\" : val,\n",
    "                                    \"Low\" : val,\n",
    "                                    \"Close\" : val,\n",
    "                                    \"Volume\" : val},\n",
    "                                   index=self.time_index)\n",
    "            key = \"Cash\"\n",
    "            data[key] = cash_df\n",
    "            impute_data[key] = dict(time_range=(self.time_index[-1], self.time_index[0]),\n",
    "                                    impute_val=(cash_df.iloc[-1], cash_df.iloc[0]))\n",
    "        self.impute_data  = impute_data\n",
    "        if start is None:\n",
    "            self.start = self.time_index[0]\n",
    "        else:\n",
    "            self.start = min(start, self.time_index[0])\n",
    "        if end is None:\n",
    "            self.end = self.time_index[-1]\n",
    "        else:\n",
    "            self.end = max(end, self.time_index[-1])\n",
    "        self.data = data\n",
    "        self.symbols = list(data.keys())\n",
    "        self.num_stocks = len(self.symbols)\n",
    "        self.current_time = self.start\n",
    "        self.current_step = 0\n",
    "        # Use for calculate return\n",
    "        self.prev_states = self._get_bar()\n",
    "\n",
    "    def _reset(self):\n",
    "        self.current_time = self.start\n",
    "        self.cirrent_step = 0\n",
    "        current_bars = self._get_bar()\n",
    "        observation = self._get_observation(current_bars)\n",
    "        return observation\n",
    "\n",
    "    def _step(self, action):\n",
    "        current_bars = self._get_bar()\n",
    "        returns = []\n",
    "        for symbol in self.symbols:\n",
    "            returns.append(current_states[symbol][\"Close\"] / self.prev_states[symbol][\"Close\"] - 1)\n",
    "        returns = np.array(returns)\n",
    "        # Update status\n",
    "        self.prev_states = deepcopy(current_states)\n",
    "        self._update_time()\n",
    "        observation = self._get_observation(current_bars)\n",
    "        terminal = False\n",
    "        reward = np.sum(returns * action)\n",
    "        info = {}\n",
    "        info[\"returns\"] = returns\n",
    "        return observation, terminal, reward, info\n",
    "    \n",
    "    def _get_observation(self, bars):\n",
    "        observation = [] \n",
    "        for symbol in self.symbols:\n",
    "            observation.append([bars[symbol][key] for key in self.keys])\n",
    "        return np.array(observation)\n",
    "            \n",
    "    def _update_time(self):\n",
    "        index = self.time_index.index(self.current_time)\n",
    "        self.current_time = self.time_index[index + 1]\n",
    "        self.current_step += 1\n",
    "        \n",
    "    def _get_bar(self):\n",
    "        bar = {}\n",
    "        for symbol in self.symbols:\n",
    "            min_t = self.impute_data[symbol][\"time_range\"][0]\n",
    "            max_t = self.impute_data[symbol][\"time_range\"][1]\n",
    "            if (min_t <= self.current_time) and (max_t >= self.current_time):\n",
    "                if self.current_time in self.data[symbol].index:\n",
    "                    bar[symbol] = self.data[symbol].loc[self.current_time]\n",
    "                else:\n",
    "                    bar[symbol] = deepcopy(self.impute_bar[symbol])\n",
    "            elif min_t > self.current_time:\n",
    "                bar[symbol] = self.impute_data[symbol][\"impute_val\"][0]\n",
    "            else:\n",
    "                bar[symbol] = self.impute_data[symbol][\"impute_val\"][1]\n",
    "        # Keep value for imputation\n",
    "        self.impute_bar = deepcopy(bar)\n",
    "        return bar\n",
    "    \n",
    "    @property\n",
    "    def action_dim(self):\n",
    "        return self.num_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_stats(log_return, accumulated_pv, peak_pv):\n",
    "    accumulated_pv *= np.exp(log_return)\n",
    "    if peak_pv < accumulated_pv:\n",
    "        peak_pv = accumulated_pv\n",
    "    draw_down = (peak_pv - accumulated_pv) / peak_pv\n",
    "    return_ = np.exp(log_return) - 1.\n",
    "    return return_, accumulated_pv, peak_pv, draw_down\n",
    "\n",
    "def calc_sharp_ratio(returns, bench_mark=0, eps=1e-6):\n",
    "    var = np.var(returns)\n",
    "    mean = np.mean(returns)\n",
    "    return (mean - bench_mark) / (np.sqrt(var) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-d3778a9180f2>, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-d3778a9180f2>\"\u001b[0;36m, line \u001b[0;32m50\u001b[0m\n\u001b[0;31m    *args, **kwargs)'test.final_value',\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import time\n",
    "from six.moves import xrange\n",
    "from tensorforce.execution import Runner\n",
    "\n",
    "\n",
    "class TradeRunner(Runner):\n",
    "    def __init__(self, agent, env, env_name=\"trading\",\n",
    "                 tensorboard_dir=\"./logs\", scalar_summary_tags=None,\n",
    "                 histogram_summary_tags=None, load_file_path=None,\n",
    "                 *args, **kwargs):\n",
    "\n",
    "        if scalar_summary_tags is None:\n",
    "            scalar_summary_tags = [\n",
    "                'average.loss',\n",
    "                'average.returns',\n",
    "                'drawdown',\n",
    "                'cumulative_returns',\n",
    "                'episode.final_value',\n",
    "                'episode.max_returns',\n",
    "                'episode.min_returns',\n",
    "                'episode.avg_returns',\n",
    "                'episode.maximum_drawdowns',\n",
    "                'episode.sharp_ratio',\n",
    "                'training.learning_rate',\n",
    "                'training.num_step_per_sec',\n",
    "                'training.time',\n",
    "                'test.cumulative_returns',\n",
    "                'test.drawdowns',\n",
    "                'test.final_value',\n",
    "                'test.maximum_drawdowns',\n",
    "                'test.sharp_ratio',]\n",
    "        self.scalar_summary_tags = scalar_summary_tags\n",
    "\n",
    "        if histogram_summary_tags is None:\n",
    "            histogram_summary_tags = ['episode.returns', 'test.returns']\n",
    "            for i in range(env.action_dim):\n",
    "                histogram_summary_tags.append(\"episode.action_{}\".format(i))\n",
    "                histogram_summary_tags.append(\"test.action_{}\".format(i))\n",
    "        \n",
    "        super(TradeRunner, self).__init__(agent=agent, env=env,\n",
    "                                          env_name=env_name,\n",
    "                                          tensorboard_dir=tensorboard_dir,\n",
    "                                          scalar_summary_tags=scalar_summary_tags,\n",
    "                                          histogram_summary_tags=histogram_summary_tags,\n",
    "                                          load_file_path=load_file_path,\n",
    "                                          *args, **kwargs)\n",
    "        \n",
    "        \n",
    "    def run(\n",
    "        self,\n",
    "        timesteps=None,\n",
    "        episodes=None,\n",
    "        max_episode_timesteps=None,\n",
    "        deterministic=False,\n",
    "        episode_finished=None,\n",
    "        init_pv=100.,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Runs the agent on the environment.\n",
    "\n",
    "        Args:\n",
    "            timesteps: Number of timesteps\n",
    "            episodes: Number of episodes\n",
    "            max_episode_timesteps: Max number of timesteps per episode\n",
    "            deterministic: Deterministic flag\n",
    "            episode_finished: Function handler taking a `Runner` argument and returning a boolean indicating\n",
    "                whether to continue execution. For instance, useful for reporting intermediate performance or\n",
    "                integrating termination conditions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Keep track of episode reward and episode length for statistics.\n",
    "        self.start_time = time.time()\n",
    "\n",
    "        self.agent.reset()\n",
    "\n",
    "        self.episode = self.agent.episode\n",
    "        if episodes is not None:\n",
    "            episodes += self.agent.episode\n",
    "\n",
    "        self.timestep = self.agent.timestep\n",
    "        if timesteps is not None:\n",
    "            timesteps += self.agent.timestep\n",
    "            \n",
    "        self.sp_list = []\n",
    "        self.mmd_list = []\n",
    "        self.pv_list = []\n",
    "        self.accumulated_pvs_list = []\n",
    "        self.draw_downs_list = []\n",
    "\n",
    "        while True:\n",
    "            episode_start_time = time.time()\n",
    "\n",
    "            self.agent.reset()\n",
    "            state = self.environment.reset()\n",
    "            accumulated_pv = init_pv\n",
    "            peak_pv = init_pv\n",
    "            self.accumulated_pvs = [accumulated_pv]\n",
    "            draw_downs = [0.]\n",
    "            returns = [0.]\n",
    "            self.episode_timestep = 0\n",
    "\n",
    "            while True:\n",
    "                action = self.agent.act(states=state, deterministic=deterministic)\n",
    "                log_return = 0\n",
    "                for repeat in xrange(self.repeat_actions):\n",
    "                    state, terminal, step_reward = self.environment.execute(actions=action)\n",
    "                    log_return += np.log(1. + step_reward)\n",
    "                    if terminal:\n",
    "                        break\n",
    "\n",
    "                if max_episode_timesteps is not None and self.episode_timestep >= max_episode_timesteps:\n",
    "                    terminal = True\n",
    "\n",
    "                self.agent.observe(terminal=terminal, reward=log_return)\n",
    "\n",
    "                self.episode_timestep += 1\n",
    "                self.timestep += 1\n",
    "                return_, accumulated_pv, peak_pv, draw_down = calc_stats(log_return, accumulated_pv, peak_pv)\n",
    "                returns.append(return_)\n",
    "                self.accumulated_pvs.append(accumulated_pv)\n",
    "                draw_downs.append(draw_down)\n",
    "                \n",
    "                if terminal or self.agent.should_stop():  # TODO: should_stop also termina?\n",
    "                    break\n",
    "                    \n",
    "            time_passed = time.time() - episode_start_time\n",
    "\n",
    "            self.pv_list.append(self.accumulated_pvs[-1])\n",
    "            self.mmd_list.append(np.max(draw_downs))\n",
    "            self.sp_list.append(calc_sharp_ratio(returns))\n",
    "            self.accumulated_pvs_list.append(self.accumulated_pvs)\n",
    "            self.draw_downs_list.append(draw_downs)\n",
    "            \n",
    "            self.episode_timesteps.append(self.episode_timestep)\n",
    "            self.episode_times.append(time_passed)\n",
    "\n",
    "            self.episode += 1\n",
    "\n",
    "            if episode_finished and not episode_finished(self) or \\\n",
    "                    (episodes is not None and self.agent.episode >= episodes) or \\\n",
    "                    (timesteps is not None and self.agent.timestep >= timesteps) or \\\n",
    "                    self.agent.should_stop():\n",
    "                # agent.episode / agent.timestep are globally updated\n",
    "                break\n",
    "\n",
    "        self.agent.close()\n",
    "        self.environment.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
