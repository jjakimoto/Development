{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"data/cornell movie-dialogs corpus/movie_lines.txt\", \"r\",encoding='utf-8', errors='ignore')\n",
    "data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.metrics import edit_distance\n",
    "import re\n",
    "import enchant\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "replacement_patterns = [\n",
    "    (r'won\\'t', 'will not'),\n",
    "    (r'can\\'t', 'cannot'),\n",
    "    (r'i\\'m', 'i am'),\n",
    "    (r'ain\\'t', 'is not'),\n",
    "    (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "    (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "    (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "    (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "    (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "    (r'(\\w+)\\'d', '\\g<1> would')\n",
    "]\n",
    "\n",
    "class RegexpReplacer(object):\n",
    "    def __init__(self, patterns=replacement_patterns):\n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "        \n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            s = re.sub(pattern, repl, s)\n",
    "        return s\n",
    "    \n",
    "\n",
    "class SpellingReplacer(object):\n",
    "    def __init__(self, dict_name=\"en\", max_dist=2, min_word_length=1):\n",
    "        self.spell_dict = enchant.Dict(dict_name)\n",
    "        self.max_dist = max_dist\n",
    "        self.min_word_length = min_word_length\n",
    "        \n",
    "    def replace(self, word):\n",
    "        if self.spell_dict.check(word):\n",
    "            return word\n",
    "        if len(word) < self.min_word_length:\n",
    "            return word\n",
    "        suggestions = self.spell_dict.suggest(word)\n",
    "        if suggestions and edit_distance(word, suggestions[0]) <= self.max_dist:\n",
    "            return suggestions[0]\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "class AntonymReplacer(object):\n",
    "    def replace(self, word, pos=None):\n",
    "        antonyms = set()\n",
    "        for syn in wordnet.synsets(word, pos=pos):\n",
    "            for lemma in syn.lemmas():\n",
    "                for antonym in lemma.antonyms():\n",
    "                    antonyms.add(antonym.name())\n",
    "        if len(antonyms) == 1:\n",
    "            return antonyms.pop()\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def replace_negations(self, sent):\n",
    "        i, length = 0, len(sent)\n",
    "        words = []\n",
    "        while i < length:\n",
    "            word = sent[i]\n",
    "            if word == \"not\" and i+1 < length:\n",
    "                ant = self.replace(sent[i+1])\n",
    "                if ant:\n",
    "                    words.append(ant)\n",
    "                    i += 2\n",
    "                    continue\n",
    "            words.append(word)\n",
    "            i += 1\n",
    "        return words\n",
    "\n",
    "\n",
    "class RepeatReplacer(object):\n",
    "    def __init__(self):\n",
    "        self.repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "        self.repl = r'\\1\\2\\3'\n",
    "        \n",
    "    def replace(self, word):\n",
    "        if wordnet.synsets(word):\n",
    "            return word\n",
    "        repl_word = self.repeat_regexp.sub(self.repl, word)\n",
    "        if repl_word != word:\n",
    "            return self.replace(repl_word)\n",
    "        else:\n",
    "            return repl_word\n",
    "        \n",
    "def clean_text(text, replace_neg=False, use_unknown=False, dict_name=\"en\", max_dist=2, min_word_length=1):\n",
    "    rep = RepeatReplacer()\n",
    "    ant = AntonymReplacer()\n",
    "    reg = RegexpReplacer()\n",
    "    spell = SpellingReplacer(dict_name, max_dist, min_word_length)\n",
    "    # Get rid of some abbreviations\n",
    "    text = reg.replace(text)\n",
    "    words = word_tokenize(text)\n",
    "    if replace_neg:\n",
    "        words = ant.replace_negations(words)\n",
    "    words = [spell.replace(word) for word in words]\n",
    "    if not use_unknown:\n",
    "        spell_dict = enchant.Dict(dict_name)\n",
    "        words = [word for word in words if spell_dict.check(word)]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def clean_movie_data(data):\n",
    "    pattern = \" \\+\\+\\+\\$\\+\\+\\+ u[0-9] \\+\\+\\+\\$\\+\\+\\+ m[0-9] \\+\\+\\+\\$\\+\\+\\+ \\w* \\+\\+\\+\\$\\+\\+\\+ \"\n",
    "    lines = re.split(pattern, data.lower())\n",
    "    line_words = []\n",
    "    for line in tqdm(lines):\n",
    "        try:\n",
    "            cleaned_line = clean_text(line, max_dist=0)\n",
    "            if len(cleaned_line) >= 1:\n",
    "                line_words.append(cleaned_line)\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "    return line_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.5 ms, sys: 46.9 ms, total: 109 ms\n",
      "Wall time: 322 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "# texts = clean_movie_data(data)\n",
    "df = pd.read_csv(\"data/All-seasons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>You guys, you guys! Chef is going away. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>Going away? For how long?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Forever.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Chef</td>\n",
       "      <td>I'm sorry boys.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Chef said he's been bored, so he joining a gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Season Episode Character                                               Line\n",
       "0     10       1      Stan         You guys, you guys! Chef is going away. \\n\n",
       "1     10       1      Kyle                        Going away? For how long?\\n\n",
       "2     10       1      Stan                                         Forever.\\n\n",
       "3     10       1      Chef                                  I'm sorry boys.\\n\n",
       "4     10       1      Stan  Chef said he's been bored, so he joining a gro..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"Line\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['You guys, you guys! Chef is going away. \\n',\n",
       "       'Going away? For how long?\\n', 'Forever.\\n', \"I'm sorry boys.\\n\",\n",
       "       \"Chef said he's been bored, so he joining a group called the Super Adventure Club. \\n\",\n",
       "       'Wow!\\n',\n",
       "       'Chef?? What kind of questions do you think adventuring around the world is gonna answer?!\\n',\n",
       "       \"What's the meaning of life? Why are we here?\\n\",\n",
       "       \"I hope you're making the right choice.\\n\",\n",
       "       \"I'm gonna miss him.  I'm gonna miss Chef and I...and I don't know how to tell him! \\n\"], dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def batch(inputs, max_sequence_length=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs:\n",
    "            list of sentences (integer lists)\n",
    "        max_sequence_length:\n",
    "            integer specifying how large should `max_time` dimension be.\n",
    "            If None, maximum sequence length would be used\n",
    "    \n",
    "    Outputs:\n",
    "        inputs_time_major:\n",
    "            input sentences transformed into time-major matrix \n",
    "            (shape [max_time, batch_size]) padded with 0s\n",
    "        sequence_lengths:\n",
    "            batch-sized list of integers specifying amount of active \n",
    "            time steps in each input sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    sequence_lengths = [len(seq) for seq in inputs]\n",
    "    batch_size = len(inputs)\n",
    "    \n",
    "    if max_sequence_length is None:\n",
    "        max_sequence_length = max(sequence_lengths)\n",
    "    sequence_lengths = [min(length, max_sequence_length) for length in sequence_lengths]\n",
    "    \n",
    "    inputs_batch_major = np.zeros(shape=[batch_size, max_sequence_length], dtype=np.int32) # == PAD\n",
    "    \n",
    "    for i, seq in enumerate(inputs):\n",
    "        seq = seq[:max_sequence_length]\n",
    "        for j, element in enumerate(seq):\n",
    "            inputs_batch_major[i, j] = element\n",
    "\n",
    "    return inputs_batch_major, sequence_lengths\n",
    "\n",
    "\n",
    "def random_sequences(length_from, length_to,\n",
    "                     vocab_lower, vocab_upper,\n",
    "                     batch_size):\n",
    "    \"\"\" Generates batches of random integer sequences,\n",
    "        sequence length in [length_from, length_to],\n",
    "        vocabulary in [vocab_lower, vocab_upper]\n",
    "    \"\"\"\n",
    "    if length_from > length_to:\n",
    "            raise ValueError('length_from > length_to')\n",
    "\n",
    "    def random_length():\n",
    "        if length_from == length_to:\n",
    "            return length_from\n",
    "        return np.random.randint(length_from, length_to + 1)\n",
    "    \n",
    "    while True:\n",
    "        yield [\n",
    "            np.random.randint(low=vocab_lower,\n",
    "                              high=vocab_upper,\n",
    "                              size=random_length()).tolist()\n",
    "            for _ in range(batch_size)\n",
    "        ]\n",
    "        \n",
    "def get_length(sequence):\n",
    "    \"\"\"Get length of each instance in batch\n",
    "    \n",
    "    Args:\n",
    "        sequence: tensor, shape = (batch_size, length)\n",
    "            or shape = (batch_size, length) + shape\n",
    "            \n",
    "    Returns:\n",
    "        tensor: shape = (None,), length of each instance\n",
    "    \"\"\"\n",
    "    shape = sequence.get_shape().as_list()\n",
    "    if len(shape) < 2:\n",
    "        used = tf.sign(tf.abs(sequence))\n",
    "    else:\n",
    "        reduction_indices = list(range(2, len(shape)))\n",
    "        used = tf.sign(tf.reduce_max(tf.abs(sequence),\n",
    "                       reduction_indices=reduction_indices))\n",
    "    length = tf.reduce_sum(used, reduction_indices=1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from hedgeable_ai.models.nn import BaseModel, get_shape, get_length\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from hedgeable_ai.models.nn.params import nn_is_logit\n",
    "from hedgeable_ai.models.nn import BaseNN, get_shape\n",
    "\n",
    "from hedgeable_ai.models.nn.rnn import get_cell\n",
    "\n",
    "\n",
    "class DialogueAgent(BaseNN):\n",
    "    def __init__(self, processor, maxlen=None, conf=None, *args, **kwargs):\n",
    "        self.emb_size = 300\n",
    "        # add padding index 0 and index 1 for <eos>\n",
    "        self.vocab_size = processor.vocab_size + 2\n",
    "        self.maxlen = maxlen\n",
    "        super().__init__(processor=processor, conf=conf, *args, **kwargs)\n",
    "        \n",
    "    def _build_graph(self):\n",
    "        \"\"\"Build tensorflow graph\n",
    "        \n",
    "        Note:\n",
    "            You build graphs for output and input, which will be used \n",
    "            for training and prediction.\n",
    "        \"\"\"\n",
    "        self.encoder_input = tf.placeholder(tf.int32, shape=(None, None), name=\"encoder_input\")\n",
    "        self.encoder_input_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_input_length')\n",
    "        self.decoder_target = tf.placeholder(tf.int32, shape=(None, None), name=\"decoder_target\")\n",
    "        encoder_length = get_length(self.encoder_input)\n",
    "        self.encoder_length = encoder_length\n",
    "        decoder_length = get_length(self.decoder_target)\n",
    "        # Encoder\n",
    "        encoder_cell = get_cell(self.conf[\"model\"])\n",
    "        embeddings = tf.Variable(tf.random_uniform([self.vocab_size, self.emb_size], -1.0, 1.0, dtype=tf.float32))\n",
    "        encoder_input_embedded = tf.nn.embedding_lookup(embeddings, self.encoder_input)\n",
    "        encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "            encoder_cell, encoder_input_embedded, sequence_length=encoder_length, dtype=tf.float32, \n",
    "            time_major=False, scope=\"encoder\")\n",
    "        \n",
    "        decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "        decoder_outputs = decoder_outputs_ta.stack()\n",
    "        decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "        decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_output_size))\n",
    "        decoder_logits_flat = tf.matmul(decoder_outputs_flat, W)\n",
    "        decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, self.vocab_size))\n",
    "        decoder_logits = tf.transpose(decoder_logits, [1, 0, 2])\n",
    "        self.decoder_prediction = tf.argmax(decoder_logits, 2)\n",
    "        self.decoder_logits = decoder_logits\n",
    "\n",
    "        # Decoder\n",
    "        decoder_cell = get_cell(self.conf[\"model\"])\n",
    "        batch_size, encoder_max_time = tf.unstack(tf.shape(self.encoder_input))\n",
    "        decoder_output_size = self._get_output_size(self.conf[\"model\"])\n",
    "        # We use a decoder length 10 words longer than encoder\n",
    "        max_decoder_length = self.encoder_input_length + 6\n",
    "        self.max_decoder_length = max_decoder_length\n",
    "        W = tf.Variable(tf.random_uniform([decoder_output_size, self.vocab_size], -1, 1), dtype=tf.float32)\n",
    "        b = tf.Variable(tf.zeros([self.vocab_size]), dtype=tf.float32)\n",
    "        # Prepare for padding and EOS\n",
    "        eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "        pad_time_slice = tf.zeros([batch_size],  dtype=tf.int32, name='PAD')\n",
    "        eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "        pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)\n",
    "        \n",
    "        def loop_fn_initial():\n",
    "            initial_elements_finished = (0 >= max_decoder_length)\n",
    "            initial_input = eos_step_embedded\n",
    "            initial_cell_state = encoder_final_state\n",
    "            initial_cell_output  = None\n",
    "            initial_loop_state = None\n",
    "            return (initial_elements_finished,\n",
    "                initial_input,\n",
    "                initial_cell_state,\n",
    "                initial_cell_output,\n",
    "                initial_loop_state)\n",
    "        \n",
    "        def loop_fn_transition(time, previous_output,  previous_state, previous_loop_state):\n",
    "            output_logits = tf.matmul(previous_output, W)\n",
    "            prediction  = tf.argmax(output_logits, axis=-1)\n",
    "            \n",
    "            def get_next_input():\n",
    "                # output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "                next_input = tf.nn.embedding_lookup(embeddings,  prediction)\n",
    "                return next_input\n",
    "            \n",
    "            prediciton_finished = (prediction <= tf.ones_like(prediction))\n",
    "            elements_finished = (time >= max_decoder_length)\n",
    "            finished = tf.logical_or(elements_finished, prediciton_finished)\n",
    "            finished = tf.reduce_all(finished)\n",
    "            input_ = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "            state  = previous_state\n",
    "            output = previous_output\n",
    "            loop_state = None\n",
    "            return (elements_finished, \n",
    "                input_,\n",
    "                state,\n",
    "                output,\n",
    "                loop_state)\n",
    "        \n",
    "        def loop_fn(time, previous_output, previous_state,  previous_loop_state):\n",
    "            if previous_state is None:\n",
    "                assert previous_output is None and previous_state is None\n",
    "                return loop_fn_initial()\n",
    "            else:\n",
    "                return loop_fn_transition(time, previous_output, previous_state,  previous_loop_state)\n",
    "        \n",
    "        decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "        decoder_outputs = decoder_outputs_ta.stack()\n",
    "        decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "        decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_output_size))\n",
    "        decoder_logits_flat = tf.matmul(decoder_outputs_flat, W)\n",
    "        decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, self.vocab_size))\n",
    "        decoder_logits = tf.transpose(decoder_logits, [1, 0, 2])\n",
    "        self.decoder_prediction = tf.argmax(decoder_logits, 2)\n",
    "        self.decoder_logits = decoder_logits\n",
    "        \n",
    "        # Optimization\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=tf.one_hot(self.decoder_target, depth=self.vocab_size, dtype=tf.float32),\n",
    "            logits=decoder_logits)\n",
    "        self.loss = tf.reduce_mean(cross_entropy)\n",
    "        self.learning_rate_op = self._get_learning_rate()\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self.optimizer = self._get_optimizer(self.optimizer_name, self.learning_rate_op, self.optimizer_conf)\n",
    "            self.train_step = self.optimizer.minimize(self.loss)\n",
    "        \n",
    "    def _optimize(self, batch_X, batch_y, *args, **kwargs):\n",
    "        batch_X = [x[::-1] for x in batch_X[0]]\n",
    "        batch_X, Xlen = batch(batch_X, self.maxlen)\n",
    "        length = np.max(Xlen) + 6\n",
    "        batch_y = self._batch_padding(batch_y, length)\n",
    "        \n",
    "        feed_dict = {self.encoder_input: batch_X,\n",
    "                     self.decoder_target: batch_y,\n",
    "                     self.encoder_input_length: Xlen,\n",
    "                     self.training: True}\n",
    "        # print(self.sess.run(self.max_decoder_length, feed_dict=feed_dict))\n",
    "        _, loss = self.sess.run([self.train_step, self.loss], feed_dict=feed_dict)\n",
    "        return loss\n",
    "    \n",
    "    def _get_output_size(self, conf):\n",
    "        if isinstance(conf, list) or isinstance(conf, tuple):\n",
    "            x = conf[-1]\n",
    "        else:\n",
    "            x = conf\n",
    "        return x[\"num_units\"]\n",
    "    \n",
    "    def generate_sentences(self, sentences):\n",
    "        X = [self.processor.encode(sentence) for sentence in sentences]\n",
    "        X = [x_[::-1] for x_ in X]\n",
    "        X, Xlen = batch(X, self.maxlen)\n",
    "        feed_dict = {self.encoder_input: X,\n",
    "                     self.encoder_input_length: Xlen,\n",
    "                     self.training: False}\n",
    "        word_idx = self.sess.run(self.decoder_prediction, feed_dict=feed_dict)\n",
    "        print(word_idx)\n",
    "        return [self.processor.decode(i) for i in word_idx]\n",
    "    \n",
    "    def _batch_padding(self, batch, length):\n",
    "        EOS = 1\n",
    "        PAD = 0\n",
    "        padded_batch = []\n",
    "        for x in batch:\n",
    "            x = list(x)\n",
    "            if len(x) > length:\n",
    "                x = x[:length]\n",
    "            elif len(x) < length:\n",
    "                x.append(EOS)\n",
    "            while len(x) < length:\n",
    "                x.append(PAD)\n",
    "            padded_batch.append(x)\n",
    "        return np.array(padded_batch)\n",
    "    \n",
    "    def attention(self, query, attentions=None):\n",
    "        if attentions is None:\n",
    "            return query\n",
    "        else:\n",
    "            query = tf.expand_dims(query, 1)\n",
    "            score = tf.matmul(query, attentions, transpose_b=True)\n",
    "        score = tf.squeeze(score, [1])\n",
    "        alignments = tf.nn.softmax(score)\n",
    "        return alignments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: params/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 1/100 [00:06<11:21,  6.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 2/100 [00:23<16:10,  9.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 3/100 [00:42<20:27, 12.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 4/100 [00:57<21:02, 13.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 5/100 [01:17<24:18, 15.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 6/100 [01:34<24:47, 15.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 7/100 [01:54<26:28, 17.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 8/100 [02:09<25:22, 16.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 9/100 [02:25<24:28, 16.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 10/100 [02:41<24:23, 16.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|█         | 11/100 [03:02<26:07, 17.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 12/100 [03:18<25:20, 17.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 13/100 [03:36<25:01, 17.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 14/100 [03:53<24:39, 17.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 15/100 [04:13<25:36, 18.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 16/100 [04:29<24:29, 17.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 17/100 [04:46<23:57, 17.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 18/100 [05:02<23:17, 17.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|█▉        | 19/100 [05:23<24:36, 18.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 20/100 [05:41<23:53, 17.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|██        | 21/100 [06:01<24:45, 18.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 22/100 [06:17<23:19, 17.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 23/100 [06:33<22:04, 17.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 24/100 [06:52<22:44, 17.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 25/100 [07:08<21:30, 17.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 26/100 [07:23<20:24, 16.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 27/100 [07:39<20:02, 16.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 28/100 [07:58<20:44, 17.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▉       | 29/100 [08:15<20:21, 17.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: params/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "conf = {\n",
    "        \"learning_rate\": 0.5,\n",
    "        \"learning_rate_minimum\": 0.5,\n",
    "        \"learning_rate_decay\": 0.9,\n",
    "        \"learning_rate_decay_step\": 20,\n",
    "        \"batch_size\": 64,\n",
    "        \"model_dir\": \"./logs\",\n",
    "        \"load_file_path\": None,\n",
    "        \"save_file_path\": None,\n",
    "        \"log_freq\": 1,\n",
    "        \"model\":{\"name\":\"lstm\", \"num_units\":256},\n",
    "}\n",
    "\n",
    "tf.reset_default_graph()\n",
    "agent = DialogueAgent(processor, maxlen=30, conf=conf)\n",
    "train_X = processor.data[:-1]\n",
    "train_y = []\n",
    "for y in processor.data[1:]:\n",
    "    list_y = list(y)\n",
    "    list_y.append(1)\n",
    "    train_y.append(np.array(list_y))\n",
    "train_y = np.array(train_y)\n",
    "agent.fit(train_X[:100], train_y[:100], num_epochs=100, batch_bar=False, log_freq=1, batch_log_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17496     1     1    36     1     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   36     1     1     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [ 7949  7949   899     1 17914     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [17877  7184     1    36     1     1     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [17877     1  8492     1    36     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [17496     1     1     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [17496  8492  8492     1     1 17914     1     1     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [ 7949  7949  7949     1 17914    36     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [ 7949 17914    36     1     1     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [14077  9934  5874     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['what', '.'],\n",
       " ['.'],\n",
       " ['i', 'i', 'am', 'you'],\n",
       " ['yeah', 'guys', '.'],\n",
       " ['yeah', 'is', '.'],\n",
       " ['what'],\n",
       " ['what', 'is', 'is', 'you'],\n",
       " ['i', 'i', 'i', 'you', '.'],\n",
       " ['i', 'you', '.'],\n",
       " ['shreds', 'misses', 'fatal']]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tilde = [(\"\").join(text) for text in texts[:10]]\n",
    "agent.generate_sentences(texts_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You guys, you guys! Chef is going away. \\n',\n",
       " 'Going away? For how long?\\n',\n",
       " 'Forever.\\n',\n",
       " \"I'm sorry boys.\\n\",\n",
       " \"Chef said he's been bored, so he joining a group called the Super Adventure Club. \\n\",\n",
       " 'Wow!\\n',\n",
       " 'Chef?? What kind of questions do you think adventuring around the world is gonna answer?!\\n',\n",
       " \"What's the meaning of life? Why are we here?\\n\",\n",
       " \"I hope you're making the right choice.\\n\",\n",
       " \"I'm gonna miss him.  I'm gonna miss Chef and I...and I don't know how to tell him! \\n\"]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([996, 270, 657]), array([ 996,  270, 1018]),\n",
       "       array([489, 476, 904,   2]), array([873, 675]),\n",
       "       array([550, 515, 403,   2]), array([1140]),\n",
       "       array([ 675, 1150,   57,  641, 1018,  544,  483, 1018,  552,    2]),\n",
       "       array([650]),\n",
       "       array([ 489,   42,  527,    2, 1150,  536,  483,  912, 1150,  523,   91,\n",
       "       1002,  727,   45, 1150,  270,  657,  536,  483, 1018,  793]),\n",
       "       array([ 555,  633,  339,  668, 1097,  711]),\n",
       "       array([ 989,  805, 1150,    2]), array([1105,  411,  949]),\n",
       "       array([ 489,  352, 1150, 1139,  396, 1018,  989,  411,  949,  308,    2]),\n",
       "       array([ 986,  404,  491,  489,  428, 1018,  446,  680,  620,  943,   12,\n",
       "       1151,  185,    3]),\n",
       "       array([ 597,    2, 1002,  302,    3,   76,    2,  489,   42,  555,  124,\n",
       "        634,    2]),\n",
       "       array([1105,  217]), array([ 270, 1150,  560, 1018, 1002,  217]),\n",
       "       array([650,   3]),\n",
       "       array([ 992,  843,  491, 1150,  403,   50,  554, 1150,   57,  569,  555,\n",
       "         44,  324,  678,    6,    2]),\n",
       "       array([1150,   41,   93, 1002,  860]), array([143]),\n",
       "       array([ 992,  987,  515,   33, 1150,  428, 1018,  842,    2]),\n",
       "       array([1100,  650,    3]),\n",
       "       array([1150,  645, 1088, 1018,  403,  694, 1125,  255, 1150]),\n",
       "       array([ 489, 1091]),\n",
       "       array([ 489,  570,  365, 1150,   78,   68,  989,  709,  143, 1150,   41,\n",
       "        855, 1018,   86,  667,    2]),\n",
       "       array([1024]), array([ 441,  389, 1023]),\n",
       "       array([ 489,   97, 1095,  872,   44,   59,  506]),\n",
       "       array([1150,  536,  170]),\n",
       "       array([ 572,  555,  998, 1135,  694, 1023,  485]),\n",
       "       array([463,   2]),\n",
       "       array([1114,  538,   33,  489,  441,  309,  447,  458,  842,  515,  987,\n",
       "        873, 1139,  263,   95,  234,    8,  424,  987,  903,    2]),\n",
       "       array([904, 987, 515, 989, 531, 668, 424, 873, 557, 763, 681]),\n",
       "       array([549, 650,   2, 489, 374,   8, 732, 668, 496, 680, 668, 458, 280,\n",
       "       904, 489,  42, 763, 959, 873, 515, 657, 433, 839, 980,   2]),\n",
       "       array([873, 515, 657,   8,   3]),\n",
       "       array([ 489,   42,  678,  517,    2,  143,  873,  271,  657,  854, 1018,\n",
       "         86,  365,  468,    2]),\n",
       "       array([ 489,  807,  807,  807, 1086,  403,  143,  489,  150,  657,    2,\n",
       "        657, 1062,  633,  888,  405,    2]),\n",
       "       array([959, 441,   2]),\n",
       "       array([ 515,  248,  197,  310, 1050,  238,    2,   45,  489,  645,  309,\n",
       "       1072,    8, 1126,  989,  260,   69,    2]),\n",
       "       array([ 483,  270, 1150,  396, 1151,  429, 1018,  569,  555,  987]),\n",
       "       array([1150,   57,  961,    2]),\n",
       "       array([1150,  441,  633, 1132,    2,   60,    8,  395]),\n",
       "       array([ 489,  211,  678, 1150, 1018,  454,  633,  163,    2, 1150,   45,\n",
       "        987, 1010,   57,  666,  327,    2,   57,  657, 1095,  309,  406,\n",
       "        678,  693,  232]),\n",
       "       array([1150,  413,  911,  678, 1151,  607]), array([1110]),\n",
       "       array([994,   2]),\n",
       "       array([1100,  994,  515,  910,  489,  999,  605,   86]),\n",
       "       array([ 483,  515,  693,  563,  353,  989, 1101,    8,  232,  740,  770]),\n",
       "       array([369,   2]),\n",
       "       array([987, 515,  90, 517, 515, 953,   8, 648, 680,   2]),\n",
       "       array([ 489,  270,  657, 1087, 1018,  536,  483, 1018,  842,  987, 1004,\n",
       "          2,  489, 1087, 1018,  536, 1074,  998,    2,  555, 1110,  989,\n",
       "        411,  942,   57,    2,  483,  629,  271,  165,  207,  949,  555,\n",
       "        171,    2,  489,  441,  645,  496,  633,  553,  428, 1018,  748,\n",
       "        694,  633,  444, 1018,  910,    2]),\n",
       "       array([ 825,    2,  853, 1150,   57,  804,  365,  989,  795,    2]),\n",
       "       array([ 583,    2, 1002,  515,  633,  444]),\n",
       "       array([ 550,  597,  853, 1105,  489,  150,  270,    2]),\n",
       "       array([ 412,  491,  682, 1095,  209,  353,    8,  128,    3]),\n",
       "       array([987, 515,   8, 871,   2]),\n",
       "       array([1064,  635,    2,  873, 1073, 1018,   86,  807,  751, 1109,  873,\n",
       "        932,  465,  846,  992,  517, 1091,  523,  555,  873,  413,  883,\n",
       "        668,  517,  688,  911,    2]),\n",
       "       array([1119]),\n",
       "       array([856, 555, 873, 209, 396,   8, 232, 291, 304,   3]),\n",
       "       array([ 989,  997,  515,  489,   42,   68,  989,  602,  668,    8,  706,\n",
       "        464,  136,  668,  574,    2,  633,  888,    2,  489,  150,  657,\n",
       "        232, 1065,  873,  271,    2]),\n",
       "       array([2]),\n",
       "       array([ 650,  650,  517,  515,  633,  336, 1095,  255,  657,  441,    8,\n",
       "        774,  512]),\n",
       "       array([369, 517,   2]),\n",
       "       array([1150,   57,   64,  597,  694,    2,  987,  515,  904,  224,    2,\n",
       "       1105,  515, 1151,  639,   30]),\n",
       "       array([ 675,    3,  992,  483, 1095, 1043,  694,  909,  223,    2,  649]),\n",
       "       array([657, 989, 427,  45, 391,  45, 928, 704,   2, 744,   2]),\n",
       "       array([1100,  489, 1005, 1095, 1139,  931, 1125,  773,  491,  987,  515,\n",
       "        675, 1125, 1150,    2]),\n",
       "       array([ 150, 1095,  587, 1002,  792,   45,   57,  442,   44,  499,  478,\n",
       "        780,  133, 1067,  678,  989,  788,    2,   30,    2]),\n",
       "       array([489, 255,   2]),\n",
       "       array([1150,  999, 1150,  802,  989,  682,  914,   68,  989,  771]),\n",
       "       array([ 489,  270,  657,  441, 1018,   86,  473, 1050,    2]),\n",
       "       array([ 489,  441, 1018,   86,  473,  496, 1048,  611,    2]),\n",
       "       array([  33,  489,  536,  515,  489, 1139,  402, 1067,  633,  767,  559,\n",
       "       1018,  403,  694, 1125,    8,  424,  555,  521,    2]),\n",
       "       array([ 912,  489, 1130,  491,  989,  425, 1095,   57,  958, 1018, 1087,\n",
       "       1018,  403,  694, 1125,   57,  989,  681, 1095,   21, 1087, 1018,\n",
       "        403,  694, 1125, 1150,  536]),\n",
       "       array([ 489,  270,  657,  999,  989,  467,  668,  234,  521,   57,  406,\n",
       "       1018,  498,  277,   45,  184,    2]),\n",
       "       array([ 186,    2,  489,  270,  657,  536,  489, 1005,  443, 1139,   86,\n",
       "        259,    2,  620,  668,    8,  395,    3]),\n",
       "       array([515, 443, 674, 688, 285]),\n",
       "       array([ 443,  757,  775, 1109,  443,  374,  694, 1095,  428,  989,  838,\n",
       "        252,    2,  489,  598,    2,  515,  418,   44,   33,  143,  443,\n",
       "        515,  657,  313,  813,  709,  202,    2]),\n",
       "       array([1139, 1150,  607,  398,  597,    8,  282]), array([418]),\n",
       "       array([521,   2]), array([1114]),\n",
       "       array([1110,  255,  443,  403,  443, 1091,  523,  459,    2]),\n",
       "       array([1150,  605, 1086,  999,   12,  517]), array([650,   2]),\n",
       "       array([ 255, 1150,  167, 1151,  429]),\n",
       "       array([1150,  536,  989,  243,    2,  489,  150,  963,  403,  491,  271,\n",
       "        657,  403]),\n",
       "       array([ 560,  489, 1087, 1018,  968, 1018, 1150,   12,  989,  771,    2]),\n",
       "       array([1150,   57,  195,   74,  434,  199,  517,  515,  426,  178,    2]),\n",
       "       array([463, 521,   2]), array([462, 961, 173,   2]),\n",
       "       array([ 633,   31,  843,  489,  441,  413,    8,  411,  878,   68,   96,\n",
       "        989,  424,  647, 1146,    2]),\n",
       "       array([640,   3]),\n",
       "       array([ 517,  515,    8,  393,  221,  559,  143,  489, 1121,   86,  555,\n",
       "       1097,    8, 1061,   45,  949,    2]),\n",
       "       array([789, 435]),\n",
       "       array([ 904, 1145,  489,  441,  413,  989,  852,  161,  997,  406,   45,\n",
       "        989, 1044,  906,  399,  987,  515,   86,  484,    2,   45,  992,\n",
       "        489,   42, 1067,  365,   44,   22,  365,  789,  435,  647, 1098,\n",
       "          2]),\n",
       "       array([477,   2]),\n",
       "       array([ 313,  904, 1150,  406, 1018,  121,  515,  997,  678]),\n",
       "       array([318]), array([517, 515, 620]), array([724]),\n",
       "       array([515, 988,  10]), array([ 517,  515,  523, 1150,    2]),\n",
       "       array([ 515,  987, 1128,    8,  193,  383,  688,  515,  517,  523,  597]),\n",
       "       array([ 650,  489,  523, 1088]),\n",
       "       array([1105, 1018,  194,  227,  597, 1018,  861,  597, 1018,  993,  368,\n",
       "       1105]),\n",
       "       array([ 489,  523, 1088]), array([1150,  864,  597, 1067,    2]),\n",
       "       array([550, 403]), array([ 904,  255, 1150]),\n",
       "       array([1150,  570,   89,  541,  649, 1150,  536,    2]),\n",
       "       array([ 489,  423,  489, 1121,  645,  536, 1121,  489]),\n",
       "       array([ 657,   33,  320,   57,  411,    2, 1150,  150,  657,   41, 1042,\n",
       "        989,  720, 1150, 1087, 1018,    2]),\n",
       "       array([ 404, 1150,   57,  523,  555,  468,  523,  524,  597,  568,   73,\n",
       "        496,  989,  231,  904,  489,  150,  657,  319,   53,  365,  634]),\n",
       "       array([ 489,  423,  489, 1005,  489, 1091,  777, 1150,    2]),\n",
       "       array([ 489,   42,  657,  951,  304, 1018,  816, 1151,  615,    2]),\n",
       "       array([987, 515, 657]),\n",
       "       array([ 650,    2, 1150,  255,  657,  491, 1150,  807, 1005,  489,  209,\n",
       "        587,  633,  698,  247, 1150, 1139,  441,  550,  597,  403,  694,\n",
       "       1125,  468,  504,  668,  456,  226,  472,  597,  480,    2]),\n",
       "       array([ 489, 1088, 1018,  550, 1150,  587, 1067, 1151,  698,  607,   12,\n",
       "        468,    2]),\n",
       "       array([1119,  255,  657, 1150,  977,  597]),\n",
       "       array([  28,  987,  489,  962,  489, 1139,  645,  270,   53,  523,   90,\n",
       "        311,  298, 1091,  273,  517,    2,   45,  489,  441,  657,  887,\n",
       "          2,  314,  365,  121,  515,  709,   45,  633,  950,  269]),\n",
       "       array([143]),\n",
       "       array([ 523,  679,    2,   29,  489, 1021,  468,  489,  255,  657, 1087,\n",
       "       1018,   51,    2,  489, 1091,  657,  804,    2,  443,  413,  738,\n",
       "          2,  992,  443,  137, 1067, 1125,  597,    2]),\n",
       "       array([1150,  255, 1105]),\n",
       "       array([ 443,  837,  311, 1091,  273,  517,    2,  904,  489,  255,  517,\n",
       "          2]),\n",
       "       array([ 60, 496,   3]),\n",
       "       array([ 660,  489,  270,    2,   78,  992, 1091,    8,  259,  943,    2]),\n",
       "       array([ 143, 1150,  437,  521]),\n",
       "       array([ 443, 1091,  555,    8, 1029,   77]), array([1119]),\n",
       "       array([496,   7,   2, 365,   8, 619]), array([1105]),\n",
       "       array([ 521,  645, 1021, 1150, 1095, 1102,  694,  255,  443]),\n",
       "       array([ 489, 1123,  489,  428,  987,  581,    2,  489,   42,  989,  682,\n",
       "        914,  987,  413,   63, 1018,  989,  771,   45,  489,  150,  657,\n",
       "        403,   90, 1150, 1129,  964]),\n",
       "       array([ 489,  270,  155,    2,  143,  489,   42,    8,  356,   98,  496,\n",
       "        273,  911,  365, 1151,  698,  808,  657,  910,  298,  835,    2]),\n",
       "       array([ 555, 1150,  155,    2]),\n",
       "       array([ 560,  489,  536, 1150,  437,  442, 1018,  889,  473,   90,  489,\n",
       "         42,  657,  465,  846,    2]),\n",
       "       array([1150,   57, 1099,    2]),\n",
       "       array([ 489,  270,  657,  396, 1150,    2, 1150,   16,  555, 1150,   57,\n",
       "       1025,  411,  365,   50,  668, 1002,   45,  992, 1150,  403, 1030,\n",
       "       1109, 1150,  396,  459,    2]),\n",
       "       array([ 489,  807,  270,  657,  999,  489,  641,   50,  905,   25,  382,\n",
       "       1150,  825,  660,    2]),\n",
       "       array([ 489,  641, 1018,  968, 1018, 1150,  489,  641, 1018,  977, 1150]),\n",
       "       array([ 150, 1095,  403,  660]),\n",
       "       array([1150,   57,  904,  194, 1055,    2]),\n",
       "       array([1145,  443,  515, 1151,  376,  380,  515,  128,    2,  489,  423,\n",
       "        887,  489,   42,  657,   34, 1018,  403,  694,  489,  880,  664,\n",
       "        697,    8,  242,  424, 1025,    2]),\n",
       "       array([ 517,  515,    2,  596, 1150,  441,  447,  668,  468]),\n",
       "       array([ 555,  489,   42,  958, 1018,  536, 1105,  987,  306,  599,    2]),\n",
       "       array([ 68, 545, 489,  42, 657,   8, 181, 347, 955, 450,   2]),\n",
       "       array([ 150,  657, 1150,  369,  365,  523,  680,  649,  987, 1150,   57,\n",
       "        194, 1142]),\n",
       "       array([ 121,  515,  709,  515,  655,  143, 1150,   57, 1025,  142,  561,\n",
       "       1018,  113, 1114,  641, 1018,  536,  987,    2]),\n",
       "       array([1105,  515,  655]),\n",
       "       array([1150,   57,  829,  633,  553,   90, 1150, 1121,  657,   86,  655,\n",
       "        489,  150,  657,   86,  655,    2]),\n",
       "       array([ 489,  999, 1150,   57,    8,  376,    2,  489,  999, 1150,  270,\n",
       "       1002, 1018, 1028,  597,    2,   45,  489,  999, 1150,  954,    2]),\n",
       "       array([1105,  270, 1150,  999]),\n",
       "       array([ 673,  489, 1005, 1150,  605,  441,    8,  232,  489,  270,  657,\n",
       "        536, 1119,  489,   42,  125, 1018,   62,  143,   57, 1150,  406,\n",
       "       1018,  121,  515,  709,  649]),\n",
       "       array([ 517,  599,  987,  515,  742,   68,  182,  893,   45, 1095,   57,\n",
       "        406,    2]),\n",
       "       array([ 673,  633,  404,  271, 1002,  598, 1150,   57,   92,  655]),\n",
       "       array([ 150, 1150,   68,  545,  931, 1097,    8,  130]),\n",
       "       array([ 489,  441,  989,  755, 1018,  900,  989,  217,  694,  668, 1150,\n",
       "        491, 1150,  270,  657,  396,  694,  668,  633, 1094,    2]),\n",
       "       array([661,   3, 463, 226,   2]), array([1110,  441, 1150,   93]),\n",
       "       array([ 489,  441,    8,  232,  226,    2,   45,  443,  835,  657,    8,\n",
       "        153,  668,  687,  555,  909,  601, 1095,  536,    2,  489,   42,\n",
       "        613,  911,    2]),\n",
       "       array([ 354,    2,  489,  853,  987,  489,   42,    8,  766,  496,  633,\n",
       "        698,  482,    2,  489,   42,  657,    8,  235,    2,  489,   42,\n",
       "          8,  754, 1150,   57,  657,  406, 1062, 1151,  888,  405,    2,\n",
       "        301,  668,  943,    2]),\n",
       "       array([ 443,  515,  657,    8,  481,  827,    2, 1106,  987,  515,    2,\n",
       "        517,  515,  987,  481,  827,  521,  825,  987,  835, 1114, 1150,\n",
       "       1087,  597, 1018,  101,  633,  830,  365]),\n",
       "       array([650, 143, 989, 771, 436,   8, 232]),\n",
       "       array([ 226,  489, 1087, 1018,  267,  989,  771, 1125, 1150,    2,  517,\n",
       "        515, 1022,  649,   90,  873, 1121,  844,  991,   73,    2]),\n",
       "       array([1119,  772,  597, 1150, 1121,  657,  968, 1018,   50,  129, 1062,\n",
       "       1151,  888,  515,  760,    2,  523,  365,    8,  610]),\n",
       "       array([ 226,  650, 1096,  989,   99,   95, 1150,  403,    2]),\n",
       "       array([ 517,  515,  523,    8,  709,    2,  226,    2,  673,  404,    2,\n",
       "        517,  515,  933,    2,  491,  515,  657,  406, 1150,   57,  657,\n",
       "        406,    2]),\n",
       "       array([ 226,  720,  317,  597, 1018,   86,  994]),\n",
       "       array([ 517,  515,  523,    8,  709,    2,  226,  143,  489,  535, 1150,\n",
       "       1139,  366,  597, 1018,  403,  887,  697,  994,  515,  657,  406,\n",
       "        692,  537,   60,   44,  690]),\n",
       "       array([ 491, 1150,  631,  536, 1095, 1103,   71, 1018,  403, 1018,    8,\n",
       "        901,  948,  422,  668,  381,    2,   45, 1110,   57, 1150,  406]),\n",
       "       array([226, 489, 313, 633, 748]),\n",
       "       array([ 143,  873,  271,  657, 1087, 1018,  232,    2]),\n",
       "       array([ 143,  517,  515,  657,  328,  873,  515,    8,  632,  226,  992,\n",
       "        644, 1121, 1150,    2,   45,  489, 1121,  396, 1018,  894,   68,\n",
       "        649,    2]),\n",
       "       array([1105,  491,  873,  645,  934,  234,  650, 1150,   57,  657,  234,\n",
       "       1065, 1151,  888,  934,  234,    2,  301,  668,  268,    2]),\n",
       "       array([ 660,  270,  657,  396, 1070,    2,  226,  143,  994,  515, 1002,\n",
       "        127,    3,   45,  489,  999,  443,  605,   62,    3]),\n",
       "       array([ 523,  862, 1009,    2]),\n",
       "       array([ 401,    2,  680,  971,  245,  120,    2,  989,  691,  680,  532,\n",
       "        877,   45, 1058]),\n",
       "       array([645]),\n",
       "       array([ 332,  668,    8,  332,    2, 1150,  853,    8,  212,  668,  609,\n",
       "        187,  496]),\n",
       "       array([ 255,  657,  441, 1150,  719,  365,    8,  332,    2,   57,  657,\n",
       "        996,    8,  563, 1025,  100,  826,  365, 1150]),\n",
       "       array([ 41,   8, 745,   2]),\n",
       "       array([ 105,  159,  845, 1150,   57,   78,  678,  989,  717,  365,   75,\n",
       "          2]),\n",
       "       array([1150,  487,  989, 1128,  836, 1152,  678,  989,   39,  668,  261,\n",
       "         45,  306,  989,  849,    2]),\n",
       "       array([650, 489, 582, 657,   2]),\n",
       "       array([   2,  143,  462, 1150,   57,  589,  768,    2]),\n",
       "       array([ 989,  453,  515,  987, 1105,  531,  668,  523,  731, 1067,    8,\n",
       "        400,   45,  158,  458,   73, 1112, 1150,   57,  970, 1018,  458]),\n",
       "       array([ 325, 1060,  592,    2]),\n",
       "       array([ 453,  489,  441,  523,   93,  406,  697,  989, 1116,  997,  496,\n",
       "        633,  444,   45]),\n",
       "       array([1150, 1021,  597,  987,  704,   38,    2]),\n",
       "       array([517, 515, 458, 338,  82,   2]),\n",
       "       array([  66, 1151,  289,  365,  680,  649,    2]),\n",
       "       array([ 675,  489, 1091,  657,  959]), array([443, 515, 763]),\n",
       "       array([242,  68, 372,   2]), array([ 458,  338, 1056]),\n",
       "       array([517, 515,   8, 580, 151, 516]),\n",
       "       array([662, 680,   2, 873, 439, 902]),\n",
       "       array([  57, 1150,  527,  443, 1121,  737,  469, 1125,  522,    2,  443,\n",
       "        515,  989, 1054,  533,   65,    2]),\n",
       "       array([1121,  121,  396,  103]),\n",
       "       array([ 496,  987,  159, 1095, 1121,  641, 1018,  587,  517,    8,  847,\n",
       "        118,  694,    2]),\n",
       "       array([1002,  515,  517,    2,    8,  407,  685,    2,  150,   62, 1018,\n",
       "        989,  709,    2]),\n",
       "       array([ 555, 1095,  428,    8,  176,  104, 1109, 1150,  550,  989,  303,\n",
       "        999,  443,  515,  689,  989,   85, 1150,   57,  496,    8,  753,\n",
       "        668,  756,    2, 1095,  550,  468,  762,  443,  515,  148,  989,\n",
       "        879,   45, 1112,  443,  515,  142,  866, 1067,  989,  740, 1150,\n",
       "        441, 1013, 1018, 1131,    2]),\n",
       "       array([1150,  413,  468,  514]),\n",
       "       array([ 462,  489,  441,  413,  441,    8,  350,  179, 1109,  489,  396,\n",
       "       1018, 1085,  944,    2]),\n",
       "       array([ 489, 1005, 1150,  438, 1003,  720,    2]),\n",
       "       array([1150,  536,  491, 1150,  270,  403,  694, 1125, 1150, 1139,   86,\n",
       "        864,    2, 1150, 1139,  696,  311,    2,  945,    9,    2, 1125,\n",
       "        597,  145, 1151,  884,    2]),\n",
       "       array([ 987,  515, 1105,  489,  523,  837]),\n",
       "       array([ 255,  873,   21,  842,  873, 1139,  403,  694, 1125, 1150]),\n",
       "       array([ 369,  471,  817,    2,  270, 1150,  999, 1095,  441,  413,    8,\n",
       "        740,  688,  657]),\n",
       "       array([ 489,   42,  863,  591,  443,  515, 1104,    2,  443,  908,  471,\n",
       "        698,  566,  678,  989,  114,  594,  904,  443,  209,  144,  646,\n",
       "        920,    2]),\n",
       "       array([996,  41, 550, 344, 889, 496, 678, 475, 111]),\n",
       "       array([ 650,  527,    2,  443,  515,    8,  220,    2,  489,  447,  443,\n",
       "        562,    8,  936, 1039,  678,  355,    2,  443,  523,  413,  694,\n",
       "        668,    3]),\n",
       "       array([ 443,  856,  555,  443, 1008,  678,  229]),\n",
       "       array([1105,  588, 1150,  999,  443, 1121,  270,  517]),\n",
       "       array([1150, 1086,  403,  694, 1125,  468]),\n",
       "       array([1105,   12,  468]),\n",
       "       array([1063,  143,  306,  904,  873,  939,  150,  657,  403,  694, 1125,\n",
       "       1150,    2,  904, 1105,  515,  989,  748]),\n",
       "       array([ 489,  973,  458,  396, 1018,  536,  458,  240,  458, 1125,  169,\n",
       "         45,  873,  330,  496,  578, 1125,  597,    2]),\n",
       "       array([ 989,  604, 1141,  460,    2]),\n",
       "       array([987, 515, 458, 515, 888]),\n",
       "       array([1145,  523,    8,  608,  300, 1125,  989,  882,    2]),\n",
       "       array([1150,  209,  198, 1125,  458,  633,  380,    2]),\n",
       "       array([1150,  598,  489, 1139,  396,    8,  166, 1018,  968, 1018,  458]),\n",
       "       array([ 423, 1114,  523,  885, 1067,  365,    8, 1045]),\n",
       "       array([959, 270,   3, 633, 617, 515, 382]), array([1150,  536]),\n",
       "       array([ 521,    2,  489, 1123,  489,  209,  842,  443,  515,    8,  621,\n",
       "        143,  443,  515,  662, 1047,  496,  989,  178,    2,   45,    8,\n",
       "        616,    2,  623,  811,  949,  143,  443,  515,  832, 1018,  441,\n",
       "          8,  108, 1044,  906,   22,  188,  694,    2]),\n",
       "       array([443,  41, 441, 987, 876, 420]),\n",
       "       array([  90,  996,   57,  135, 1018,    2,  990,  624,  556,  425,  555,\n",
       "        987,   45,  990,  417,   95,  991,    2,  990,  394,  750,  515,\n",
       "        801,  262,    2]),\n",
       "       array([1119,  270,  401,  555,  987,   41,  555,  425,  555,  987]),\n",
       "       array([ 489,  209,  931, 1125, 1151,  430,  143,  517,  271,  657,  595,\n",
       "          2,  873,  515,  657,   34, 1018,  232, 1065,  458,  677,  888,\n",
       "        271,    2,   45,  987,  515,   44,  494,    2]),\n",
       "       array([1119,  657]),\n",
       "       array([  2, 914,   2, 270, 657, 306, 999,  12, 517]),\n",
       "       array([1114,  515,  873]),\n",
       "       array([1150,  140, 1150,  736, 1150,  722]), array([987, 400, 489]),\n",
       "       array([1145,  143,  995,  425,  441,  645,  857,    8,  479,    2,  996,\n",
       "        523,  518,  669, 1018,    2]),\n",
       "       array([ 987,  489,   42, 1073, 1018,    2]),\n",
       "       array([ 212, 1006,    2,  622,  668,  991,  312]),\n",
       "       array([483, 593, 720, 403, 459]), array([396, 694]),\n",
       "       array([1001,    2]),\n",
       "       array([ 483,  593,  720, 1103,  496, 1151,  676,  846]),\n",
       "       array([1145,    2,    8,  212,    2, 1095,   57,  695,  145,  989,  215,\n",
       "       1004,    2]),\n",
       "       array([ 489, 1091,  527,    2,  720,   21,  564,  994]),\n",
       "       array([ 656,   21,    2,  483, 1139, 1150]),\n",
       "       array([ 904, 1111, 1150,  382]),\n",
       "       array([   2,  489,   42,  958, 1018,  402, 1150,  989, 1033,    2]),\n",
       "       array([904, 996, 977, 597,   3]), array([1150,  989,  646,  424]),\n",
       "       array([1150,  396,  989,  400,    2]),\n",
       "       array([1105,  515,  989, 1138]), array([1110]),\n",
       "       array([873, 534, 597,   2]), array([1150,   50,  445]),\n",
       "       array([ 873,  523,  642, 1013, 1018,  204,  669,  489, 1121,  402,  517,\n",
       "          8,  237,    2]),\n",
       "       array([ 873,  439, 1150, 1125,  989,  355,  668,    8, 1006,  956,    2,\n",
       "        987,  515,    8,  264,  796]),\n",
       "       array([ 489,  275,  963,  536,    2,  489,  246,  657, 1018,  638,  458,\n",
       "       1109,  873, 1091, 1025,  284, 1018,  814,  517,    2]),\n",
       "       array([1105, 1139, 1150,  270, 1018,  458]),\n",
       "       array([992, 403, 396, 458]), array([959]),\n",
       "       array([ 270, 1150,  555,  989,  400]),\n",
       "       array([ 873,  515,  705, 1018,  521,  657,  597]),\n",
       "       array([1105, 1150,  970,   12]),\n",
       "       array([ 517,  515,  669,    2,  989, 1116,  997,    2]),\n",
       "       array([489,  42,   8, 563, 142]),\n",
       "       array([270, 657, 587, 597, 270, 517, 591]),\n",
       "       array([ 515,  742,  994, 1022,  649,    2]),\n",
       "       array([ 904, 1105,  271,  987,  402,  597,  489,   42,  958, 1018,  144,\n",
       "        458,  909,  653,   45,    8,  123,   45,  889,   58,  561, 1018,\n",
       "        175, 1114,  150,  657,  741,  990,  507]),\n",
       "       array([675, 557, 363, 346, 776,  45,  47, 941, 400, 630, 668, 989, 729,   2]),\n",
       "       array([ 489,  441,  823,  164,  734,  668,  500,  678,  612,  489,  999,\n",
       "       1150, 1121,  353,  455,    2]),\n",
       "       array([1105,  441, 1150,  413,  365,  597]),\n",
       "       array([1145, 1095, 1121,  853,    2]),\n",
       "       array([  45,  443,  599,  987,  945,  496,    8,  651,  765, 1051,  668,\n",
       "       1094,    2]),\n",
       "       array([  45, 1119, 1139,  489,  270,  987]),\n",
       "       array([546, 633, 888,  37,   2]), array([1151,  888,  459]),\n",
       "       array([73,  2]), array([1110, 1144]), array([657,  68,  33]),\n",
       "       array([ 462,  270, 1150,  607]),\n",
       "       array([996,  57, 834, 989, 820, 668, 597, 647, 619,   2]),\n",
       "       array([1145,   45,  489,  659,  989,  682,  704,  668, 1150,  340,  496,\n",
       "       1151,  108,  929, 1091, 1151,  297,    2, 1032,  132,    2]),\n",
       "       array([ 989, 1081,  569,  515,  697,    2,  441,  657, 1150,   93,  803,\n",
       "       1151,  840]),\n",
       "       array([ 304, 1125,  989,  637,  525,  875,    2,  489,  536,    2]),\n",
       "       array([ 489,  270,  657,  536,    2,  558,  359,    2,   48,  488,  365,\n",
       "        989, 1046]),\n",
       "       array([ 396,  458, 1018,   16,  555,    8,  486]),\n",
       "       array([ 270, 1105]), array([ 483, 1139, 1150,  270,  517]),\n",
       "       array([  8, 243, 515,   8, 243,   2]),\n",
       "       array([ 517,  515,   12, 1013,    2]),\n",
       "       array([369, 458, 888, 992,   2]), array([369, 517,   2]),\n",
       "       array([  8, 488, 138,   8, 232,   2]), array([1105]),\n",
       "       array([ 489,  523, 1069,  633,  764]),\n",
       "       array([ 489,  413,  458, 1057,  201,    2,  873,  523,   20,  218,  496,\n",
       "        780, 1018,  524, 1067,  989,  492,    2]),\n",
       "       array([1093,  989,  112, 1037,  633,  154,  271,  657,  210,   60,    8,\n",
       "        232,    2]),\n",
       "       array([489,  42, 678, 517]),\n",
       "       array([1109,  489,  874,  694,  351,  489,  317,  821,    2]),\n",
       "       array([ 351,   45, 1150,  441,  413, 1151,  591,    2]),\n",
       "       array([ 966,  517,  688,  546,  517,    2, 1002,  515,  657,    8,  643,\n",
       "          2]),\n",
       "       array([ 354, 1000,    2]),\n",
       "       array([ 489,  150,  657,  966,    8,  400,  555,  987,  694,  678, 1048,\n",
       "        138,    2]),\n",
       "       array([483, 629]),\n",
       "       array([ 489,  150,  657,  232,  458,  888, 1065,  987,  680,  397,    8,\n",
       "        128,    2,   45,  987,  515,  989,  162,    2,  873,  271,  657,\n",
       "       1087,    8,  128,    2]),\n",
       "       array([1150,   57,  715,  597, 1018,  966,  694,  909,  400]),\n",
       "       array([1150,  413,  517,    2,  489,  730, 1067,  989,  965, 1150,  270,\n",
       "        989,  475,    2]),\n",
       "       array([ 143, 1150, 1139,  403,  694, 1125,  458,  491, 1150,  428,  989,\n",
       "        146]),\n",
       "       array([1150,  641,  618, 1018,  966,    8,  400,  694]),\n",
       "       array([1150,  523,  837]),\n",
       "       array([ 959,  918,    2,  489, 1121,  396,  825,  678,  517,    2]),\n",
       "       array([1145, 1106,    2,  489, 1087, 1150, 1018,  403,  694, 1125,  458,\n",
       "          2]),\n",
       "       array([1050,  548,  648,  797,    3]),\n",
       "       array([1105,  270, 1150,  999]), array([1145]),\n",
       "       array([462, 517, 515,  33, 365, 989, 466, 411, 825]),\n",
       "       array([1150,  106,  657,  384, 1002, 1067,    2,  489,   42,  449,  513,\n",
       "          2]),\n",
       "       array([1105, 1095, 1026,   84, 1020, 1109, 1095, 1103,  528,    2]),\n",
       "       array([1150,   45]), array([1053, 1145,    2, 1095,   57,  676]),\n",
       "       array([ 489,  446, 1150,   57,    2]),\n",
       "       array([ 904, 1105, 1150,  641, 1018,  270,  515,  809,    8,  424, 1114,\n",
       "       1121,  403,  694, 1125,  458,    2,  910, 1114,  515, 1067,  365,\n",
       "        989,  520,    2]),\n",
       "       array([ 271, 1002,  202,  441,    8,  786]),\n",
       "       array([ 143,  873,  150,  657,  403,  694, 1125, 1150,   90,  458,  888,\n",
       "        515, 1002,  502,  444,  159,   45,  650,  680, 1121,  403,  694,\n",
       "       1125,  458,    2,  825]),\n",
       "       array([1095,   57,  657,    2]),\n",
       "       array([1100,   21,  489, 1005,  489, 1139,  833,   44,  490,  145, 1150,\n",
       "          2, 1150,  536,  523, 1018,  853,  491, 1150,   57,  509,    2]),\n",
       "       array([1095,  270,  657,  171,    2]),\n",
       "       array([ 654,  523,  149,  145, 1018,  171]),\n",
       "       array([  57, 1150,  576]), array([462,   2]),\n",
       "       array([ 673,  474,  977,  597, 1095,  441,  657,  769, 1018,  388,  431,\n",
       "          2]),\n",
       "       array([ 443,   63,  597, 1018,  600,  468,  459,    2]),\n",
       "       array([1114]), array([ 441, 1150,  857,  468]),\n",
       "       array([ 673,  411,    2,  911,  646,   45,  259,  365, 1071,    2]),\n",
       "       array([1150,  802,  571,   68, 1002,  382,  989, 1143,  728,    2, 1095,\n",
       "         57,  589,    8,  937,    2]),\n",
       "       array([ 675,  675, 1095, 1121,  657,  403,    2,  517,  515,  657,  555,\n",
       "        489,  441,    8,  281,   54]),\n",
       "       array([ 560, 1018, 1150, 1150,  917,  555,   33,  738,  669,   90,  515,\n",
       "        967, 1079,    2]),\n",
       "       array([1100,  489,  423, 1095,   57,  657,  887, 1095,  270,  657,  441,\n",
       "        233,    2]),\n",
       "       array([ 150, 1150,  306,  493, 1114,  989,  453, 1139,  403, 1018, 1002,\n",
       "          8,   83,  668,  190,  315]),\n",
       "       array([ 489,  413,  284,    2,  489,  781,    2,  489,  413,  812,    2,\n",
       "        517, 1091,  108,  389,    2]),\n",
       "       array([1150,  255,  657]),\n",
       "       array([489, 255,   8, 337,  45, 517,  79,   2]),\n",
       "       array([1150,  255,  657,  441,    8,  176, 1110,  515,   45, 1105,  441,\n",
       "       1150,  276, 1125,  458]),\n",
       "       array([489, 255, 657, 441,   8, 176,   2]),\n",
       "       array([1150, 1102, 1018,  989,  709,  489, 1005, 1095, 1103,  671,  686,\n",
       "       1018,  952,  905,   19,    2]),\n",
       "       array([1114,  157]), array([1105, 1139,  443,  842]),\n",
       "       array([650, 339,   2]), array([1150,  999, 1002, 1121, 1134]),\n",
       "       array([ 491,  489, 1091,  517, 1139,   86,   50,  846, 1150, 1087,  758,\n",
       "          2,  270,  657,  369, 1151, 1012,    2]),\n",
       "       array([271, 517, 595]),\n",
       "       array([ 489,   55, 1151,  295, 1034,    8,  923,  244,  143,  489,   42,\n",
       "        200,    2,  270, 1150,  607]),\n",
       "       array([644, 436, 471, 461,   2]), array([987, 515, 645,  93, 778]),\n",
       "       array([ 255,  657,  306,  403, 1018,  465,  846]),\n",
       "       array([1139,  645,  441,  410, 1018,    8,  936,  846,    2]),\n",
       "       array([ 904,  443,  436, 1002,  484,  798,  357,   12,   45,  503,  987,\n",
       "        489,  403, 1018,  471,  590,  782,  375,  127,  662,  680,  408,\n",
       "        974,  846,    2,  489,  441,  650,  842,   68,   33,    2]),\n",
       "       array([1150,  209,   41,  403, 1125,  597,    2,  489,   42,  959,  436,\n",
       "        909,  381,    2]),\n",
       "       array([ 989,  720,   68, 1002,  846,   57,  904,  499,  373,    2]),\n",
       "       array([ 143,  493,  989,  998,  443, 1139,  842,  287,  869,    2]),\n",
       "       array([ 489,  806,  987,  989,  601,  668, 1002,  354,  505,   57,  868,\n",
       "        539,  143,  530, 1152,  904, 1150,  150,   86, 1125,  515,  107,\n",
       "        989,  848,  668,  655,  975,  665,    2, 1150,   57, 1077,  333,\n",
       "        710,  239,  968,  881,  361,   45,  305,  989, 1136,  668, 1003,\n",
       "       1114,  641, 1080,  318,  993,    2]),\n",
       "       array([ 44,  70, 898,   2]), array([1105,  515, 1002]),\n",
       "       array([523,   8, 563,   2]),\n",
       "       array([ 292,    2,  935, 1152,  515,    8, 1080,  899, 1094, 1018,  256,\n",
       "          2]),\n",
       "       array([117, 288]), array([443,  41, 569, 904]),\n",
       "       array([489,  42, 959, 443, 515, 194, 497, 668, 273,  53, 987, 510,   2]),\n",
       "       array([ 987,  515,  712,  989,  680, 1114, 1091,  410,  365,    8, 1146,\n",
       "        489,  447,  443, 1091,  273,  752,  627,    2]),\n",
       "       array([800, 892,   2]), array([1114,  515,  987]),\n",
       "       array([ 275,  963, 1150,  306,  230,    2,    2,    2]),\n",
       "       array([ 673,  150, 1150,  396,  597,  633,  378, 1147]),\n",
       "       array([  90,  489,  555, 1018, 1028, 1150,    2]),\n",
       "       array([1119,  515,  633, 1076,  139,  989,  682,  141,  663,  678, 1002,\n",
       "        419]),\n",
       "       array([1145,  143,  992,  489,  386, 1067,    2,  489,  343,  365,  458,\n",
       "          2]),\n",
       "       array([515, 987, 825]),\n",
       "       array([ 104,  489,  428,  909,  324,  160,    2,  909,   67,  700,  597,\n",
       "       1018,  966,  694,    8,  807,  418,  400,    2]),\n",
       "       array([ 489, 1005, 1150,  209, 1072,  517,    2, 1109, 1150,  931, 1151,\n",
       "         82,    2]),\n",
       "       array([   8,  348,    2, 1150,  126, 1002]),\n",
       "       array([489, 255, 657, 155,  12, 989, 618,   2]),\n",
       "       array([ 807, 1105, 1091,  517,  555,    8,  278,  716,  660,  992,    8,\n",
       "        122,  365,  895, 1125,  597]),\n",
       "       array([ 517, 1091,  657,  555,  987,    2]),\n",
       "       array([1150, 1103,  700, 1018,  966,  597,  694,  145,  989,  680,  726,\n",
       "        489, 1041,  437,    2,  489,  535,  517, 1091,    8,  865]),\n",
       "       array([1083,  489,    3]),\n",
       "       array([ 517,  397, 1137, 1150,  939,  441, 1151,  378, 1147]),\n",
       "       array([987, 835, 194,  24]),\n",
       "       array([ 987,  515, 1110,  489, 1091,  541, 1146,    2,  873, 1139,  645,\n",
       "        565,   37,  633,  414,  257,  489,  938, 1125,  458,    2,  489,\n",
       "       1091,  657,  496,  519,  489,  270,  657,  536,   45,  489,  441,\n",
       "        645,  896, 1125,    8,  927,  400,    2,  489,  925,    8, 1146,\n",
       "        890,  647, 1018,  633,  415,  678,  989,  208, 1093, 1108,  668,\n",
       "        370,    2,  301,  668,  943,    2]),\n",
       "       array([1105]), array([633, 416, 515,   2]),\n",
       "       array([ 569,  489,   42,  915,  987,  489,  791, 1151,  626,    2,  489,\n",
       "       1091, 1143,    2]),\n",
       "       array([673, 485]),\n",
       "       array([ 517,  515,  523,  911,  489,  428,    2, 1150,  536]),\n",
       "       array([ 517,  515,  851,  515,    2,  471,  232,  413,  203,    2, 1110,\n",
       "       1139, 1150,  396,  989,  281]),\n",
       "       array([ 483, 1139, 1150,  396,    8, 1046,   68,  989,  541,  610]),\n",
       "       array([ 658,  994,  515,  658,  496,  517,  365,  597,    2,  523,  989,\n",
       "        745,  668, 1151,  191,    2]),\n",
       "       array([ 49, 989, 790]),\n",
       "       array([1150,  641,  993,    2,  436,   52,  309, 1021, 1150,  987]),\n",
       "       array([1150,  977,  597,    2]),\n",
       "       array([ 904,  489,  441, 1018,  441,    8,  625, 1018,   86, 1125, 1150]),\n",
       "       array([ 219,    8,  563,  279,  931,    8,  646,  831, 1105]),\n",
       "       array([  90,  489,  270,  657, 1087, 1018,    2,  517,  515,    8,  951,\n",
       "       1036,    2]),\n",
       "       array([1119,  657]),\n",
       "       array([ 650,  489, 1121,  657,  403, 1125, 1150]),\n",
       "       array([ 650, 1105]), array([650,   2]),\n",
       "       array([1150,  536, 1105,  489,  598]),\n",
       "       array([515, 987,   8, 818, 688,   8, 189]),\n",
       "       array([ 403, 1018,  989,  771, 1125,  597]),\n",
       "       array([1150,   57,   43,  859,    2,  436,   52,  309, 1021, 1150,  987]),\n",
       "       array([650, 680, 298, 538]), array([1105]),\n",
       "       array([1150,   57,  961,    2,   45,  870,    2,   45,  194,  481,  365,\n",
       "        597,    2]),\n",
       "       array([650, 911, 805,   2, 911, 650, 680, 298, 538,   2]),\n",
       "       array([489, 437, 718,   2]), array([ 977,  597,  911, 1040,    2]),\n",
       "       array([489, 536, 989, 752, 156, 515,   8, 552,   2]),\n",
       "       array([448,   2]), array([989, 286]), array([329,   2]),\n",
       "       array([ 936, 1039]), array([365,   2,   2,   2]),\n",
       "       array([1150, 1067,  365,  517]),\n",
       "       array([1150,  645,  266,  597,    2]), array([483]),\n",
       "       array([ 992, 1150,  850, 1067]), array([911, 555, 987]),\n",
       "       array([ 904,  491, 1150,  265,  991,  382,  989,  931, 1150,   57,  214]),\n",
       "       array([ 489,  270,  657,  555, 1018,  270, 1105,  720,  317,    2,  992,\n",
       "        996,  317,  517,   33,  989, 1013,   45,  996,  396,  266, 1109,\n",
       "       1150,  167,    2]),\n",
       "       array([1149]), array([  17,  989, 1094, 1095,  270,    2]),\n",
       "       array([ 904, 1105,  515, 1151,  316]),\n",
       "       array([1145, 1100,  270,  657,  550,  517,  396,  694]),\n",
       "       array([   8,  907,  884, 1114,  535]),\n",
       "       array([ 489,  241,  468, 1125,  633, 1124]),\n",
       "       array([ 904,  483, 1139, 1150,  396, 1018,  569,  989,  691, 1094]),\n",
       "       array([411, 147,   2]),\n",
       "       array([ 489,  352,  517,  428, 1018,   86,  911,  824, 1018, 1122, 1151,\n",
       "        819,    2,   45,  737, 1150,  669,    2]),\n",
       "       array([989, 707, 331]), array([596,   2]),\n",
       "       array([1150, 1087,  597, 1018,  180, 1067,   45,  881, 1150,  483, 1018,\n",
       "        396,  278]),\n",
       "       array([369, 517,   2, 489,  42,   2]),\n",
       "       array([ 787, 1151,  825,  364,  994]),\n",
       "       array([1043,   68,  517,  382, 1002,   46]),\n",
       "       array([  2, 517, 515, 657, 987,  80]),\n",
       "       array([ 489,  423,  489,  645, 1021, 1150,  489,   42,   27,  668,  451,\n",
       "          2]),\n",
       "       array([ 569, 1067,  957]),\n",
       "       array([443, 547, 489, 930, 989,  45, 443, 222, 678, 597,   2]),\n",
       "       array([ 691,  985,  633, 1068,  810,  658,    2]),\n",
       "       array([ 904, 1105,  255,  489,  441,   44,  294,  678]),\n",
       "       array([ 270,  657,  365,  680,  610,  999,  987, 1150,  428,   50,  294,\n",
       "       1107,  678,  633,  702,    2]),\n",
       "       array([1066,  489,  423,  910,  939,  436,  458,  702,  496,    8, 1049,\n",
       "          2]),\n",
       "       array([1066,    2]), array([1117,    2]), array([743]),\n",
       "       array([1150,  904]),\n",
       "       array([ 489,  447,  994, 1091,    8,  747,  803,    2]),\n",
       "       array([1105,   57, 1150,  273,  459]),\n",
       "       array([ 316,  597,  441, 1150,  857,  989,  345,  636,  489,  576,  633,\n",
       "        205,    2]),\n",
       "       array([ 650,  670,  143, 1150,   57,  888,  515, 1126,    2,  489,  536,\n",
       "        311,  557,  458,   45,   33,  143,    3]),\n",
       "       array([1114]),\n",
       "       array([ 443,  523, 1089,  597, 1018,   86,  910,  489,   42,  657,    2]),\n",
       "       array([ 904, 1105,  835, 1067, 1125, 1151,  225,  443,    8,  701,  496,\n",
       "        989,   65]),\n",
       "       array([489,  42, 994]),\n",
       "       array([ 673,  904,  660, 1150,  999, 1150,  536,  597]),\n",
       "       array([1150,  270,  657,  946,  597,   60,  989, 1051,  987, 1139,   62,\n",
       "        725,    2]),\n",
       "       array([ 633,  334, 1139,  657,   56,  668,  987,  987]),\n",
       "       array([931,   8,  82]), array([1002,    2]), array([ 270, 1105]),\n",
       "       array([ 489,  880,  270, 1002,    2]),\n",
       "       array([1119, 1139, 1150,  552]),\n",
       "       array([ 992, 1119, 1139, 1150,   62]),\n",
       "       array([ 650, 1150, 1103,  657]), array([596,   2]),\n",
       "       array([1103, 1150,  496,  519]), array([142]),\n",
       "       array([1109, 1150, 1103,  410,  541, 1146, 1110, 1103, 1150]),\n",
       "       array([ 143,  517,  515,  489,  536, 1150,  555,  991,    2,  489,  841,\n",
       "       1150,  994,    2]),\n",
       "       array([ 45, 489,  42, 496, 201, 668, 517,   2]), array([1105]),\n",
       "       array([1084, 1067]), array([1150,  536, 1105,  996,  842]),\n",
       "       array([ 489, 1005, 1150, 1103,   13,   33,  987]),\n",
       "       array([ 462,  591,    2,    2,    2, 1150,  275,  963,  999,  489,  150,\n",
       "         86,  204, 1150,  270,  657,  999,  489,  150,   86,  540,   78,\n",
       "        555,  311,  298]),\n",
       "       array([ 489,  536,    2,  517, 1139,  441, 1018,   86,    8,  763,  108,\n",
       "        243, 1018,  396, 1150, 1018,  584,  981,    2, 1150,  270,  657,\n",
       "        854,  555,  989, 1051,    2]),\n",
       "       array([489, 437, 468,   2]), array([2]), array([1114]),\n",
       "       array([1119, 1139, 1150,  550,  468,  396, 1018, 1150]),\n",
       "       array([523, 550, 597, 889, 278,   2]),\n",
       "       array([ 853,  987, 1114,  642,   26, 1109,  489,  441,  413,  116,  440]),\n",
       "       array([ 555, 1150,  209,  353,  680]),\n",
       "       array([  90,  992,  489, 1139,  441, 1018,  931,  967,  694,  401, 1114,\n",
       "        555,  597,    2]),\n",
       "       array([1119]), array([959, 489, 270]),\n",
       "       array([1150,  270,  657,  155,  491,  489,  256]),\n",
       "       array([ 489, 1021, 1150]), array([1119, 1150,  273, 1002]),\n",
       "       array([ 546,  517, 1018, 1150, 1018, 1072,  108, 1133, 1109, 1150,   57,\n",
       "          2]),\n",
       "       array([1002,  515,  904,  713,    2]),\n",
       "       array([1105,  491, 1150,  441,    8,  196,  633,  272, 1102, 1018,  894,\n",
       "       1125,    8,  196,   45, 1127, 1067,    8, 1075,    2,  657,  987,\n",
       "        489,  209,  977,  989,  258,    3]),\n",
       "       array([489, 536, 523, 550, 597, 894]),\n",
       "       array([1053, 1053,    2, 1150,  552,  278,   45, 1150, 1121,  403, 1018,\n",
       "        894]),\n",
       "       array([ 489,  523,  641, 1018,  552,  278,  365,   75]),\n",
       "       array([1150,   57,  657,  675,    2]),\n",
       "       array([489,  42, 354,   2, 489,  42]), array([675]),\n",
       "       array([ 390, 1150,   57,  989,  682,  680]),\n",
       "       array([ 489,  842,  270, 1105, 1150, 1086,  270,    2]),\n",
       "       array([ 489,   42,  398, 1038,  591,    2,  515,  657,  987, 1105, 1150,\n",
       "         57,  958, 1018,  270,   68,    8,  709]),\n",
       "       array([1105,  515, 1002]), array([1119,  270,  657, 1150]),\n",
       "       array([1150,  536, 1114,  989,  799,   57]),\n",
       "       array([1150,  536,  995,  425,   57,  650,  110,  529,  688,  989,  799,\n",
       "        143,  996,   57,  825, 1067,  994,    2]),\n",
       "       array([ 270, 1150,  607, 1150,   57,  916,  668,  829,  517,  365,  597,\n",
       "          2]),\n",
       "       array([ 987,  515, 1105, 1150, 1087,  515,  657,  517]),\n",
       "       array([316, 597]), array([462,   2, 418, 881, 485]),\n",
       "       array([ 251,  678,  989, 1027,    2,  633,  349,  270,  657,  807, 1113,\n",
       "        597,  511,    8, 1078,  377,    2]),\n",
       "       array([1150,   57,  657,    8,  108,  969,   57, 1150]),\n",
       "       array([463]),\n",
       "       array([ 489, 1091,  496,  989,  542,    2,  489,  841, 1151,  154,    2,\n",
       "       1005,  489, 1139,  842,  463,    2]),\n",
       "       array([  57, 1150,  362,  597]), array([867]),\n",
       "       array([1150,  214,  496,  633, 1082,    2]),\n",
       "       array([ 187,  678,  989,  749,  989,  358,   94, 1150, 1125,  618,  496,\n",
       "       1151,  326,  597, 1125,  633,  432,  678, 1151,   65,    3]),\n",
       "       array([  45, 1119, 1139,  489,  270,  987]),\n",
       "       array([ 992,  842, 1150, 1121,  924,  274,  649,   68,  989, 1035, 1125,\n",
       "        597,    2]),\n",
       "       array([ 489,  270,  657,  807,  999, 1150, 1090,  987,  947,   44,  299,\n",
       "          2]),\n",
       "       array([1150,  437,  597,  270,  657, 1150]),\n",
       "       array([489, 536,   8, 577, 620, 985, 987]),\n",
       "       array([ 555, 1110,  989,    5,  678,  270, 1150,  306,  536,  633,  639]),\n",
       "       array([ 989,  649,  489,  966, 1150, 1018,  739, 1150,  441,  645,   93,\n",
       "         95,    2,   45,   78,    2]),\n",
       "       array([673, 825,   2,   2]), array([ 730, 1150, 1067,  992]),\n",
       "       array([633, 614, 496, 553,   2]),\n",
       "       array([ 994,  515,    8, 1094, 1018,  396,    8,  424,  515,   72,    2]),\n",
       "       array([ 960,  555,    8,  735,   21,    2,   45, 1152]),\n",
       "       array([ 489,  598,    2,  483, 1144,  673,    2,  270,  657,  977,  597,\n",
       "       1150,  441,  168, 1151,  607,    2,  489,   38,  862,    8,  172,\n",
       "          2]),\n",
       "       array([1109,  489,  403, 1150,  536,  335,  270,  657,  555, 1018,   23,\n",
       "        987,  990,  236,   57,  152,  668,  834,  990,  698,  567,    2,\n",
       "        517,  599, 1095,  441,   91,  922,    2,  939,  551,  597,  741,\n",
       "          8,  350,  501,    2, 1150,  441,  428,  597,  678,  989,  115,\n",
       "        365, 1148,    2, 1109, 1150,  403, 1018,  489, 1121,  657,  306,\n",
       "         86,   11, 1018, 1092,  989,  392,    2,  650,  495,    2]),\n",
       "       array([1105,  515,  989,  595, 1070,  987,  489,  828,  669,  678,  458,\n",
       "        255, 1105]),\n",
       "       array([ 989,  704, 1110,   88,  989,  453,  694,  668,  909,  424,    2,\n",
       "       1111,  708]),\n",
       "       array([ 708,  668,  517,    2,  904,  977,  597,   12, 1002,  228,    2,\n",
       "       1091,  517,  389]),\n",
       "       array([ 650,  226,    2,  489,  270,  657, 1059,  989,   36,  668,  249,\n",
       "        363,    2,  515, 1002,  911,  489,  880,   86,  470, 1018,  390,\n",
       "          2]),\n",
       "       array([1145,    2,  873,  547, 1125,  909,  109,  108,  681,    2,  387,\n",
       "        668,  926,    2, 1091,  987, 1151,  888]),\n",
       "       array([ 489, 1087, 1018,  403, 1018,   44,  290,  183,  846,  489, 1087,\n",
       "       1150, 1018, 1042,  597, 1018,  587,  633,  698,  177,    2,  489,\n",
       "       1087, 1150,   57,  296,    2, 1150,  270,  657,  536, 1105, 1150,\n",
       "       1087,    2, 1150, 1121,  657,  536, 1065, 1150,   57,  371,   45,\n",
       "       1150,  270,  657,  441,  517,    2]),\n",
       "       array([ 904, 1105,  489, 1087,  271,  657,  595,   60,    8,  703,  987,\n",
       "        515,  633,  825]),\n",
       "       array([  90, 1150,   57,  589,  247,  365,  597,    2, 1119,  150,  657,\n",
       "       1095,   32,  678, 1002]),\n",
       "       array([ 489, 1005, 1150, 1103,  783,  597,    2,  515, 1002,   12, 1150,\n",
       "        783,  597]),\n",
       "       array([992, 977, 991, 489, 428,   8, 858,   2, 633, 508, 271, 657, 213, 304]),\n",
       "       array([1002,  382,  910, 1118,  254,  515,  253, 1018,  338,  421, 1014]),\n",
       "       array([1150,  246,    2,  489, 1005, 1095,  246, 1150, 1103,  406, 1018,\n",
       "        846,  459,    2,   68, 1052,  668,    4]),\n",
       "       array([489, 536,   2, 612, 723, 523, 900, 458, 660,   2]),\n",
       "       array([  42,  489,  958, 1018,  341,  106,  555,  825,  660,  688,  270,\n",
       "        489,  441,  909, 1013, 1018,  999,   12,  517,  612,  723,  650,\n",
       "          3,  489,   97,  452,  112,  515,  989,  982, 1073,  622,  672,\n",
       "          2]),\n",
       "       array([ 979,  612,  723,  989,  748,  515,  720,  721, 1150,   60,  913,\n",
       "          3]),\n",
       "       array([ 489,  939,  585,  987,  443,  526,  469,  496,  989,   81,    2,\n",
       "        489, 1091,  603,    8,  921,    2,  612,  723, 1100, 1149,  192,\n",
       "       1018, 1151,  691,  177,  668,  323, 1002, 1146, 1019,  515,  307,\n",
       "         57,  794,  606,    2,  145,  989, 1094,  119,  515,  409,  822,\n",
       "        683, 1102,  794, 1100,  496,  159, 1150,   57,  509,    2]),\n",
       "       array([ 322,  633,  684,  515,  657,    8,  983,   18,    2,  612,  723,\n",
       "          2,  633,  633,    2, 1150,  441,   93,  984,  628,   30,    2]),\n",
       "       array([1145,    3]), array([   8,  332, 1025]), array([825,   2]),\n",
       "       array([825]), array([ 673, 1145,    2]), array([1150,  999]),\n",
       "       array([1145,    2,  489,  423,    2]),\n",
       "       array([ 204,  733,    2, 1150,    8,  332]), array([463,   2]),\n",
       "       array([ 462,  994,    2, 1015,  668,  134]),\n",
       "       array([ 591,  270,  657,  842,  875,  555,  987, 1018,  597,    2,  720,\n",
       "        150,  446, 1150,    2]),\n",
       "       array([ 961,  578,  815, 1011,  367]),\n",
       "       array([1150, 1103,  825,    2,  873,  515,  939,  738,    2]),\n",
       "       array([ 650,  489,  441,  413,    8,  520,  987,  489,   42,   12, 1018,\n",
       "        573,    2]),\n",
       "       array([ 904, 1150,  413,  216, 1125,  873, 1114,  940]),\n",
       "       array([ 489,   42, 1150,  425,  106]),\n",
       "       array([ 489,  759, 1018,  999,  668,  517,  886,   60,   44,   40, 1018,\n",
       "       1105,  989,  543,   35,    2]),\n",
       "       array([1145,    2]), array([ 309,   93, 1018,  182,  893]),\n",
       "       array([523, 365, 660,   2]),\n",
       "       array([  57, 1150,  978,  597,  489,   42,    8,  652]),\n",
       "       array([411, 304,   2]), array([1105]),\n",
       "       array([1095,   57, 1151,  425,    2]),\n",
       "       array([1150, 1050,   57,  454,  597,  972,  989, 1120,   87]),\n",
       "       array([ 712, 1150,   57,  657,  571,   68,  989,  108,  732,    2,  521,\n",
       "        515,  523,    8,  714,    2, 1095,  864, 1002, 1116,  997, 1067,\n",
       "        904,  150,  396,  989,  400,    2]),\n",
       "       array([904, 150, 396, 989, 400]),\n",
       "       array([ 987,  515, 1110, 1095,  150,  454, 1150,    2, 1125,    2]),\n",
       "       array([ 150,  746, 1115,  443, 1089,    2,  489,   42,  523,  496, 1002,\n",
       "        365,  989,  160,    2]),\n",
       "       array([ 489,  999,  489,  919,  206, 1109,  489,  842,  987,  515,  578,\n",
       "        515,  784,    2,  785,  985,  842,  521,  515,    2]),\n",
       "       array([1105,  515,  517, 1125, 1002,  174,  873,  441, 1007, 1017]),\n",
       "       array([989, 891, 515, 633, 591, 459, 436,   8, 586, 365,   2]),\n",
       "       array([1105,  740]),\n",
       "       array([1106,  989,  453,  517,  515, 1150,   57,  994, 1018,  842,    2]),\n",
       "       array([1105]), array([842, 517]),\n",
       "       array([ 853, 1150,  647, 1098,  612,  723, 1150,   57,  194,  250,    2]),\n",
       "       array([1100, 1150,  536,  994,  515,  989,  761,  668,  989,  520, 1016,\n",
       "          3,   45,  989,  102,  699,  515,  763,  411,    3,  612,  723,\n",
       "       1150, 1103,  657,   15, 1150,   57,  657,  951,   45,   60,  333,\n",
       "         60,  489,  150,  977, 1150,   57,  682,  897,  779,  904, 1119,\n",
       "        515,  517,  987, 1150,   57,  953,    8,  385]),\n",
       "       array([1105,  515, 1018,  267,  612,  723, 1119,  270,  657, 1095,  267,\n",
       "       1151,  283,  641, 1018,   86,    8,  457,  612,  723,  489,   42,\n",
       "         68,    8,  575,  992,    2, 1105,  880, 1095,  968,   12, 1151,\n",
       "       1146,  668,   14]),\n",
       "       array([1031,  668,  989,  360,    2,  612,  723,  489,  270,  657, 1059,\n",
       "          2, 1150,  441,  657,  276,   53,   61, 1002, 1098,    2,   57,\n",
       "       1150,  657,  342, 1100,  612,  723, 1125,  989,  976,  668, 1151,\n",
       "       1153]),\n",
       "       array([ 517, 1091,    8,  131,    2,  489, 1091,  293,  579,    2,  612,\n",
       "        723,  517,  843,  459, 1150,  321, 1152, 1018,    8,  422,  668,\n",
       "        379,  401,    2])], dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "class BasicProcessor(object):\n",
    "    \"\"\"Process data for estimators.\"\"\"\n",
    "        \n",
    "    def batch_process(self, X, y=None):\n",
    "        \"\"\"Make sure to have numpy data for input and target\"\"\"\n",
    "        if y is None:\n",
    "            return np.array(X)\n",
    "        else:\n",
    "            return np.array(X), np.array(y)\n",
    "\n",
    "    def batch_process_y(self, y):\n",
    "        return np.array(y)\n",
    "    \n",
    "class Word2IndexProcessor(BasicProcessor):\n",
    "    def __init__(self,  texts, is_processed=False):\n",
    "        _texts = []\n",
    "        lengths = []\n",
    "        for text in texts:\n",
    "            if is_processed:\n",
    "                words = text\n",
    "            else:\n",
    "                words = clean_text(text.lower(), max_dist=0, min_word_length=1)\n",
    "            if len(words) > 0:\n",
    "                _texts.extend(words)\n",
    "                lengths.append(len(words))\n",
    "        lengths = list(np.cumsum(lengths))\n",
    "        lengths.insert(0, 0)\n",
    "        self.encoder = preprocessing.LabelEncoder()\n",
    "        # 0 and 1 are taken for padding and <eos>\n",
    "        indices = self.encoder.fit_transform(_texts) + 2\n",
    "        # split to sentences\n",
    "        self.data = np.array([indices[lengths[i]:lengths[i+1]] for i in range(len(lengths) - 1)])\n",
    "        \n",
    "    def encode(self, text):\n",
    "        words = clean_text(text.lower())\n",
    "        return self.encoder.transform(words) + 2\n",
    "    \n",
    "    def decode(self, index):\n",
    "        return [self.encoder.inverse_transform(i-2) for i in index if i >=2]    \n",
    "            \n",
    "    \n",
    "    def batch_process_test(self, X, y=None):\n",
    "        if y is None:\n",
    "            return np.array([self.encode(x_i) for x_i in X])\n",
    "        else:\n",
    "            return np.array([self.encode(x_i) for x_i in X]), np.array(y)\n",
    "        \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 50s, sys: 1min 51s, total: 40min 42s\n",
      "Wall time: 40min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processor = Word2IndexProcessor(texts, is_processed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['you', 'guys', 'you', 'guys', 'chef', 'is', 'going', 'away', '.'],\n",
       " ['going', 'away', 'for', 'how', 'long'],\n",
       " ['forever', '.'],\n",
       " ['i', 'am', 'sorry', 'boys', '.'],\n",
       " ['chef',\n",
       "  'said',\n",
       "  'he',\n",
       "  'is',\n",
       "  'been',\n",
       "  'bored',\n",
       "  'so',\n",
       "  'he',\n",
       "  'joining',\n",
       "  'a',\n",
       "  'group',\n",
       "  'called',\n",
       "  'the',\n",
       "  'super',\n",
       "  'adventure',\n",
       "  'club',\n",
       "  '.'],\n",
       " ['wow'],\n",
       " ['chef',\n",
       "  'what',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'questions',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'adventuring',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'is',\n",
       "  'answer'],\n",
       " ['what', 'is', 'the', 'meaning', 'of', 'life', 'why', 'are', 'we', 'here'],\n",
       " ['i', 'hope', 'you', 'are', 'making', 'the', 'right', 'choice', '.'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'miss',\n",
       "  'him',\n",
       "  '.',\n",
       "  'i',\n",
       "  'am',\n",
       "  'miss',\n",
       "  'chef',\n",
       "  'and',\n",
       "  'i',\n",
       "  '...',\n",
       "  'and',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'him']]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[processor.decode(index) for index in processor.data[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['You guys, you guys! Chef is going away. \\n',\n",
       "       'Going away? For how long?\\n', 'Forever.\\n', \"I'm sorry boys.\\n\",\n",
       "       \"Chef said he's been bored, so he joining a group called the Super Adventure Club. \\n\",\n",
       "       'Wow!\\n',\n",
       "       'Chef?? What kind of questions do you think adventuring around the world is gonna answer?!\\n',\n",
       "       \"What's the meaning of life? Why are we here?\\n\",\n",
       "       \"I hope you're making the right choice.\\n\",\n",
       "       \"I'm gonna miss him.  I'm gonna miss Chef and I...and I don't know how to tell him! \\n\",\n",
       "       'Dude, how are we gonna go on? Chef was our fuh...f-ffriend. \\n',\n",
       "       'And we will all miss you, Chef,  but we know you must do what your heart tells you..\\n',\n",
       "       'Bye-bye!\\n', 'Good-bye!\\n', 'So long!\\n', 'So long, Chef!\\n',\n",
       "       'Good-bye, Chef!\\n',\n",
       "       'Good-bye, Chef! Have a great time with the Super Adventure Club!\\n',\n",
       "       'Good-bye! ..\\n', 'Draw two card, fatass.\\n',\n",
       "       'Reverse to you, Jew. \\n', \"I'll get it. \\n\",\n",
       "       'Hello there, children!\\n', \"He's back!\\n\", 'Yeah!\\n',\n",
       "       'All right! \\n', \"Chef! I can't believe you're back!\\n\",\n",
       "       \"Well, it's true.\\n\", 'But are you back for good?\\n',\n",
       "       \"That's right.\\n\", \"Hey everybody! Chef's back!\\n\",\n",
       "       'What? All right! Yeah! \\n', 'Oh, finally! \\n',\n",
       "       'Wow! It seems like you had a great time with the Super Adventure Club, Chef. They sound like really interesting people.\\n',\n",
       "       'Yeah!\\n',\n",
       "       \"But now that you're back here, does that mean that you're not in the Super Adventure Club anymore?\\n\",\n",
       "       'Nnono!\\n',\n",
       "       'Ohhh, so have you decided you can still belong to the Super Adventure Club but live here in South Park again?\\n',\n",
       "       \"That's right.\\n\",\n",
       "       'Well, it seems like the Super Adventure Club was just what you needed, Chef. You must be feeling very happy that you found a club to belong to with new friends, but that you can also live here in South Park with all your old friends whom you care for deeply.  Right?\\n',\n",
       "       \"That's right. Randy! \\n\",\n",
       "       \"Well Chef, you're welcome to stay with me until you buy another house.\\n\",\n",
       "       'Thank you. Jimbo.\\n',\n",
       "       \"Well, come on everybody. I'm sure Chef would like a little time to get moved back in.\\n\",\n",
       "       \"That's right! Thank you. Good-bye- Everybody.\\n\",\n",
       "       'Later. Great to have you back. Bye-bye. See ya Chef. See you later. Bye-bye\\n',\n",
       "       \"Well, I- guess we'll see you in school tomorrow, Chef.\\n\",\n",
       "       'You bet! Good-bye. Children! \\n', 'Right. Uh, see ya.\\n',\n",
       "       'Uh, guys? Did Chef seem a little, uh, trippy to you?\\n',\n",
       "       \"Well, look. he said he's happier now. Maybe he just needs to rest up a little.\\n\",\n",
       "       \"Yeah. I'm sure whatever that Super Adventure Club does is pretty tiring.\\n\",\n",
       "       \"Yeah, but whatever, I'm just glad he's back for good.\\n\",\n",
       "       '(Yeah, me too.)\\n',\n",
       "       \"It's really weird what he said. I don't know, it kind of confused me.\\n\",\n",
       "       \"Oh boy oh boy, I can't wait to have Chef's lunch food again.\\n\",\n",
       "       'Yeah. I hope he makes his Salisbury steak with buttered noodles! \\n',\n",
       "       'You guys, you guys.\\n', 'What?\\n',\n",
       "       \"Something's wrong with Chef. He's saying some really weird stuff.\\n\",\n",
       "       'Like what?\\n',\n",
       "       'I think...  I think he wants to have sex with me.\\n', 'What??\\n',\n",
       "       'I gotta- I gotta go. \\n', 'Weirdo. \\n', 'Hello there, children!\\n',\n",
       "       'Hey Chef.\\n', \"How's it goin'?\\n\", 'Good.\\n',\n",
       "       'Well, how about I meet you boys after work and we make love?\\n',\n",
       "       'Excuse me?\\n',\n",
       "       \"Come on, children! You're my sexual fantasy. Let's all make sweet love.\\n\",\n",
       "       '...Chef?? A-are you okay?\\n',\n",
       "       'I want to stick my balls inside your rectum, Kyle.\\n',\n",
       "       'Dude, what are you saying??\\n',\n",
       "       \"I'm gonna make love to your asshole, children.\\n\", '...WHAT??\\n',\n",
       "       \"Hi kids, I'm Detective Jarvis. I need to ask you all some difficult questions about your school cafeteria chef.\\n\",\n",
       "       \"This doesn't make any sense!\\n\",\n",
       "       'We have some information that all this time Chef has been and still is a pedophile.\\n',\n",
       "       \"No, he's not.\\n\", 'Uh huh.\\n', \"No, he's not.\\n\",\n",
       "       'Yeah, yeah he is so.\\n', \"What's a pedophile?\\n\",\n",
       "       \"Now, we need some testimony in order to arrest Chef,  so I'm gonna use this doll to ask you kids a few questions. Did Chef ever touch any of you... here? \\n\",\n",
       "       'NO!\\n', 'Okay, did he touch you here? \\n', 'NO!\\n',\n",
       "       'Did he ever do this? How about this? \\n',\n",
       "       'My Uncle Bud did that to me once! \\n',\n",
       "       'Did Chef ever try one of these on for size? \\n',\n",
       "       \"Goddammit, Chef isn't like that! Something funny is going on around here!\\n\",\n",
       "       'Young man, will you PLEASE pay attention! This is very important stuff! Ohhh. Ohhhhhh.\\n',\n",
       "       'Hello there, children!\\n',\n",
       "       'Chef, the police are asking questions about you!\\n',\n",
       "       \"Oh really? Well, let's all go home and make love.\\n\",\n",
       "       \"No, Chef, we don't wanna make love to you!\\n\",\n",
       "       'Kenny, how would you like to sodomize my black ass\\n',\n",
       "       'Chef, CHEF! You need to get out of here before you get arrested, all right?!\\n'], dtype=object)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The two structures don't have the same number of elements. First structure: LSTMStateTuple(c=<tf.Tensor 'encoder/while/Exit_2:0' shape=(?, 256) dtype=float32>, h=<tf.Tensor 'encoder/while/Exit_3:0' shape=(?, 256) dtype=float32>), second structure: AttentionWrapperState(cell_state=LSTMStateTuple(c=256, h=256), attention=256, time=TensorShape([]), alignments=<tf.Tensor 'LuongAttention/strided_slice_2:0' shape=() dtype=int32>, alignment_history=()).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-346-aa4e89a0c48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDialogueAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-341-c9b1951a0b22>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processor, maxlen, conf, *args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tomoaki/anaconda3/lib/python3.6/site-packages/hedgeable_ai-0.1.2-py3.6.egg/hedgeable_ai/models/nn/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, output_dim, model, conf, sess, default_conf, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_update_step_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# Build tensorboad graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-341-c9b1951a0b22>\u001b[0m in \u001b[0;36m_build_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mloop_fn_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_state\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mprevious_loop_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mdecoder_outputs_ta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_final_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_outputs_ta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mdecoder_max_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mraw_rnn\u001b[0;34m(cell, loop_fn, parallel_iterations, swap_memory, scope)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m     \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0mflat_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types)\u001b[0m\n\u001b[1;32m    144\u001b[0m     raise ValueError(\"The two structures don't have the same number of \"\n\u001b[1;32m    145\u001b[0m                      \u001b[0;34m\"elements. First structure: %s, second structure: %s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                      % (nest1, nest2))\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0m_recursive_assert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same number of elements. First structure: LSTMStateTuple(c=<tf.Tensor 'encoder/while/Exit_2:0' shape=(?, 256) dtype=float32>, h=<tf.Tensor 'encoder/while/Exit_3:0' shape=(?, 256) dtype=float32>), second structure: AttentionWrapperState(cell_state=LSTMStateTuple(c=256, h=256), attention=256, time=TensorShape([]), alignments=<tf.Tensor 'LuongAttention/strided_slice_2:0' shape=() dtype=int32>, alignment_history=())."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "conf = {\n",
    "        \"learning_rate\": 0.5,\n",
    "        \"learning_rate_minimum\": 0.5,\n",
    "        \"learning_rate_decay\": 0.9,\n",
    "        \"learning_rate_decay_step\": 20,\n",
    "        \"batch_size\": 128,\n",
    "        \"model_dir\": \"./logs\",\n",
    "        \"load_file_path\": None,\n",
    "        \"save_file_path\": None,\n",
    "        \"log_freq\": 1,\n",
    "        \"model\":{\"name\":\"lstm\", \"num_units\":256},\n",
    "        \"attension_size\": 512,\n",
    "}\n",
    "\n",
    "tf.reset_default_graph()\n",
    "agent = DialogueAgent(processor, maxlen=30, conf=conf)\n",
    "train_X = processor.data[:-1]\n",
    "train_y = processor.data[1:]\n",
    "agent.fit(train_X, train_y, num_epochs=10, batch_bar=True, log_freq=1, batch_log_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([75, 19, 53]), array([75, 19, 77]), array([33, 31, 67,  0]),\n",
       "       array([66, 55]), array([40, 35, 26,  0]), array([85]),\n",
       "       array([55, 86, 10, 50, 77, 39, 32, 77, 41,  0]), array([52]),\n",
       "       array([33,  6, 37,  0, 86, 38, 32, 68, 86, 36, 12, 76, 60,  8, 86, 19, 53,\n",
       "       38, 32, 77, 61]),\n",
       "       array([43, 48, 23, 54, 80, 59]), array([73, 62, 86,  0]),\n",
       "       array([82, 28, 70]),\n",
       "       array([33, 24, 86, 84, 25, 77, 73, 28, 70, 21,  0]),\n",
       "       array([71, 27, 34, 33, 29, 77, 30, 57, 47, 69,  3, 87, 16,  1]),\n",
       "       array([46,  0, 76, 20,  1, 11,  0, 33,  6, 43, 14, 49,  0]),\n",
       "       array([82, 17]), array([19, 86, 44, 77, 76, 17]), array([52,  1]),\n",
       "       array([74, 64, 34, 86, 26,  9, 42, 86, 10, 45, 43,  7, 22, 56,  2,  0]),\n",
       "       array([86,  5, 13, 76, 65]), array([15]),\n",
       "       array([74, 72, 35,  4, 86, 29, 77, 63,  0]), array([81, 52,  1]),\n",
       "       array([86, 51, 78, 77, 26, 58, 83, 18, 86])], dtype=object)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hope', 'had', 'selfish'],\n",
       " ['hope', 'had', 'selfish'],\n",
       " ['says', 'not'],\n",
       " ['not', 'would', 'and', 'my', 'they', 'learn'],\n",
       " ['hope', 'all', 'is'],\n",
       " ['hope',\n",
       "  'extra',\n",
       "  'would',\n",
       "  'what',\n",
       "  'fear',\n",
       "  'they',\n",
       "  'thank',\n",
       "  'go',\n",
       "  'sometimes',\n",
       "  'do'],\n",
       " ['would', 'about', 'babble', 'then', 'say'],\n",
       " ['hope',\n",
       "  'extra',\n",
       "  'would',\n",
       "  'what',\n",
       "  'fear',\n",
       "  'they',\n",
       "  'thank',\n",
       "  'go',\n",
       "  'sometimes',\n",
       "  'do'],\n",
       " ['need'],\n",
       " ['wearing', 'go', 'sometimes'],\n",
       " ['hope', 'had', 'selfish'],\n",
       " ['wearing', 'go', 'sometimes'],\n",
       " ['hope', 'to'],\n",
       " ['wearing', 'but'],\n",
       " ['hope', 'to'],\n",
       " ['hope',\n",
       "  'extra',\n",
       "  'would',\n",
       "  'what',\n",
       "  'fear',\n",
       "  'they',\n",
       "  'thank',\n",
       "  'go',\n",
       "  'sometimes',\n",
       "  'do'],\n",
       " ['hope', 'to'],\n",
       " ['not', 'would', 'and', 'my', 'they', 'kidding', 'hear'],\n",
       " ['but'],\n",
       " ['wearing', 'go', 'sometimes'],\n",
       " ['crap', 'would', 'lighter', 'they', 'then', 'but'],\n",
       " ['been'],\n",
       " ['hope',\n",
       "  'extra',\n",
       "  'would',\n",
       "  'what',\n",
       "  'fear',\n",
       "  'they',\n",
       "  'thank',\n",
       "  'go',\n",
       "  'sometimes',\n",
       "  'do'],\n",
       " ['hope', 'to'],\n",
       " ['would', 'myself', 'this', 'they', 'figured', 'on', 'well', 'coiffure']]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tilde = [(\" \").join(text) for text in texts[:100]]\n",
    "agent.generate_sentences(texts_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['theydonot',\n",
       " 'theydoto',\n",
       " 'ihopeso.',\n",
       " 'sheokay',\n",
       " 'letisgo.',\n",
       " 'wow',\n",
       " 'okayyouareneedtolearnhowtolie.',\n",
       " 'no',\n",
       " 'iamkidding.youknowhowsometimesyoujustbecomethispersonaandyoudonotknowhowtoquit',\n",
       " 'likemyfearofwearingpastels',\n",
       " 'therealyou.',\n",
       " 'whatgoodstuff',\n",
       " 'ifiguredyouwouldgettothegoodstuffeventually.',\n",
       " 'thankgodifihadtohearonemorestoryaboutyourcoiffure...',\n",
       " 'me.thisendless...babble.iamlikeboringmyself.',\n",
       " 'whatcrap',\n",
       " 'doyoulistentothiscrap',\n",
       " 'no...',\n",
       " 'thensaysifyougoanylighteryouarelooklikeanextraon90210.',\n",
       " 'youalwaysbeenthisselfish',\n",
       " 'but',\n",
       " 'thenthatisallyouhadtosay.',\n",
       " 'wellno...',\n",
       " 'youneverwantedtogooutwithdidyou',\n",
       " 'iwas']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.metrics import edit_distance\n",
    "import re\n",
    "import enchant\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "replacement_patterns = [\n",
    "    (r'won\\'t', 'will not'),\n",
    "    (r'can\\'t', 'cannot'),\n",
    "    (r'i\\'m', 'i am'),\n",
    "    (r'ain\\'t', 'is not'),\n",
    "    (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "    (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "    (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "    (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "    (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "    (r'(\\w+)\\'d', '\\g<1> would')\n",
    "]\n",
    "\n",
    "class RegexpReplacer(object):\n",
    "    def __init__(self, patterns=replacement_patterns):\n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "        \n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            s = re.sub(pattern, repl, s)\n",
    "        return s\n",
    "    \n",
    "\n",
    "class SpellingReplacer(object):\n",
    "    def __init__(self, dict_name=\"en\", max_dist=2):\n",
    "        self.spell_dict = enchant.Dict(dict_name)\n",
    "        self.max_dist = max_dist\n",
    "        \n",
    "    def replace(self, word):\n",
    "        if self.spell_dict.check(word):\n",
    "            return word\n",
    "        suggestions = self.spell_dict.suggest(word)\n",
    "        if suggestions and edit_distance(word, suggestions[0]) <= self.max_dist:\n",
    "            return suggestions[0]\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "class AntonymReplacer(object):\n",
    "    def replace(self, word, pos=None):\n",
    "        antonyms = set()\n",
    "        for syn in wordnet.synsets(word, pos=pos):\n",
    "            for lemma in syn.lemmas():\n",
    "                for antonym in lemma.antonyms():\n",
    "                    antonyms.add(antonym.name())\n",
    "        if len(antonyms) == 1:\n",
    "            return antonyms.pop()\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def replace_negations(self, sent):\n",
    "        i, length = 0, len(sent)\n",
    "        words = []\n",
    "        while i < length:\n",
    "            word = sent[i]\n",
    "            if word == \"not\" and i+1 < length:\n",
    "                ant = self.replace(sent[i+1])\n",
    "                if ant:\n",
    "                    words.append(ant)\n",
    "                    i += 2\n",
    "                    continue\n",
    "            words.append(word)\n",
    "            i += 1\n",
    "        return words\n",
    "\n",
    "\n",
    "class RepeatReplacer(object):\n",
    "    def __init__(self):\n",
    "        self.repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "        self.repl = r'\\1\\2\\3'\n",
    "        \n",
    "    def replace(self, word):\n",
    "        if wordnet.synsets(word):\n",
    "            return word\n",
    "        repl_word = self.repeat_regexp.sub(self.repl, word)\n",
    "        if repl_word != word:\n",
    "            return self.replace(repl_word)\n",
    "        else:\n",
    "            return repl_word\n",
    "        \n",
    "def clean_text(text, replace_neg=False, use_unknown=False, dict_name=\"en\",):\n",
    "    rep = RepeatReplacer()\n",
    "    ant = AntonymReplacer()\n",
    "    reg = RegexpReplacer()\n",
    "    spell = SpellingReplacer(dict_name)\n",
    "    # Get rid of some abbreviations\n",
    "    text = reg.replace(text)\n",
    "    words = word_tokenize(text)\n",
    "    if replace_neg:\n",
    "        words = ant.replace_negations(words)\n",
    "    words = [spell.replace(word) for word in words]\n",
    "    if not use_unknown:\n",
    "        spell_dict = enchant.Dict(dict_name)\n",
    "        words = [word for word in words if spell_dict.check(word)]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'do', 'not', 'swim', 'in', 'the', 'sea', '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(\"I don\\'t swim in the sea werwerwe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'do', \"n't\", 'swim', 'in', 'the', 'sea']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(\"I don\\'t swim in the sea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'evil', 'badness', 'bad', 'evilness', 'ill'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'not', 'good', 'guy']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer = AntonymReplacer()\n",
    "replacer.replace_negations([\"I\", \"am\",  \"not\",\"good\", \"guy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fuck'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmer.stem('fucking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I should have done that thing I did not do'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer = RegexpReplacer()\n",
    "replacer.replace(\"I should've done that thing I didn't do\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets(\"erqeqr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn.lemmas()[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i doingowerwe'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"i doingOwerwe\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a86796e3762f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreplacer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatReplacer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreplacer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ahhhhhhhhhhhhhhhhh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Looooove\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-12b00fda3f36>\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mrepl_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_regexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Hedgeable/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36msynsets\u001b[0;34m(self, lemma, pos, lang, check_exceptions)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0mof\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \"\"\"\n\u001b[0;32m-> 1483\u001b[0;31m         \u001b[0mlemma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eng'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "replacer = RepeatReplacer()\n",
    "replacer.replace([\"ahhhhhhhhhhhhhhhhh\", \"Looooove\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I specializes in your asshole, Kyle. \\n',\n",
       "       \"...Man, I can't believe all this time, Chef just wanted us for sex.\\n\",\n",
       "       \"He didn't want us for sex, fatass! Something is making him say those things.\\n\",\n",
       "       '(Like what?)\\n',\n",
       "       'Something must have happened to Chef while he was gone. Maybe he hit his head or, or got stuck in some quantum time vortex.\\n',\n",
       "       \"Well look: he spent the last three months with that adventurers' club. Maybe they know what happened to him.\\n\",\n",
       "       '(Yeah! I think...)\\n', 'Yeah!\\n', 'All right, come on guys!\\n',\n",
       "       \"Hey you guys, you know what they call a Jewish woman's boobs? Jewbs. \\n\",\n",
       "       'May I help you.\\n',\n",
       "       'Ahh, hi, can we speak to the head guy or something?\\n',\n",
       "       'Right this way. \\n',\n",
       "       \"Now, the upper rim of Kilimanjaro should be quite a trek, and so we'll need to have a-\\n\",\n",
       "       'Excuse me, sir. These boys wanted to speak with you.\\n',\n",
       "       \"Ahh yes, splendid! Good afternoon, lads! I'm Head Adventurer William P. Connolly, Esquire! Welcome, to the Super Adventure Club!\\n\",\n",
       "       'Tally ho!\\n', 'Indeed!\\n',\n",
       "       'Uh, hi. Our friend joined your club a while back, and now he wants to molest kids. \\n',\n",
       "       \"What? Well... well yes, of course! That's what the Super Adventure Club does!\\n\",\n",
       "       '...Huh?\\n', 'We travel the world and have sex with children!\\n',\n",
       "       'Yes, what else would we do?\\n',\n",
       "       'Well, we thought you went exploring and like, hunting and stuff!\\n',\n",
       "       \"Noo, no, that's the Adventure Club. We're the Super Adventure Club!  Next week, we'll be heading to the outer banks of the Amazon, where we will make camp and have sex with children of the Ugani tribe, then it's off to the mighty Himalayas, where we will climb K-2, and molest several Tibetan children on the east summit.\\n\",\n",
       "       '...Dude!\\n',\n",
       "       \"I know, but it gets even better! From there we will kayak to the fruitful banks of the Mele River in Africa, where the secret and mysterious Hanimi people have children who have never seen a white man's erect penis. Of course, we're always looking for kids to have sex with on the plane rides over to these places, so how would you ALL like to join the Super Adventure Club!\\n\",\n",
       "       'NO!!\\n',\n",
       "       'No? Oh really? Perhaps I should ask you again?  How would you like to join the Super Adventure Club? \\n',\n",
       "       'No! \\n', 'Dude, what are you doing?!\\n',\n",
       "       \"Oh well, it doesn't work on everybody.  Well, so long then.\\n\",\n",
       "       'Just what the hell is that thing?!\\n',\n",
       "       \"What? What thing? I don't see anything.\\n\", 'HA! I knew it!\\n',\n",
       "       'Knew what?\\n',\n",
       "       \"The reason Chef has been saying those terrible things about us is because he's been brainwashed! By this- fruity little club!\\n\",\n",
       "       'Oh, son of a bitch!\\n',\n",
       "       \"Come on, children. Let's all go home and make love.\\n\",\n",
       "       \"You need to see a psychiatrist, Chef. It's for your own good.\\n\",\n",
       "       'I just like to make love up your butt.\\n', 'Oh my God!\\n',\n",
       "       'Mr. Chef, is it?\\n', 'All right, come on. \\n',\n",
       "       \"Hello, I'm Dr. Neeland. What can I do for you today?\\n\",\n",
       "       'Hi, uh- our friend has been brainwashed by some fruity little club.\\n',\n",
       "       'Brainwashed.\\n',\n",
       "       'Yeah, he joined the Super Adventure Club, and they convinced him having sex with children was okay with a little thing that goes whrrrrrr.\\n',\n",
       "       'I thought that club was for hiking and kayaking.\\n',\n",
       "       \"No, that's the Adventure Club. The Super Adventure Club has sex with children.\\n\",\n",
       "       \"Oh. ...Oh, that's right, yeah.\\n\",\n",
       "       'Doctor, do you have- children?\\n',\n",
       "       'Why, yes, I have two young boys.\\n',\n",
       "       'Have you all been sodomizing your children too?\\n',\n",
       "       \"You say he's never been like this before?\\n\",\n",
       "       'No, Chef has always been super-cool.\\n',\n",
       "       \"I'm gonna make love to the children.\\n\",\n",
       "       \"He's pretty brainwashed all right. Worst case I've ever seen.\\n\",\n",
       "       'So what can we do??\\n',\n",
       "       \"I'm afraid there's no simple answer. When somebody's brainwashed it can take months, even years, to reverse the process.\\n\",\n",
       "       \"But we don't have years! If Chef keeps this up, he's gonna go to jail forever!\\n\",\n",
       "       \"Tell me, what was Chef's favorite thing to do before it was having sex with children?\\n\",\n",
       "       'Having sex with women.\\n',\n",
       "       \"Then that's it. We'd better get your friend to the Peppermint Hippo right away.\\n\",\n",
       "       'All right guys, be sure to tip the waitresses; this is two for one; put your hands together, this is Monique!\\n',\n",
       "       \"Aw, come on, children. Let's go home.\\n\", \"This isn't working.\\n\",\n",
       "       \"Well let's... give it some more time, kids. \\n\",\n",
       "       'Would you like to daaance???\\n',\n",
       "       \"No thanks. We're trying to unbrainwash our friend.\\n\",\n",
       "       'Daaance??? Anybody wanna daaance???\\n', 'Come on, bitch! Dance!\\n',\n",
       "       'Up yours, fatty.\\n', \"Bitch, I'll twist your nuts off!\\n\",\n",
       "       'All right guys, help me feel it out to them; we got a featured dancer coming out next; put your hands together for... Spontaneous Bootay! \\n',\n",
       "       'Come on guys, we might as well go. \\n', 'God-damn!\\n',\n",
       "       \"Chef, we're leaving.\\n\", 'Nono, wait. Let him go. \\n',\n",
       "       'Come here, chubby. \\n', 'Wait a minute.\\n', \"He's remembering.\\n\",\n",
       "       'Children! What have I done?\\n',\n",
       "       \"It's okay Chef. Go on, remember!\\n\", \"I'm goinna- I'm gonna-\\n\",\n",
       "       'Come on, Chef! You can do it!\\n',\n",
       "       \"I'm gonna make love to you woman, 'gonna lay you down by the fire!\\n\",\n",
       "       'Yay!\\n', '(Chef!)\\n', \"Hey children, everybody! I'm back!  Ow.\\n\",\n",
       "       'Great shot, William! Hit him with another. \\n', 'Oh! \\n',\n",
       "       'Chef!\\n',\n",
       "       \"Tally ho, lads! I must say you're starting to become quite a thorn in my balls.\\n\",\n",
       "       \"Where's Chef?! What have you done with him?!\\n\",\n",
       "       \"He's safe.  He's fasting in the Deprivation Room and being read the Super Adventure Club manual. We've got to undo the damage you've done.\\n\",\n",
       "       \"Look: If you wanna go around the world molesting kids, that's totally fine. But why do you need Chef?!\\n\",\n",
       "       \"We don't need him, he needs us! Our club offers hope. Do you think we go around the world molesting children just because it feels really really really really good?! No! Our club has a message! And a secret that explains the mysteries of life!\\n\",\n",
       "       'Oh Jesus, here we go.\\n',\n",
       "       \"Very well. I'm now going to tell you the secret of the Super Adventure Club.\\n\"], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"goin'ta\", 'aware', '=', 'footsteps', 'hover', 'loneliness', '='],\n",
       " ['forests', '-where'],\n",
       " ['hände', \"'loverboy\", 'sori', 'boyle', '-where'],\n",
       " ['cheesy',\n",
       "  'sahr',\n",
       "  'hbc',\n",
       "  \"'red\",\n",
       "  'beelzeboot',\n",
       "  'borders',\n",
       "  '+1',\n",
       "  'snusunarich',\n",
       "  'hbc',\n",
       "  'join',\n",
       "  '_________',\n",
       "  'groundings',\n",
       "  'call',\n",
       "  'thay',\n",
       "  'sunshine',\n",
       "  'advantaaage',\n",
       "  'clown',\n",
       "  '-where'],\n",
       " ['wounds'],\n",
       " ['cheesy',\n",
       "  '=',\n",
       "  '=',\n",
       "  'whassat',\n",
       "  'kincade',\n",
       "  'oen',\n",
       "  'question',\n",
       "  'dmvs',\n",
       "  'yorkshire',\n",
       "  'thingy',\n",
       "  'adventures',\n",
       "  'arose',\n",
       "  'thay',\n",
       "  'works',\n",
       "  'iru',\n",
       "  'gomez',\n",
       "  'n-word',\n",
       "  'another',\n",
       "  '='],\n",
       " ['whassat',\n",
       "  \"'red\",\n",
       "  'thay',\n",
       "  'meanest',\n",
       "  'oen',\n",
       "  'lieu',\n",
       "  '=',\n",
       "  'whup',\n",
       "  'arctic',\n",
       "  'wayward',\n",
       "  'herder',\n",
       "  '='],\n",
       " ['hände',\n",
       "  'hoowwdy',\n",
       "  'yorkshire',\n",
       "  \"'quiet\",\n",
       "  'make…pot-bellied',\n",
       "  'thay',\n",
       "  'rigged',\n",
       "  'chocolaty',\n",
       "  '-where'],\n",
       " ['hände',\n",
       "  \"'loverboy\",\n",
       "  'gomez',\n",
       "  'n-word',\n",
       "  'misled',\n",
       "  'hilt',\n",
       "  '-where',\n",
       "  'hände',\n",
       "  \"'loverboy\",\n",
       "  'gomez',\n",
       "  'n-word',\n",
       "  'misled',\n",
       "  'cheesy',\n",
       "  'ancient',\n",
       "  'hände',\n",
       "  '.',\n",
       "  'ancient',\n",
       "  'hände',\n",
       "  'dmvs',\n",
       "  \"n'aw\",\n",
       "  'knoooow',\n",
       "  'hover',\n",
       "  'tm',\n",
       "  'television/cd',\n",
       "  'hilt']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[processor.decode(text) for text in processor.data[1:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['you', 'guys', 'e', 'you', 'guys', 'e', 'chef', 'is', 'going', 'away', '.'],\n",
       " ['going', 'away', 'e', 'for', 'how', 'long', 'e'],\n",
       " ['forever', '.'],\n",
       " ['i', 'm', 'sorry', 'boys', '.'],\n",
       " ['chef',\n",
       "  'said',\n",
       "  'he',\n",
       "  'is',\n",
       "  'been',\n",
       "  'bored',\n",
       "  'e',\n",
       "  'so',\n",
       "  'he',\n",
       "  'joining',\n",
       "  'a',\n",
       "  'group',\n",
       "  'called',\n",
       "  'the',\n",
       "  'super',\n",
       "  'adventure',\n",
       "  'club',\n",
       "  '.'],\n",
       " ['wow', 'e'],\n",
       " ['chef',\n",
       "  'e',\n",
       "  'e',\n",
       "  'what',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'questions',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'adventuring',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'is',\n",
       "  'hon',\n",
       "  'an',\n",
       "  'answer',\n",
       "  'e',\n",
       "  'e'],\n",
       " ['what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'meaning',\n",
       "  'of',\n",
       "  'life',\n",
       "  'e',\n",
       "  'why',\n",
       "  'are',\n",
       "  'we',\n",
       "  'here',\n",
       "  'e'],\n",
       " ['i', 'hope', 'you', 'are', 'making', 'the', 'right', 'choice', '.'],\n",
       " ['i',\n",
       "  'm',\n",
       "  'hon',\n",
       "  'an',\n",
       "  'miss',\n",
       "  'him',\n",
       "  '.',\n",
       "  'i',\n",
       "  'm',\n",
       "  'hon',\n",
       "  'an',\n",
       "  'miss',\n",
       "  'chef',\n",
       "  'and',\n",
       "  'i',\n",
       "  '...',\n",
       "  'and',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'him',\n",
       "  'e'],\n",
       " ['dude',\n",
       "  'e',\n",
       "  'how',\n",
       "  'are',\n",
       "  'we',\n",
       "  'hon',\n",
       "  'an',\n",
       "  'go',\n",
       "  'on',\n",
       "  'e',\n",
       "  'chef',\n",
       "  'was',\n",
       "  'our',\n",
       "  'duh',\n",
       "  '...',\n",
       "  'f-friend',\n",
       "  '.'],\n",
       " ['and',\n",
       "  'we',\n",
       "  'will',\n",
       "  'all',\n",
       "  'miss',\n",
       "  'you',\n",
       "  'e',\n",
       "  'chef',\n",
       "  'e',\n",
       "  'but',\n",
       "  'we',\n",
       "  'know',\n",
       "  'you',\n",
       "  'must',\n",
       "  'do',\n",
       "  'what',\n",
       "  'your',\n",
       "  'heart',\n",
       "  'tells',\n",
       "  'you..'],\n",
       " ['bye-bye', 'e'],\n",
       " ['good-bye', 'e'],\n",
       " ['so', 'long', 'e'],\n",
       " ['so', 'long', 'e', 'chef', 'e'],\n",
       " ['good-bye', 'e', 'chef', 'e'],\n",
       " ['good-bye',\n",
       "  'e',\n",
       "  'chef',\n",
       "  'e',\n",
       "  'have',\n",
       "  'a',\n",
       "  'great',\n",
       "  'time',\n",
       "  'with',\n",
       "  'the',\n",
       "  'super',\n",
       "  'adventure',\n",
       "  'club',\n",
       "  'e'],\n",
       " ['good-bye', 'e', '..'],\n",
       " ['draw', 'two', 'card', 'e', 'fatals', '.'],\n",
       " ['reverse', 'to', 'you', 'e', 'jew', '.'],\n",
       " ['i', 'will', 'get', 'it', '.'],\n",
       " ['hello', 'there', 'e', 'children', 'e'],\n",
       " ['he', 'is', 'back', 'e'],\n",
       " ['yeah', 'e'],\n",
       " ['all', 'right', 'e'],\n",
       " ['chef', 'e', 'i', 'can', 'not', 'believe', 'you', 'are', 'back', 'e'],\n",
       " ['well', 'e', 'it', 'is', 'true', '.'],\n",
       " ['but', 'are', 'you', 'back', 'for', 'good', 'e'],\n",
       " ['that', 'is', 'right', '.'],\n",
       " ['hey', 'everybody', 'e', 'chef', 'is', 'back', 'e'],\n",
       " ['what', 'e', 'all', 'right', 'e', 'yeah', 'e'],\n",
       " ['oh', 'e', 'finally', 'e'],\n",
       " ['wow',\n",
       "  'e',\n",
       "  'it',\n",
       "  'seems',\n",
       "  'like',\n",
       "  'you',\n",
       "  'had',\n",
       "  'a',\n",
       "  'great',\n",
       "  'time',\n",
       "  'with',\n",
       "  'the',\n",
       "  'super',\n",
       "  'adventure',\n",
       "  'club',\n",
       "  'e',\n",
       "  'chef',\n",
       "  '.',\n",
       "  'they',\n",
       "  'sound',\n",
       "  'like',\n",
       "  'really',\n",
       "  'interesting',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['yeah', 'e'],\n",
       " ['but',\n",
       "  'now',\n",
       "  'that',\n",
       "  'you',\n",
       "  'are',\n",
       "  'back',\n",
       "  'here',\n",
       "  'e',\n",
       "  'does',\n",
       "  'that',\n",
       "  'mean',\n",
       "  'that',\n",
       "  'you',\n",
       "  'are',\n",
       "  'not',\n",
       "  'in',\n",
       "  'the',\n",
       "  'super',\n",
       "  'adventure',\n",
       "  'club',\n",
       "  'anymore',\n",
       "  'e'],\n",
       " ['e'],\n",
       " ['e',\n",
       "  'so',\n",
       "  'have',\n",
       "  'you',\n",
       "  'decided',\n",
       "  'you',\n",
       "  'can',\n",
       "  'still',\n",
       "  'belong',\n",
       "  'to',\n",
       "  'the',\n",
       "  'super',\n",
       "  'adventure',\n",
       "  'club',\n",
       "  'but',\n",
       "  'live',\n",
       "  'here',\n",
       "  'in',\n",
       "  'south',\n",
       "  'park',\n",
       "  'again',\n",
       "  'e'],\n",
       " ['that', 'is', 'right', '.'],\n",
       " ['well',\n",
       "  'e',\n",
       "  'it',\n",
       "  'seems',\n",
       "  'like',\n",
       "  'the',\n",
       "  'super',\n",
       "  'adventure',\n",
       "  'club',\n",
       "  'was',\n",
       "  'just',\n",
       "  'what',\n",
       "  'you',\n",
       "  'needed',\n",
       "  'e',\n",
       "  'chef',\n",
       "  '.',\n",
       "  'you',\n",
       "  'must',\n",
       "  'be',\n",
       "  'feeling',\n",
       "  'very',\n",
       "  'happy',\n",
       "  'that',\n",
       "  'you',\n",
       "  'found',\n",
       "  'a',\n",
       "  'club',\n",
       "  'to',\n",
       "  'belong',\n",
       "  'to',\n",
       "  'with',\n",
       "  'new',\n",
       "  'friends',\n",
       "  'e',\n",
       "  'but',\n",
       "  'that',\n",
       "  'you',\n",
       "  'can',\n",
       "  'also',\n",
       "  'live',\n",
       "  'here',\n",
       "  'in',\n",
       "  'south',\n",
       "  'park',\n",
       "  'with',\n",
       "  'all',\n",
       "  'your',\n",
       "  'old',\n",
       "  'friends',\n",
       "  'whom',\n",
       "  'you',\n",
       "  'care',\n",
       "  'for',\n",
       "  'deeply',\n",
       "  '.',\n",
       "  'right',\n",
       "  'e'],\n",
       " ['that', 'is', 'right', '.', 'randy', 'e'],\n",
       " ['well',\n",
       "  'chef',\n",
       "  'e',\n",
       "  'you',\n",
       "  'are',\n",
       "  'welcome',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'with',\n",
       "  'me',\n",
       "  'until',\n",
       "  'you',\n",
       "  'buy',\n",
       "  'another',\n",
       "  'house',\n",
       "  '.'],\n",
       " ['thank', 'you', '.', 'limbo', '.'],\n",
       " ['well',\n",
       "  'e',\n",
       "  'come',\n",
       "  'on',\n",
       "  'everybody',\n",
       "  '.',\n",
       "  'i',\n",
       "  'm',\n",
       "  'sure',\n",
       "  'chef',\n",
       "  'would',\n",
       "  'like',\n",
       "  'a',\n",
       "  'little',\n",
       "  'time',\n",
       "  'to',\n",
       "  'get',\n",
       "  'moved',\n",
       "  'back',\n",
       "  'in',\n",
       "  '.'],\n",
       " ['that',\n",
       "  'is',\n",
       "  'right',\n",
       "  'e',\n",
       "  'thank',\n",
       "  'you',\n",
       "  '.',\n",
       "  'good-bye-',\n",
       "  'everybody',\n",
       "  '.'],\n",
       " ['later',\n",
       "  '.',\n",
       "  'great',\n",
       "  'to',\n",
       "  'have',\n",
       "  'you',\n",
       "  'back',\n",
       "  '.',\n",
       "  'bye-bye',\n",
       "  '.',\n",
       "  'see',\n",
       "  'ya',\n",
       "  'chef',\n",
       "  '.',\n",
       "  'see',\n",
       "  'you',\n",
       "  'later',\n",
       "  '.',\n",
       "  'bye-bye'],\n",
       " ['well',\n",
       "  'e',\n",
       "  'i-',\n",
       "  'guess',\n",
       "  'we',\n",
       "  'will',\n",
       "  'see',\n",
       "  'you',\n",
       "  'in',\n",
       "  'school',\n",
       "  'tomorrow',\n",
       "  'e',\n",
       "  'chef',\n",
       "  '.'],\n",
       " ['you', 'bet', 'e', 'good-bye', '.', 'children', 'e'],\n",
       " ['right', '.', 'uh', 'e', 'see', 'ya', '.'],\n",
       " ['uh',\n",
       "  'e',\n",
       "  'guys',\n",
       "  'e',\n",
       "  'did',\n",
       "  'chef',\n",
       "  'seem',\n",
       "  'a',\n",
       "  'little',\n",
       "  'e',\n",
       "  'uh',\n",
       "  'e',\n",
       "  'tippy',\n",
       "  'to',\n",
       "  'you',\n",
       "  'e'],\n",
       " ['well',\n",
       "  'e',\n",
       "  'look',\n",
       "  '.',\n",
       "  'he',\n",
       "  'said',\n",
       "  'he',\n",
       "  'is',\n",
       "  'happier',\n",
       "  'now',\n",
       "  '.',\n",
       "  'maybe',\n",
       "  'he',\n",
       "  'just',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'rest',\n",
       "  'up',\n",
       "  'a',\n",
       "  'little',\n",
       "  '.'],\n",
       " ['yeah',\n",
       "  '.',\n",
       "  'i',\n",
       "  'm',\n",
       "  'sure',\n",
       "  'whatever',\n",
       "  'that',\n",
       "  'super',\n",
       "  'adventure',\n",
       "  'club',\n",
       "  'does',\n",
       "  'is',\n",
       "  'pretty',\n",
       "  'tiring',\n",
       "  '.'],\n",
       " ['yeah',\n",
       "  'e',\n",
       "  'but',\n",
       "  'whatever',\n",
       "  'e',\n",
       "  'i',\n",
       "  'm',\n",
       "  'just',\n",
       "  'glad',\n",
       "  'he',\n",
       "  'is',\n",
       "  'back',\n",
       "  'for',\n",
       "  'good',\n",
       "  '.'],\n",
       " ['e', 'yeah', 'e', 'me', 'too', '.', 'e'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'really',\n",
       "  'weird',\n",
       "  'what',\n",
       "  'he',\n",
       "  'said',\n",
       "  '.',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'e',\n",
       "  'it',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'confused',\n",
       "  'me',\n",
       "  '.'],\n",
       " ['oh',\n",
       "  'boy',\n",
       "  'oh',\n",
       "  'boy',\n",
       "  'e',\n",
       "  'i',\n",
       "  'can',\n",
       "  'not',\n",
       "  'wait',\n",
       "  'to',\n",
       "  'have',\n",
       "  'chef',\n",
       "  'is',\n",
       "  'lunch',\n",
       "  'food',\n",
       "  'again',\n",
       "  '.'],\n",
       " ['yeah',\n",
       "  '.',\n",
       "  'i',\n",
       "  'hope',\n",
       "  'he',\n",
       "  'makes',\n",
       "  'his',\n",
       "  'salisbury',\n",
       "  'steak',\n",
       "  'with',\n",
       "  'buttered',\n",
       "  'noodles',\n",
       "  'e'],\n",
       " ['you', 'guys', 'e', 'you', 'guys', '.'],\n",
       " ['what', 'e'],\n",
       " ['something',\n",
       "  'is',\n",
       "  'wrong',\n",
       "  'with',\n",
       "  'chef',\n",
       "  '.',\n",
       "  'he',\n",
       "  'is',\n",
       "  'saying',\n",
       "  'some',\n",
       "  'really',\n",
       "  'weird',\n",
       "  'stuff',\n",
       "  '.'],\n",
       " ['like', 'what', 'e'],\n",
       " ['i',\n",
       "  'think',\n",
       "  '...',\n",
       "  'i',\n",
       "  'think',\n",
       "  'he',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'have',\n",
       "  'sex',\n",
       "  'with',\n",
       "  'me',\n",
       "  '.'],\n",
       " ['what', 'e', 'e'],\n",
       " ['i', 'got', 'ta', 'e', 'i', 'got', 'ta', 'go', '.'],\n",
       " ['weirdo', '.'],\n",
       " ['hello', 'there', 'e', 'children', 'e'],\n",
       " ['hey', 'chef', '.'],\n",
       " ['how', 'is', 'it', 'goon', 'e', 'e'],\n",
       " ['good', '.'],\n",
       " ['well',\n",
       "  'e',\n",
       "  'how',\n",
       "  'about',\n",
       "  'i',\n",
       "  'meet',\n",
       "  'you',\n",
       "  'boys',\n",
       "  'after',\n",
       "  'work',\n",
       "  'and',\n",
       "  'we',\n",
       "  'make',\n",
       "  'love',\n",
       "  'e'],\n",
       " ['excuse', 'me', 'e'],\n",
       " ['come',\n",
       "  'on',\n",
       "  'e',\n",
       "  'children',\n",
       "  'e',\n",
       "  'you',\n",
       "  'are',\n",
       "  'my',\n",
       "  'sexual',\n",
       "  'fantasy',\n",
       "  '.',\n",
       "  'let',\n",
       "  'is',\n",
       "  'all',\n",
       "  'make',\n",
       "  'sweet',\n",
       "  'love',\n",
       "  '.'],\n",
       " ['...', 'chef', 'e', 'e', 'a-are', 'you', 'okay', 'e'],\n",
       " ['i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'stick',\n",
       "  'my',\n",
       "  'balls',\n",
       "  'inside',\n",
       "  'your',\n",
       "  'rectum',\n",
       "  'e',\n",
       "  'kyle',\n",
       "  '.'],\n",
       " ['dude', 'e', 'what', 'are', 'you', 'saying', 'e', 'e'],\n",
       " ['i',\n",
       "  'm',\n",
       "  'hon',\n",
       "  'an',\n",
       "  'make',\n",
       "  'love',\n",
       "  'to',\n",
       "  'your',\n",
       "  'asshole',\n",
       "  'e',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['...', 'what', 'e', 'e'],\n",
       " ['hi',\n",
       "  'kids',\n",
       "  'e',\n",
       "  'i',\n",
       "  'm',\n",
       "  'detective',\n",
       "  'jarvis',\n",
       "  '.',\n",
       "  'i',\n",
       "  'need',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'you',\n",
       "  'all',\n",
       "  'some',\n",
       "  'difficult',\n",
       "  'questions',\n",
       "  'about',\n",
       "  'your',\n",
       "  'school',\n",
       "  'cafeteria',\n",
       "  'chef',\n",
       "  '.'],\n",
       " ['this', 'does', 'not', 'make', 'any', 'sense', 'e'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'some',\n",
       "  'information',\n",
       "  'that',\n",
       "  'all',\n",
       "  'this',\n",
       "  'time',\n",
       "  'chef',\n",
       "  'has',\n",
       "  'been',\n",
       "  'and',\n",
       "  'still',\n",
       "  'is',\n",
       "  'a',\n",
       "  'pedophile',\n",
       "  '.'],\n",
       " ['no', 'e', 'he', 'is', 'not', '.'],\n",
       " ['uh', 'huh', '.'],\n",
       " ['no', 'e', 'he', 'is', 'not', '.'],\n",
       " ['yeah', 'e', 'yeah', 'he', 'is', 'so', '.'],\n",
       " ['what', 'is', 'a', 'pedophile', 'e'],\n",
       " ['now',\n",
       "  'e',\n",
       "  'we',\n",
       "  'need',\n",
       "  'some',\n",
       "  'testimony',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'arrest',\n",
       "  'chef',\n",
       "  'e',\n",
       "  'so',\n",
       "  'i',\n",
       "  'm',\n",
       "  'hon',\n",
       "  'an',\n",
       "  'use',\n",
       "  'this',\n",
       "  'doll',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'you',\n",
       "  'kids',\n",
       "  'a',\n",
       "  'few',\n",
       "  'questions',\n",
       "  '.',\n",
       "  'did',\n",
       "  'chef',\n",
       "  'ever',\n",
       "  'touch',\n",
       "  'any',\n",
       "  'of',\n",
       "  'you',\n",
       "  '...',\n",
       "  'here',\n",
       "  'e'],\n",
       " ['no', 'e'],\n",
       " ['okay', 'e', 'did', 'he', 'touch', 'you', 'here', 'e'],\n",
       " ['no', 'e'],\n",
       " ['did', 'he', 'ever', 'do', 'this', 'e', 'how', 'about', 'this', 'e'],\n",
       " ['my', 'uncle', 'bud', 'did', 'that', 'to', 'me', 'once', 'e'],\n",
       " ['did',\n",
       "  'chef',\n",
       "  'ever',\n",
       "  'try',\n",
       "  'one',\n",
       "  'of',\n",
       "  'these',\n",
       "  'on',\n",
       "  'for',\n",
       "  'size',\n",
       "  'e'],\n",
       " ['goddammit',\n",
       "  'e',\n",
       "  'chef',\n",
       "  'is',\n",
       "  'not',\n",
       "  'like',\n",
       "  'that',\n",
       "  'e',\n",
       "  'something',\n",
       "  'funny',\n",
       "  'is',\n",
       "  'going',\n",
       "  'on',\n",
       "  'around',\n",
       "  'here',\n",
       "  'e'],\n",
       " ['young',\n",
       "  'man',\n",
       "  'e',\n",
       "  'will',\n",
       "  'you',\n",
       "  'please',\n",
       "  'pay',\n",
       "  'attention',\n",
       "  'e',\n",
       "  'this',\n",
       "  'is',\n",
       "  'very',\n",
       "  'important',\n",
       "  'stuff',\n",
       "  'e',\n",
       "  '.',\n",
       "  '.'],\n",
       " ['hello', 'there', 'e', 'children', 'e'],\n",
       " ['chef',\n",
       "  'e',\n",
       "  'the',\n",
       "  'police',\n",
       "  'are',\n",
       "  'asking',\n",
       "  'questions',\n",
       "  'about',\n",
       "  'you',\n",
       "  'e'],\n",
       " ['oh',\n",
       "  'really',\n",
       "  'e',\n",
       "  'well',\n",
       "  'e',\n",
       "  'let',\n",
       "  'is',\n",
       "  'all',\n",
       "  'go',\n",
       "  'home',\n",
       "  'and',\n",
       "  'make',\n",
       "  'love',\n",
       "  '.'],\n",
       " ['no',\n",
       "  'e',\n",
       "  'chef',\n",
       "  'e',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'wan',\n",
       "  'an',\n",
       "  'make',\n",
       "  'love',\n",
       "  'to',\n",
       "  'you',\n",
       "  'e'],\n",
       " ['kenny',\n",
       "  'e',\n",
       "  'how',\n",
       "  'would',\n",
       "  'you',\n",
       "  'like',\n",
       "  'to',\n",
       "  'sodomize',\n",
       "  'my',\n",
       "  'black',\n",
       "  'ass'],\n",
       " ['chef',\n",
       "  'e',\n",
       "  'chef',\n",
       "  'e',\n",
       "  'you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'get',\n",
       "  'out',\n",
       "  'of',\n",
       "  'here',\n",
       "  'before',\n",
       "  'you',\n",
       "  'get',\n",
       "  'arrested',\n",
       "  'e',\n",
       "  'all',\n",
       "  'right',\n",
       "  'e',\n",
       "  'e']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[processor.decode(text) for text in processor.data[:100]+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['You guys, you guys! Chef is going away. \\n',\n",
       "       'Going away? For how long?\\n', 'Forever.\\n', \"I'm sorry boys.\\n\",\n",
       "       \"Chef said he's been bored, so he joining a group called the Super Adventure Club. \\n\",\n",
       "       'Wow!\\n',\n",
       "       'Chef?? What kind of questions do you think adventuring around the world is gonna answer?!\\n',\n",
       "       \"What's the meaning of life? Why are we here?\\n\",\n",
       "       \"I hope you're making the right choice.\\n\",\n",
       "       \"I'm gonna miss him.  I'm gonna miss Chef and I...and I don't know how to tell him! \\n\"], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "sentence = nltk.word_tokenize(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.11404028436019"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(x) for x in processor.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 263 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index = processor.batch_process(processor.data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 21)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xt, xlen = batch(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  3,  6, 10, 15, 21, 28, 36, 45])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "np.cumsum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.seq2seq as seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_texts = []\n",
    "lengths = []\n",
    "for text in texts:\n",
    "    words = nltk.word_tokenize(text)\n",
    "    _texts.extend(words)\n",
    "    lengths.append(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths.insert(0, 0)\n",
    "# lenghts = np.cumsum(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      0,      11,      18, ..., 1071516, 1071523, 1071525])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "_lengths = deepcopy(lengths)\n",
    "_lengths.insert(0, 0)\n",
    "np.cumsum(_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_texts = []\n",
    "lengths = []\n",
    "for text in texts:\n",
    "    words = nltk.word_tokenize(text)\n",
    "    _texts.extend(words)\n",
    "    lengths.append(len(words))\n",
    "lengths = list(np.cumsum(lengths))\n",
    "lengths.insert(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 11,\n",
       " 18,\n",
       " 20,\n",
       " 25,\n",
       " 43,\n",
       " 45,\n",
       " 65,\n",
       " 77,\n",
       " 86,\n",
       " 112,\n",
       " 129,\n",
       " 149,\n",
       " 151,\n",
       " 153,\n",
       " 156,\n",
       " 161,\n",
       " 165,\n",
       " 179,\n",
       " 182,\n",
       " 188,\n",
       " 194,\n",
       " 199,\n",
       " 204,\n",
       " 208,\n",
       " 210,\n",
       " 213,\n",
       " 223,\n",
       " 229,\n",
       " 236,\n",
       " 240,\n",
       " 247,\n",
       " 254,\n",
       " 258,\n",
       " 283,\n",
       " 285,\n",
       " 307,\n",
       " 309,\n",
       " 332,\n",
       " 336,\n",
       " 394,\n",
       " 400,\n",
       " 416,\n",
       " 421,\n",
       " 442,\n",
       " 452,\n",
       " 471,\n",
       " 485,\n",
       " 492,\n",
       " 499,\n",
       " 515,\n",
       " 536,\n",
       " 551,\n",
       " 566,\n",
       " 573,\n",
       " 592,\n",
       " 609,\n",
       " 622,\n",
       " 628,\n",
       " 630,\n",
       " 644,\n",
       " 647,\n",
       " 660,\n",
       " 663,\n",
       " 672,\n",
       " 674,\n",
       " 679,\n",
       " 682,\n",
       " 688,\n",
       " 690,\n",
       " 705,\n",
       " 708,\n",
       " 726,\n",
       " 734,\n",
       " 746,\n",
       " 754,\n",
       " 766,\n",
       " 770,\n",
       " 793,\n",
       " 800,\n",
       " 817,\n",
       " 823,\n",
       " 826,\n",
       " 832,\n",
       " 839,\n",
       " 844,\n",
       " 882,\n",
       " 884,\n",
       " 892,\n",
       " 894,\n",
       " 904,\n",
       " 913,\n",
       " 924,\n",
       " 940,\n",
       " 959,\n",
       " 964,\n",
       " 974,\n",
       " 988,\n",
       " 1002,\n",
       " 1013,\n",
       " 1033,\n",
       " 1041,\n",
       " 1059,\n",
       " 1077,\n",
       " 1082,\n",
       " 1109,\n",
       " 1132,\n",
       " 1139,\n",
       " 1141,\n",
       " 1148,\n",
       " 1165,\n",
       " 1170,\n",
       " 1184,\n",
       " 1188,\n",
       " 1209,\n",
       " 1222,\n",
       " 1250,\n",
       " 1253,\n",
       " 1255,\n",
       " 1276,\n",
       " 1295,\n",
       " 1298,\n",
       " 1308,\n",
       " 1316,\n",
       " 1330,\n",
       " 1402,\n",
       " 1405,\n",
       " 1485,\n",
       " 1488,\n",
       " 1511,\n",
       " 1513,\n",
       " 1521,\n",
       " 1537,\n",
       " 1546,\n",
       " 1557,\n",
       " 1563,\n",
       " 1566,\n",
       " 1590,\n",
       " 1597,\n",
       " 1611,\n",
       " 1627,\n",
       " 1637,\n",
       " 1641,\n",
       " 1648,\n",
       " 1654,\n",
       " 1669,\n",
       " 1683,\n",
       " 1685,\n",
       " 1712,\n",
       " 1722,\n",
       " 1739,\n",
       " 1750,\n",
       " 1757,\n",
       " 1767,\n",
       " 1776,\n",
       " 1786,\n",
       " 1794,\n",
       " 1804,\n",
       " 1818,\n",
       " 1825,\n",
       " 1851,\n",
       " 1873,\n",
       " 1892,\n",
       " 1897,\n",
       " 1915,\n",
       " 1941,\n",
       " 1953,\n",
       " 1958,\n",
       " 1970,\n",
       " 1978,\n",
       " 1989,\n",
       " 2000,\n",
       " 2007,\n",
       " 2012,\n",
       " 2021,\n",
       " 2051,\n",
       " 2061,\n",
       " 2063,\n",
       " 2069,\n",
       " 2077,\n",
       " 2082,\n",
       " 2086,\n",
       " 2090,\n",
       " 2097,\n",
       " 2107,\n",
       " 2115,\n",
       " 2125,\n",
       " 2145,\n",
       " 2147,\n",
       " 2151,\n",
       " 2162,\n",
       " 2172,\n",
       " 2174,\n",
       " 2176,\n",
       " 2196,\n",
       " 2209,\n",
       " 2240,\n",
       " 2266,\n",
       " 2320,\n",
       " 2327,\n",
       " 2345,\n",
       " 2353,\n",
       " 2505,\n",
       " 2507,\n",
       " 2578,\n",
       " 2587,\n",
       " 2621,\n",
       " 2631,\n",
       " 2665,\n",
       " 2672,\n",
       " 2740,\n",
       " 2748,\n",
       " 2793,\n",
       " 2800,\n",
       " 2804,\n",
       " 2817,\n",
       " 2834,\n",
       " 2846,\n",
       " 2861,\n",
       " 2871,\n",
       " 2876,\n",
       " 2878,\n",
       " 2883,\n",
       " 2890,\n",
       " 2894,\n",
       " 2899,\n",
       " 2907,\n",
       " 2909,\n",
       " 2912,\n",
       " 2922,\n",
       " 2925,\n",
       " 2928,\n",
       " 2932,\n",
       " 2934,\n",
       " 2938,\n",
       " 2953,\n",
       " 2958,\n",
       " 2978,\n",
       " 2996,\n",
       " 3017,\n",
       " 3023,\n",
       " 3028,\n",
       " 3047,\n",
       " 3057,\n",
       " 3072,\n",
       " 3074,\n",
       " 3089,\n",
       " 3091,\n",
       " 3095,\n",
       " 3105,\n",
       " 3107,\n",
       " 3112,\n",
       " 3114,\n",
       " 3118,\n",
       " 3126,\n",
       " 3132,\n",
       " 3143,\n",
       " 3167,\n",
       " 3169,\n",
       " 3173,\n",
       " 3180,\n",
       " 3322,\n",
       " 3324,\n",
       " 3328,\n",
       " 3356,\n",
       " 3364,\n",
       " 3372,\n",
       " 3402,\n",
       " 3415,\n",
       " 3420,\n",
       " 3437,\n",
       " 3446,\n",
       " 3453,\n",
       " 3459,\n",
       " 3464,\n",
       " 3472,\n",
       " 3498,\n",
       " 3504,\n",
       " 3508,\n",
       " 3518,\n",
       " 3536,\n",
       " 3568,\n",
       " 3592,\n",
       " 3599,\n",
       " 3611,\n",
       " 3637,\n",
       " 3639,\n",
       " 3649,\n",
       " 3677,\n",
       " 3680,\n",
       " 3719,\n",
       " 3728,\n",
       " 3745,\n",
       " 3750,\n",
       " 3754,\n",
       " 3758,\n",
       " 3769,\n",
       " 3785,\n",
       " 3793,\n",
       " 3797,\n",
       " 3809,\n",
       " 3831,\n",
       " 3853,\n",
       " 3872,\n",
       " 3886,\n",
       " 3896,\n",
       " 3908,\n",
       " 3922,\n",
       " 3928,\n",
       " 3935,\n",
       " 3955,\n",
       " 3985,\n",
       " 4008,\n",
       " 4026,\n",
       " 4041,\n",
       " 4049,\n",
       " 4061,\n",
       " 4085,\n",
       " 4101,\n",
       " 4125,\n",
       " 4131,\n",
       " 4144,\n",
       " 4147,\n",
       " 4166,\n",
       " 4168,\n",
       " 4179,\n",
       " 4187,\n",
       " 4191,\n",
       " 4208,\n",
       " 4214,\n",
       " 4236,\n",
       " 4239,\n",
       " 4269,\n",
       " 4271,\n",
       " 4294,\n",
       " 4303,\n",
       " 4315,\n",
       " 4325,\n",
       " 4329,\n",
       " 4335,\n",
       " 4340,\n",
       " 4361,\n",
       " 4368,\n",
       " 4370,\n",
       " 4376,\n",
       " 4384,\n",
       " 4401,\n",
       " 4405,\n",
       " 4416,\n",
       " 4419,\n",
       " 4458,\n",
       " 4466,\n",
       " 4476,\n",
       " 4487,\n",
       " 4506,\n",
       " 4513,\n",
       " 4530,\n",
       " 4532,\n",
       " 4568,\n",
       " 4584,\n",
       " 4593,\n",
       " 4600,\n",
       " 4609,\n",
       " 4620,\n",
       " 4630,\n",
       " 4662,\n",
       " 4674,\n",
       " 4699,\n",
       " 4705,\n",
       " 4717,\n",
       " 4739,\n",
       " 4741,\n",
       " 4756,\n",
       " 4762,\n",
       " 4786,\n",
       " 4798,\n",
       " 4834,\n",
       " 4874,\n",
       " 4880,\n",
       " 4891,\n",
       " 4898,\n",
       " 4918,\n",
       " 4924,\n",
       " 4945,\n",
       " 4964,\n",
       " 4999,\n",
       " 5027,\n",
       " 5035,\n",
       " 5046,\n",
       " 5104,\n",
       " 5159,\n",
       " 5163,\n",
       " 5206,\n",
       " 5221,\n",
       " 5223,\n",
       " 5234,\n",
       " 5255,\n",
       " 5279,\n",
       " 5283,\n",
       " 5285,\n",
       " 5295,\n",
       " 5297,\n",
       " 5304,\n",
       " 5330,\n",
       " 5344,\n",
       " 5384,\n",
       " 5387,\n",
       " 5405,\n",
       " 5438,\n",
       " 5440,\n",
       " 5442,\n",
       " 5444,\n",
       " 5461,\n",
       " 5464,\n",
       " 5468,\n",
       " 5472,\n",
       " 5484,\n",
       " 5522,\n",
       " 5524,\n",
       " 5582,\n",
       " 5591,\n",
       " 5614,\n",
       " 5682,\n",
       " 5690,\n",
       " 5699,\n",
       " 5707,\n",
       " 5713,\n",
       " 5720,\n",
       " 5725,\n",
       " 5738,\n",
       " 5746,\n",
       " 5750,\n",
       " 5767,\n",
       " 5776,\n",
       " 5782,\n",
       " 5788,\n",
       " 5800,\n",
       " 5817,\n",
       " 5844,\n",
       " 5851,\n",
       " 5857,\n",
       " 5874,\n",
       " 5887,\n",
       " 5891,\n",
       " 5914,\n",
       " 5933,\n",
       " 5939,\n",
       " 5950,\n",
       " 5968,\n",
       " 5979,\n",
       " 5981,\n",
       " 5987,\n",
       " 5989,\n",
       " 6008,\n",
       " 6037,\n",
       " 6040,\n",
       " 6080,\n",
       " 6084,\n",
       " 6099,\n",
       " 6105,\n",
       " 6207,\n",
       " 6228,\n",
       " 6233,\n",
       " 6252,\n",
       " 6292,\n",
       " 6311,\n",
       " 6323,\n",
       " 6345,\n",
       " 6352,\n",
       " 6401,\n",
       " 6426,\n",
       " 6436,\n",
       " 6447,\n",
       " 6462,\n",
       " 6489,\n",
       " 6500,\n",
       " 6519,\n",
       " 6524,\n",
       " 6538,\n",
       " 6565,\n",
       " 6581,\n",
       " 6684,\n",
       " 6699,\n",
       " 6728,\n",
       " 6744,\n",
       " 6757,\n",
       " 6794,\n",
       " 6810,\n",
       " 6830,\n",
       " 6837,\n",
       " 6843,\n",
       " 6866,\n",
       " 6882,\n",
       " 6895,\n",
       " 6913,\n",
       " 6921,\n",
       " 6932,\n",
       " 6943,\n",
       " 6968,\n",
       " 6983,\n",
       " 6999,\n",
       " 7015,\n",
       " 7022,\n",
       " 7030,\n",
       " 7041,\n",
       " 7053,\n",
       " 7068,\n",
       " 7133,\n",
       " 7135,\n",
       " 7152,\n",
       " 7173,\n",
       " 7175,\n",
       " 7180,\n",
       " 7182,\n",
       " 7185,\n",
       " 7191,\n",
       " 7217,\n",
       " 7228,\n",
       " 7239,\n",
       " 7253,\n",
       " 7267,\n",
       " 7280,\n",
       " 7289,\n",
       " 7301,\n",
       " 7346,\n",
       " 7367,\n",
       " 7369,\n",
       " 7377,\n",
       " 7387,\n",
       " 7394,\n",
       " 7424,\n",
       " 7437,\n",
       " 7450,\n",
       " 7456,\n",
       " 7473,\n",
       " 7483,\n",
       " 7489,\n",
       " 7516,\n",
       " 7519,\n",
       " 7525,\n",
       " 7566,\n",
       " 7571,\n",
       " 7577,\n",
       " 7582,\n",
       " 7584,\n",
       " 7587,\n",
       " 7599,\n",
       " 7604,\n",
       " 7612,\n",
       " 7626,\n",
       " 7637,\n",
       " 7653,\n",
       " 7665,\n",
       " 7689,\n",
       " 7691,\n",
       " 7724,\n",
       " 7743,\n",
       " 7765,\n",
       " 7767,\n",
       " 7774,\n",
       " 7783,\n",
       " 7802,\n",
       " 7824,\n",
       " 7831,\n",
       " 7850,\n",
       " 7856,\n",
       " 7893,\n",
       " 7930,\n",
       " 7935,\n",
       " 7970,\n",
       " 7974,\n",
       " 7983,\n",
       " 8001,\n",
       " 8005,\n",
       " 8016,\n",
       " 8025,\n",
       " 8042,\n",
       " 8050,\n",
       " 8058,\n",
       " 8066,\n",
       " 8075,\n",
       " 8077,\n",
       " 8093,\n",
       " 8110,\n",
       " 8116,\n",
       " 8123,\n",
       " 8137,\n",
       " 8146,\n",
       " 8161,\n",
       " 8167,\n",
       " 8179,\n",
       " 8184,\n",
       " 8188,\n",
       " 8190,\n",
       " 8204,\n",
       " 8213,\n",
       " 8231,\n",
       " 8242,\n",
       " 8252,\n",
       " 8276,\n",
       " 8286,\n",
       " 8301,\n",
       " 8309,\n",
       " 8353,\n",
       " 8368,\n",
       " 8380,\n",
       " 8429,\n",
       " 8431,\n",
       " 8450,\n",
       " 8460,\n",
       " 8477,\n",
       " 8491,\n",
       " 8498,\n",
       " 8506,\n",
       " 8519,\n",
       " 8535,\n",
       " 8552,\n",
       " 8584,\n",
       " 8595,\n",
       " 8604,\n",
       " 8623,\n",
       " 8795,\n",
       " 8824,\n",
       " 8827,\n",
       " 8841,\n",
       " 8849,\n",
       " 8857,\n",
       " 8893,\n",
       " 8895,\n",
       " 8899,\n",
       " 8928,\n",
       " 8951,\n",
       " 8964,\n",
       " 8991,\n",
       " 9027,\n",
       " 9035,\n",
       " 9055,\n",
       " 9066,\n",
       " 9079,\n",
       " 9084,\n",
       " 9112,\n",
       " 9130,\n",
       " 9138,\n",
       " 9142,\n",
       " 9170,\n",
       " 9194,\n",
       " 9208,\n",
       " 9239,\n",
       " 9342,\n",
       " 9359,\n",
       " 9368,\n",
       " 9385,\n",
       " 9387,\n",
       " 9396,\n",
       " 9403,\n",
       " 9405,\n",
       " 9411,\n",
       " 9418,\n",
       " 9425,\n",
       " 9427,\n",
       " 9429,\n",
       " 9444,\n",
       " 9474,\n",
       " 9494,\n",
       " 9537,\n",
       " 9581,\n",
       " 9606,\n",
       " 9618,\n",
       " 9649,\n",
       " 9657,\n",
       " 9668,\n",
       " 9677,\n",
       " 9679,\n",
       " 9683,\n",
       " 9692,\n",
       " 9699,\n",
       " 9712,\n",
       " 9735,\n",
       " 9750,\n",
       " 9832,\n",
       " 9839,\n",
       " 9946,\n",
       " 10102,\n",
       " 10108,\n",
       " 10113,\n",
       " 10123,\n",
       " 10143,\n",
       " 10176,\n",
       " 10196,\n",
       " 10215,\n",
       " 10302,\n",
       " 10334,\n",
       " 10347,\n",
       " 10376,\n",
       " 10416,\n",
       " 10448,\n",
       " 10536,\n",
       " 10543,\n",
       " 10548,\n",
       " 10574,\n",
       " 10600,\n",
       " 10633,\n",
       " 10650,\n",
       " 10654,\n",
       " 10659,\n",
       " 10662,\n",
       " 10664,\n",
       " 10672,\n",
       " 10692,\n",
       " 10706,\n",
       " 10721,\n",
       " 10723,\n",
       " 10744,\n",
       " 10750,\n",
       " 10771,\n",
       " 10808,\n",
       " 10833,\n",
       " 10838,\n",
       " 10842,\n",
       " 10865,\n",
       " 10870,\n",
       " 10878,\n",
       " 10916,\n",
       " 10921,\n",
       " 10927,\n",
       " 10934,\n",
       " 10952,\n",
       " 10958,\n",
       " 10964,\n",
       " 10969,\n",
       " 10981,\n",
       " 11000,\n",
       " 11018,\n",
       " 11036,\n",
       " 11064,\n",
       " 11069,\n",
       " 11079,\n",
       " 11096,\n",
       " 11108,\n",
       " 11118,\n",
       " 11167,\n",
       " 11172,\n",
       " 11189,\n",
       " 11207,\n",
       " 11228,\n",
       " 11237,\n",
       " 11242,\n",
       " 11247,\n",
       " 11260,\n",
       " 11278,\n",
       " 11307,\n",
       " 11326,\n",
       " 11345,\n",
       " 11365,\n",
       " 11373,\n",
       " 11386,\n",
       " 11394,\n",
       " 11409,\n",
       " 11422,\n",
       " 11443,\n",
       " 11450,\n",
       " 11488,\n",
       " 11504,\n",
       " 11543,\n",
       " 11558,\n",
       " 11585,\n",
       " 11600,\n",
       " 11605,\n",
       " 11648,\n",
       " 11690,\n",
       " 11698,\n",
       " 11702,\n",
       " 11725,\n",
       " 11771,\n",
       " 11793,\n",
       " 11801,\n",
       " 11834,\n",
       " 11859,\n",
       " 11864,\n",
       " 11866,\n",
       " 11876,\n",
       " 11888,\n",
       " 11893,\n",
       " 11917,\n",
       " 11920,\n",
       " 11955,\n",
       " 11959,\n",
       " 11999,\n",
       " 12006,\n",
       " 12019,\n",
       " 12024,\n",
       " 12039,\n",
       " 12046,\n",
       " 12058,\n",
       " 12067,\n",
       " 12105,\n",
       " 12115,\n",
       " 12117,\n",
       " 12148,\n",
       " 12151,\n",
       " 12177,\n",
       " 12207,\n",
       " 12210,\n",
       " 12225,\n",
       " 12233,\n",
       " 12240,\n",
       " 12259,\n",
       " 12267,\n",
       " 12289,\n",
       " 12300,\n",
       " 12310,\n",
       " 12314,\n",
       " 12340,\n",
       " 12358,\n",
       " 12374,\n",
       " 12394,\n",
       " 12396,\n",
       " 12400,\n",
       " 12409,\n",
       " 12431,\n",
       " 12441,\n",
       " 12484,\n",
       " 12489,\n",
       " 12598,\n",
       " 12624,\n",
       " 12643,\n",
       " 12679,\n",
       " 12688,\n",
       " 12719,\n",
       " 12731,\n",
       " 12735,\n",
       " 12748,\n",
       " 12755,\n",
       " 12791,\n",
       " 12798,\n",
       " 12834,\n",
       " 12849,\n",
       " 12855,\n",
       " 12875,\n",
       " 12884,\n",
       " 12889,\n",
       " 12894,\n",
       " 12905,\n",
       " 12909,\n",
       " 12912,\n",
       " 12918,\n",
       " 12935,\n",
       " 12950,\n",
       " 12960,\n",
       " 12990,\n",
       " 13003,\n",
       " 13017,\n",
       " 13023,\n",
       " 13048,\n",
       " 13064,\n",
       " 13187,\n",
       " 13197,\n",
       " 13216,\n",
       " 13221,\n",
       " 13228,\n",
       " 13247,\n",
       " 13350,\n",
       " 13398,\n",
       " 13407,\n",
       " 13410,\n",
       " 13431,\n",
       " 13436,\n",
       " 13450,\n",
       " 13454,\n",
       " 13456,\n",
       " 13475,\n",
       " 13482,\n",
       " 13516,\n",
       " 13518,\n",
       " 13543,\n",
       " 13568,\n",
       " 13611,\n",
       " 13614,\n",
       " 13625,\n",
       " 13687,\n",
       " 13690,\n",
       " 13702,\n",
       " 13715,\n",
       " 13730,\n",
       " 13738,\n",
       " 13769,\n",
       " 13858,\n",
       " 13919,\n",
       " 13922,\n",
       " 13927,\n",
       " 13939,\n",
       " 13957,\n",
       " 13964,\n",
       " 13972,\n",
       " 13997,\n",
       " 14017,\n",
       " 14025,\n",
       " 14050,\n",
       " 14065,\n",
       " 14073,\n",
       " 14085,\n",
       " 14125,\n",
       " 14130,\n",
       " 14141,\n",
       " 14144,\n",
       " 14149,\n",
       " 14215,\n",
       " 14221,\n",
       " 14236,\n",
       " 14316,\n",
       " 14320,\n",
       " 14336,\n",
       " 14345,\n",
       " 14357,\n",
       " 14361,\n",
       " 14364,\n",
       " 14374,\n",
       " 14378,\n",
       " 14386,\n",
       " 14390,\n",
       " 14429,\n",
       " 14435,\n",
       " 14443,\n",
       " 14456,\n",
       " 14495,\n",
       " 14508,\n",
       " 14514,\n",
       " 14526,\n",
       " 14537,\n",
       " 14546,\n",
       " 14559,\n",
       " 14570,\n",
       " 14581,\n",
       " 14598,\n",
       " 14608,\n",
       " 14634,\n",
       " 14640,\n",
       " 14658,\n",
       " 14663,\n",
       " 14676,\n",
       " 14711,\n",
       " 14722,\n",
       " 14740,\n",
       " 14757,\n",
       " 14765,\n",
       " 14784,\n",
       " 14808,\n",
       " 14814,\n",
       " 14852,\n",
       " 14858,\n",
       " 14873,\n",
       " 14882,\n",
       " 14892,\n",
       " 14894,\n",
       " 14904,\n",
       " 14907,\n",
       " 14917,\n",
       " 14938,\n",
       " 14941,\n",
       " 14949,\n",
       " 14957,\n",
       " 14964,\n",
       " 14985,\n",
       " 14993,\n",
       " 14996,\n",
       " 15000,\n",
       " 15016,\n",
       " 15044,\n",
       " 15050,\n",
       " 15055,\n",
       " 15063,\n",
       " 15079,\n",
       " 15086,\n",
       " 15103,\n",
       " 15107,\n",
       " 15127,\n",
       " 15133,\n",
       " 15151,\n",
       " 15171,\n",
       " 15182,\n",
       " 15196,\n",
       " 15203,\n",
       " 15217,\n",
       " 15226,\n",
       " 15235,\n",
       " 15248,\n",
       " 15252,\n",
       " 15270,\n",
       " 15280,\n",
       " 15288,\n",
       " 15293,\n",
       " 15309,\n",
       " 15311,\n",
       " 15316,\n",
       " 15318,\n",
       " 15418,\n",
       " 15431,\n",
       " 15465,\n",
       " 15473,\n",
       " 15490,\n",
       " ...]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
