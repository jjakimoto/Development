{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df = df.dropna()\n",
    "X1 = df[\"question1\"].values\n",
    "X2 = df[\"question2\"].values\n",
    "y = df[\"is_duplicate\"].values\n",
    "X= [X1, X2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from hedgeable_ai.models.nn import BaseModel, get_shape, get_length\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from hedgeable_ai.models.nn.params import nn_is_logit\n",
    "from hedgeable_ai.models.nn import MultiNN, get_shape\n",
    "\n",
    "\n",
    "\n",
    "class DialogueAgent(MultiNN):\n",
    "    def __init__(self, maxlen, *args, **kwargs):\n",
    "        self.embedding_size = 300\n",
    "        self.vocabulary_size = 100\n",
    "        self.maxlen = maxlen\n",
    "        super().__init__(*args, **kwargs)\n",
    "   \n",
    "        \n",
    "    def _build_graph(self):\n",
    "        \"\"\"Build tensorflow graph\n",
    "        \n",
    "        Note:\n",
    "            You build graphs for output and input, which will be used \n",
    "            for training and prediction.\n",
    "        \"\"\"\n",
    "        self.encoder_input = tf.placeholder(tf.int32, shape=(None, self.maxlen), name=\"encoder_input\")\n",
    "        self.decoder_input = tf.placeholder(tf.int32, shape=(None, self.maxlen), name=\"decoder_input\")\n",
    "        self.target = tf.placeholder(tf.int32, shape=(None,self.maxlen), name=\"target\")\n",
    "        word_embeddings = tf.get_variable(\"word_embeddings\", [self.vocabulary_size, self.embedding_size])\n",
    "        embedded_encoder = tf.gather(word_embeddings, self.encoder_input)\n",
    "        embedded_decoder = tf.gather(word_embeddings, self.decoder_input)\n",
    "        #  Build Seq2Seq Model\n",
    "        cell = [rnn.LSTMCell(512) for _ in range(3)]\n",
    "        cell = rnn.MultiRNNCell(cell)\n",
    "        length = get_length(self.encoder_input)\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell,embedded_encoder, dtype=tf.float32)\n",
    "        helper = seq2seq.TrainingHelper(embedded_decoder, sequence_length=(20, 20), time_major=False)\n",
    "        decoder =  seq2seq.BasicDecoder(cell, helper, state)\n",
    "        final_outputs, final_state, final_sequence_lengths\\\n",
    "            = seq2seq.dynamic_decode(decoder, output_time_major=False,\n",
    "                                     impute_finished=True, maximum_iterations=None,\n",
    "                                     parallel_iterations=32, swap_memory=False, scope=None)\n",
    "        weights = tf.ones_like(self.target)\n",
    "        self.loss = seq2seq.sequence_loss(final_outputs, self.target, weights)\n",
    "        \n",
    "        self.learning_rate_op = self._get_learning_rate()\n",
    "        self.train_step =\\\n",
    "            tf.train.AdamOptimizer(self.learning_rate_op).minimize(self.loss)\n",
    "        # Build tensorboad graph\n",
    "        with tf.name_scope(\"summary\"):\n",
    "            self._build_summaries()\n",
    "        \n",
    "        # initialize graph\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def _optimize(self, batch_X, batch_y, *args, **kwargs):\n",
    "        feed_dict={\n",
    "                self.encoder_input: batch_X[0],\n",
    "                self.decoder_input: batch_X[1],\n",
    "                self.training: True,\n",
    "                self.target: batch_y}\n",
    "        _, loss = self.sess.run([self.train_step, self.loss], feed_dict=feed_dict)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BasicDecoderOutput' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9bd15e36ed1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDialogueAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-1d384d84f2d7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, maxlen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tomoaki/anaconda3/lib/python3.6/site-packages/hedgeable_ai-0.1.2-py3.6.egg/hedgeable_ai/models/nn/multi.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, output_dim, input_model, output_model, conf, sess, default_conf, *args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m                  sess=None, default_conf=None, *args, **kwargs):\n\u001b[1;32m      9\u001b[0m         super().__init__(input_dim, output_dim, output_model, conf,\n\u001b[0;32m---> 10\u001b[0;31m                  sess, default_conf, *args, **kwargs)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_calc_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_processed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tomoaki/anaconda3/lib/python3.6/site-packages/hedgeable_ai-0.1.2-py3.6.egg/hedgeable_ai/models/nn/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, output_dim, model, conf, sess, default_conf, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_update_step_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished building tensorflow graph, spent time:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1d384d84f2d7>\u001b[0m in \u001b[0;36m_build_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m                                      parallel_iterations=32, swap_memory=False, scope=None)\n\u001b[1;32m     44\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/loss.py\u001b[0m in \u001b[0;36msequence_loss\u001b[0;34m(logits, targets, weights, average_across_timesteps, average_across_batch, softmax_loss_function, name)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mdimensions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mweights\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhave\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     raise ValueError(\"Logits must be a \"\n\u001b[1;32m     79\u001b[0m                      \"[batch_size x sequence_length x logits] tensor\")\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BasicDecoderOutput' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "agent = DialogueAgent(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.ones_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.seq2seq as seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.contrib.seq2seq' has no attribute 'basic_rnn_seq2seq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c221f39d3a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_rnn_seq2seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.contrib.seq2seq' has no attribute 'basic_rnn_seq2seq'"
     ]
    }
   ],
   "source": [
    "seq2seq.basic_rnn_seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
