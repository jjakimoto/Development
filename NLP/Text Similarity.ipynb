{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hedgeable_ai.functions.preprocessing import SentenceProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SentenceProcessor(None, \"d2v\", vector_file_path=\"data/enwiki_dbow/doc2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df = df.dropna()\n",
    "X1 = df[\"question1\"].values\n",
    "X2 = df[\"question2\"].values\n",
    "y = df[\"is_duplicate\"].values\n",
    "X= [X1, X2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from logging import getLogger\n",
    "\n",
    "\n",
    "from hedgeable_ai.models.nn import NNTrainMixin\n",
    "from hedgeable_ai.models.nn.utils import generator\n",
    "\n",
    "overwrite = True\n",
    "save_file_path = None\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "class MultiNNTrainMixin(NNTrainMixin):\n",
    "    def train(self, train_X, train_y=None, valid_X=None, valid_y=None, num_epochs=100, \n",
    "              valid_freq=1, log_freq=1, is_processed=False, \n",
    "              overwrite=overwrite, save_file_path=save_file_path, *args, **kwargs):\n",
    "        \"\"\"Train neural network model\n",
    "        \n",
    "        Args:\n",
    "            train_X, train_y: list(array-like), this is preprocessed by \n",
    "                self.processor.batch_process\n",
    "            valid_X, valid_y: array-like(optional), if they are feeded, they\n",
    "                will be used as validation set\n",
    "            is_processed: bool, if True, skip preprocessing\n",
    "            args, kwargs: parameters for score function\n",
    "        \"\"\"\n",
    "        # check if there is already the same name file\n",
    "        self.save_params(self.save_file_path, overwrite)\n",
    "        self.is_trained = True\n",
    "        num_train = len(train_X[0])\n",
    "        # Each batch is a generator that returns list of data\n",
    "        train_batch_X, train_batch_y = self._get_batch(train_X, train_y, is_processed)\n",
    "        valid_batch_X, valid_batch_y = self._get_batch(valid_X, valid_y, is_processed)\n",
    "        logger.debug(\"start training!\")\n",
    "        try:\n",
    "            for i in tqdm(range(num_epochs)):\n",
    "                self.sess.run(self.update_step_op);\n",
    "                epoch_loss = []\n",
    "                for batch_i in range(num_train//self.batch_size + 1):\n",
    "                    batch_X = next(train_batch_X)\n",
    "                    if train_batch_y is not None:\n",
    "                        batch_y = next(train_batch_y)[0]\n",
    "                    else:\n",
    "                        batch_y = None\n",
    "                    batch_loss = self._optimize(batch_X, batch_y, num_data=num_train)\n",
    "                    epoch_loss.append(batch_loss)\n",
    "                step = self.global_step.eval(session=self.sess)\n",
    "                if step % log_freq == 0:\n",
    "                    lr_val = self.learning_rate_op.eval(session=self.sess)\n",
    "                    tag_dict = {'loss': np.mean(epoch_loss), \"learning_rate\":lr_val}\n",
    "                    self._inject_summary(tag_dict)\n",
    "                self._epoch_func(X=train_X, y=train_y, is_processed=is_processed)\n",
    "                accuracies = []\n",
    "                if valid_y is not None:\n",
    "                    num_valid = len(valid_y)\n",
    "                    # check accuracy every print_freq epoch\n",
    "                    if step % valid_freq == 0:\n",
    "                        accuracies = []\n",
    "                        logits_list = []\n",
    "                        for batch_i in range(num_valid//self.batch_size + 1):\n",
    "                            batch_X = next(valid_batch_X)\n",
    "                            batch_y = next(valid_batch_y)[0]\n",
    "                            _score = self.score(batch_X, batch_y, is_training=False,\n",
    "                                                is_processed=True, *args, **kwargs)\n",
    "                            accuracies.append(_score)\n",
    "                        accuracy = np.mean(accuracies)\n",
    "                        print(\"accuracy: \", accuracy)\n",
    "        except KeyboardInterrupt:\n",
    "            logger.debug(\"Save model parameters before finishing training...\")\n",
    "        finally:\n",
    "            self.save_params(save_file_path, overwrite=True)\n",
    "        logger.debug(\"finished training\")\n",
    "        \n",
    "    def _optimize(self, batch_X, batch_y, *args, **kwargs):\n",
    "        feed_dict={\n",
    "            self.target: batch_y,\n",
    "            self.training: True\n",
    "        }\n",
    "        for input_, X in zip(self.input, batch_X):\n",
    "            feed_dict[input_] = X\n",
    "        _, loss = self.sess.run([self.train_step, self.loss], feed_dict=feed_dict)\n",
    "        return loss\n",
    "        \n",
    "    def _get_batch(self, X, y=None, is_mulinput=False, is_processed=False):\n",
    "        if X is not None:\n",
    "            # preprocess data\n",
    "            if not is_processed:\n",
    "                X = [self.processor.batch_process(X_i) for X_i in X]\n",
    "                if y is not None:\n",
    "                    y = self.processor.batch_process_y(y)\n",
    "            batch_X = generator(X, self.batch_size)\n",
    "            if y is not None:\n",
    "                batch_y = generator([y], self.batch_size)\n",
    "            else:\n",
    "                batch_y = None\n",
    "        else:\n",
    "            batch_X = None\n",
    "            batch_y = None\n",
    "        return batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hedgeable_ai.models.nn import BaseNN\n",
    "\n",
    "is_training=True\n",
    "is_processed=False\n",
    "\n",
    "class MultiNN(MultiNNTrainMixin, BaseNN):\n",
    "    def __init__(self, input_dim, output_dim, input_model, output_model, conf=None,\n",
    "                 sess=None, default_conf=None, *args, **kwargs):\n",
    "        super().__init__(input_dim, output_dim, output_model, conf,\n",
    "                 sess, default_conf, *args, **kwargs)\n",
    "        \n",
    "    def _calc_output(self, X, is_training=is_training, is_processed=is_processed):\n",
    "        \"\"\"Return model output\n",
    "        \n",
    "        Returns:\n",
    "            list(array-like)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise NotTrainedError(\"Train model by 'train' beforehand\")\n",
    "        if not is_processed:\n",
    "            X = self.processor.batch_process(X)\n",
    "        num_data = len(X)\n",
    "        output_list = []\n",
    "        for batch_i in range(num_data // self.batch_size + 1):\n",
    "            feed_dict = {self.training: is_training}\n",
    "            for _input, _X in zip(self.input, X_):\n",
    "                batch_X = _X[self.batch_size * batch_i : self.batch_size * (batch_i+1)]\n",
    "                feed_dict[_input] = batch_X\n",
    "            output_list.extend(self.sess.run(self.output, feed_dict=feed_dict))\n",
    "        return np.array(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from hedgeable_ai.models.nn.params import nn_is_logit\n",
    "from hedgeable_ai.models.nn import BaseNN, get_shape\n",
    "from hedgeable_ai.functions.classification import ClassifierMixin\n",
    "\n",
    "\n",
    "class MultiNNClassifier(MultiNN, ClassifierMixin):\n",
    "    \"\"\"Classifier based on neural network\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, input_model, output_model, conf,\n",
    "                 is_logit=nn_is_logit, *args, **kwargs):\n",
    "        \"\"\"Initialize classifier with nerual network model\n",
    "        \n",
    "        Args:\n",
    "            model: class, neural network class\n",
    "            is_logit: bool(optional), if False, output of an estimator\n",
    "                as prediction directly\n",
    "            args, kwargs: parameters for parents class\n",
    "        \"\"\"\n",
    "        self.is_logit = is_logit\n",
    "        self.input_model = []\n",
    "        for i, model in enumerate(input_model):\n",
    "            self.input_model.append(model(None, conf[\"input_model\"][i], \"input_model_%d\" % i))\n",
    "        self.output_model = output_model(output_dim, conf[\"model\"], \"output_model\")\n",
    "        super().__init__(input_dim, output_dim, input_model=input_model,\n",
    "                         output_model=output_model, conf=conf, *args, **kwargs)\n",
    "        \n",
    "        \n",
    "    def _build_graph(self):\n",
    "        \"\"\"Build tensorflow graph\n",
    "        \n",
    "        Note:\n",
    "            You build graphs for output and input, which will be used \n",
    "            for training and prediction.\n",
    "        \"\"\"\n",
    "        self.epoch = tf.Variable(0, name=\"epoch\", trainable=False)\n",
    "        self.input = []\n",
    "        for _input_dim in self.input_dim:\n",
    "            _input_dim = get_shape(_input_dim, is_sequence=False)\n",
    "            self.input.append(tf.placeholder(tf.float32, shape=_input_dim))\n",
    "        self.target = tf.placeholder(tf.int32, shape=(None,), name=\"target\")\n",
    "        self.training = tf.placeholder(tf.bool, (), name=\"training\")\n",
    "        outputs = []\n",
    "        for _input, model in zip(self.input, self.input_model):\n",
    "            outputs.append(model(_input, self.training))\n",
    "        output_input = tf.concat(outputs, axis=-1)\n",
    "        self.output = self.output_model(output_input)\n",
    "        \n",
    "        # build optimizer\n",
    "        if self.is_logit:\n",
    "            if self.output_dim==1:\n",
    "                _output = tf.squeeze(self.output)\n",
    "                self.loss =\\\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        labels=tf.cast(self.target, tf.float32),\n",
    "                        logits=_output)\n",
    "            else:\n",
    "                _target = tf.one_hot(self.target, self.output_dim)\n",
    "                self.loss =\\\n",
    "                    tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        labels=tf.cast(_target, tf.float32),\n",
    "                        logits=self.output)\n",
    "        else:\n",
    "            raise NotImplementedError(\"We have not implemeted non logit output model\")\n",
    "        self.learning_rate_op = self._get_learning_rate()\n",
    "        self.train_step =\\\n",
    "            tf.train.AdamOptimizer(self.learning_rate_op).minimize(self.loss)\n",
    "        # Build tensorboad graph\n",
    "        with tf.name_scope(\"summary\"):\n",
    "            self._build_summaries()\n",
    "        \n",
    "        # initialize graph\n",
    "        self.sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hedgeable_ai.models.nn import get_shape\n",
    "from hedgeable_ai.models.nn import mlp_conf\n",
    "from hedgeable_ai.models.nn.ff.core import FeedForward\n",
    "\n",
    "\n",
    "class MLPModel(FeedForward):\n",
    "    def __init__(self, output_dim=None, model_params=None, scope_name=None, *args, **kwargs):\n",
    "        if model_params is None:\n",
    "            model_params = mlp_conf[\"model\"]\n",
    "        if scope_name is None:\n",
    "            scope_name = \"mlp\"\n",
    "        if output_dim  is not None:\n",
    "            model_params.append({\"name\": \"dense\", \"num_hidden\": output_dim})\n",
    "        super().__init__(model_params, scope_name, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: params/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [01:08<1:52:31, 68.20s/it]"
     ]
    }
   ],
   "source": [
    "conf = {\"model\":[{\"name\": \"dense\", \"num_hidden\": 100, \"is_batch\": True, \"activation\": tf.nn.relu},\n",
    "                 {\"name\": \"dense\", \"num_hidden\": 10, \"is_batch\": False, \"activation\": tf.nn.relu}],\n",
    "        \"input_model\":[[{\"name\": \"dense\", \"num_hidden\": 100, \"is_batch\": True, \"activation\": tf.nn.relu},\n",
    "                             {\"name\": \"dense\", \"num_hidden\": 100, \"is_batch\": True, \"activation\": tf.nn.relu},\n",
    "                             {\"name\": \"dense\", \"num_hidden\": 100, \"is_batch\": True, \"activation\": tf.nn.relu}],\n",
    "                            [{\"name\": \"dense\", \"num_hidden\": 100, \"is_batch\": True, \"activation\": tf.nn.relu},\n",
    "                             {\"name\": \"dense\", \"num_hidden\": 100, \"is_batch\": True, \"activation\": tf.nn.relu},\n",
    "                             {\"name\": \"dense\", \"num_hidden\": 100, \"is_batch\": True, \"activation\": tf.nn.relu}]]}\n",
    "tf.reset_default_graph()\n",
    "N = 1000000\n",
    "input_model = [MLPModel, MLPModel]\n",
    "output_model = MLPModel\n",
    "model = MultiNNClassifier([300, 300], 1, input_model, output_model, conf, processor=processor)\n",
    "model.train([X[0][:N], X[1][:N]], y[:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'What are some of the best short films available on the web?'\n",
      " 'Why does zero factorial (0!) equal one (1)?'\n",
      " 'Is it possible to see when a Quora question was asked and who asked it?'\n",
      " 'How close is a World War III?' 'What if there is no moon?'\n",
      " \"What's the process to start study of IAS?\"\n",
      " 'What is it like to randomly meet Jennifer Aniston?'\n",
      " 'If I have a tattoo can I donate blood?'\n",
      " 'How did you make money as a 13-year-old?']\n",
      "['How do I control my emotions and anger?' nan\n",
      " 'What is meant by qualitative and quantitative research?'\n",
      " 'Can you feed mealworms to a leopard gecko?'\n",
      " 'How can I get stiff and lean body?'\n",
      " 'How do I control my feelings of liking someone?'\n",
      " 'Why was the eastern roman empire wealthier than the west?'\n",
      " 'How can I focus in class?'\n",
      " \"I'm an 18 year old male and skinny. What's a good workout routine to gain muscle?\"\n",
      " \"What should a man do in his thirties who wants to pursue CA but can't go for 3 year articleship because of his full time job?\"]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X[1]) // 10):\n",
    "    X_i = X[1][i*10:(i+1)*10]\n",
    "    try:\n",
    "        df = processor.batch_process(X_i)\n",
    "    except:\n",
    "        print(X_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 300)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
