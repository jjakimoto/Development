{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the good hyperparameters of parameters is one of most imprtant procedures, but pretty much annoying and time consuming. As long as you are working on small subsets of hyperparameters, you may find an optimal hyperparameters after a few trials. That is, however, not the case for complex models like neural network. As basic algirhmts to tune them, we can consider grid, random, and Bayesian optimization. \n",
    "\n",
    "# Background\n",
    "Hyperparameter optimization can mostly be considered as black-box optimization. Black-box optimization is defined as the following:\n",
    "\n",
    "> \"Black Box\" optimization refers to a problem setup in which an optimization algorithm is supposed to optimize (e.g., minimize) an objective function through a so-called black-box interface: the algorithm may query the value f(x) for a point x, but it does not obtain gradient information, and in particular it cannot make any assumptions on the analytic form of f (e.g., being linear or quadratic). We think of such an objective function as being wrapped in a black-box. The goal of optimization is to find an as good as possible value f(x) within a predefined time, often defined by the number of available queries to the black box. Problems of this type regularly appear in practice, e.g., when optimizing parameters of a model that is either in fact hidden in a black box (e.g., a third party software library) or just too complex to be modeled explicitly.\n",
    "\n",
    "> by [Balck-Box Optimization Competition homepage](https://bbcomp.ini.rub.de/).\n",
    "\n",
    "\\* There are some hyperparameter optimization methods to make use of gradient information of models, e.g., [paper1](http://proceedings.mlr.press/v37/maclaurin15.pdf).\n",
    "\n",
    "When optimizing hyperparameters, information available is mostly only score value of defined metrics(e.g., accuracy for classification) with respect each set of hyper parameters. Thus, we query a set of hyperparameters and get a score value as a response. How to make efficient queries depends on which problem you are working on. In this article, we go through the most basic algorithms: grid, random, and Bayesian optimization. Then, we compare their performances on toy problems.\n",
    " \n",
    "\n",
    "# Grid Search\n",
    "Grid search is the simplest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomoaki/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/tomoaki/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train = mnist.train\n",
    "X = train.images\n",
    "train_X = X\n",
    "train_y = np.expand_dims(train.labels, -1)\n",
    "train_y = OneHotEncoder().fit_transform(train_y)\n",
    "\n",
    "valid = mnist.validation\n",
    "X = valid.images\n",
    "valid_X = X \n",
    "valid_y = np.expand_dims(valid.labels, -1)\n",
    "valid_y = OneHotEncoder().fit_transform(valid_y)\n",
    "\n",
    "test = mnist.test\n",
    "X = test.images\n",
    "test_X = X\n",
    "test_y = test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of the simplicity, we are going to use the following six parameters:\n",
    "\n",
    "- the number of layers\n",
    "- the number of hidden units\n",
    "- learning rate\n",
    "- weight regularizer\n",
    "- optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hedgeable_ai.optimizer.tuner import BayesOptimizer, RandomOptimizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.layers import Activation, Reshape\n",
    "from keras.optimizers import Adam, Adadelta, SGD, RMSprop\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "\n",
    "def get_optimzier(name, **kwargs):\n",
    "    if name == \"rmsprop\":\n",
    "        return RMSprop(**kwargs)\n",
    "    elif name == \"adam\":\n",
    "        return Adam(**kwargs)\n",
    "    elif name == \"sgd\":\n",
    "        return SGD(**kwargs)\n",
    "    elif name == \"adadelta\":\n",
    "        return Adadelta(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(name)\n",
    "\n",
    "\n",
    "def construct_NN(params):\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((784,), input_shape=(784,)))\n",
    "    \n",
    "    def update_model(_model, _params, name):\n",
    "        _model.add(Dropout(_params[name + \"_drop_rate\"]))\n",
    "        _model.add(Dense(units=_params[name + \"_num_units\"],\n",
    "                    activation=None,\n",
    "                    kernel_regularizer=l2(_params[name + \"_w_reg\"])))\n",
    "        if _params[name + \"_is_batch\"]:\n",
    "            _model.add(BatchNormalization())\n",
    "        if _params[name + \"_activation\"] is not None:\n",
    "            _model.add(Activation(_params[name + \"_activation\"]))\n",
    "        return _model\n",
    "    \n",
    "    # Add input layer    \n",
    "    model = update_model(model, params, \"input\")\n",
    "    # Add hidden layer\n",
    "    for i in range(params[\"num_hidden_layers\"]):\n",
    "        model = update_model(model, params, \"hidden\")\n",
    "    # Add output layer\n",
    "    model = update_model(model, params, \"output\")\n",
    "    optimizer = get_optimzier(params[\"optimizer\"],\n",
    "                              lr=params[\"learning_rate\"])\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "        \n",
    "\n",
    "def score_func(params):\n",
    "    print(\"parameters\", params)\n",
    "    model = construct_NN(params)\n",
    "    model.fit(train_X, train_y,\n",
    "              epochs=params[\"epochs\"],\n",
    "              batch_size=params[\"batch_size\"], verbose=1)\n",
    "    print(\"###################\", model.metrics_names)\n",
    "    score = model.evaluate(valid_X, valid_y,\n",
    "                  batch_size=params[\"batch_size\"])\n",
    "    idx = model.metrics_names.index(\"acc\")\n",
    "    score = score[idx]\n",
    "    return score\n",
    "\n",
    "params_conf = [\n",
    "    {\"name\": \"num_hidden_layers\", \"type\": \"integer\",\n",
    "     \"domain\": (0, 5)},\n",
    "    {\"name\": \"batch_size\", \"type\": \"integer\",\n",
    "     \"domain\": (16, 128), \"scale\": \"log\"},\n",
    "    {\"name\": \"learning_rate\", \"type\": \"continuous\",\n",
    "     \"domain\": (1e-5, 1e-1), \"scale\": \"log\"},\n",
    "    {\"name\": \"epochs\", \"type\": \"fixed\",\n",
    "     \"domain\": 1, \"scale\": \"log\"},\n",
    "    {\"name\": \"optimizer\", \"type\": \"categorical\",\n",
    "     \"domain\": (\"rmsprop\", \"sgd\", \"adam\", \"adadelta\")},\n",
    "    \n",
    "    {\"name\": \"input_drop_rate\", \"type\": \"continuous\",\n",
    "     \"domain\": (0, 0.5)},\n",
    "    {\"name\": \"input_num_units\", \"type\": \"integer\",\n",
    "     \"domain\": (32, 256), \"scale\": \"log\"},\n",
    "    {\"name\": \"input_w_reg\", \"type\": \"continuous\",\n",
    "     \"domain\": (1e-10, 1e-1), \"scale\": \"log\"},\n",
    "    {\"name\": \"input_is_batch\", \"type\": \"categorical\",\n",
    "     \"domain\": (True, False)},\n",
    "    {\"name\": \"input_activation\", \"type\": \"categorical\",\n",
    "     \"domain\": (\"relu\", \"sigmoid\", \"tanh\")},\n",
    "    \n",
    "    {\"name\": \"hidden_drop_rate\", \"type\": \"continuous\",\n",
    "     \"domain\": (0, 0.75)},\n",
    "    {\"name\": \"hidden_num_units\", \"type\": \"integer\",\n",
    "     \"domain\": (32, 256), \"scale\": \"log\"},\n",
    "    {\"name\": \"hidden_w_reg\", \"type\": \"continuous\",\n",
    "     \"domain\": (1e-10, 1e-1), \"scale\": \"log\"},\n",
    "    {\"name\": \"hidden_is_batch\", \"type\": \"categorical\",\n",
    "     \"domain\": (True, False)},\n",
    "    {\"name\": \"hidden_activation\", \"type\": \"categorical\",\n",
    "     \"domain\": (\"relu\", \"sigmoid\", \"tanh\")},\n",
    "    \n",
    "    {\"name\": \"output_drop_rate\", \"type\": \"continuous\",\n",
    "     \"domain\": (0, 0.5)},\n",
    "    {\"name\": \"output_num_units\", \"type\": \"fixed\",\n",
    "     \"domain\": 10},\n",
    "    {\"name\": \"output_w_reg\", \"type\": \"continuous\",\n",
    "     \"domain\": (1e-10, 1e-1), \"scale\": \"log\"},\n",
    "    {\"name\": \"output_is_batch\", \"type\": \"categorical\",\n",
    "     \"domain\": (True, False)},\n",
    "    {\"name\": \"output_activation\", \"type\": \"fixed\",\n",
    "     \"domain\": \"softmax\"},\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bboptimizer.samplers.random import RandomSampler\n",
    "from bboptimizer import Optimizer\n",
    "\n",
    "opt = Optimizer(score_func, params_conf, sampler=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters {'num_hidden_layers': 0, 'batch_size': 117, 'learning_rate': 0.0055451421884380216, 'epochs': 1, 'optimizer': 'adadelta', 'input_drop_rate': 0.27502278061733854, 'input_num_units': 243, 'input_w_reg': 0.005581602649551183, 'input_is_batch': False, 'input_activation': 'relu', 'hidden_drop_rate': 0.22328253884527435, 'hidden_num_units': 132, 'hidden_w_reg': 5.942947680444149e-07, 'hidden_is_batch': False, 'hidden_activation': 'tanh', 'output_drop_rate': 0.2973426860984296, 'output_num_units': 10, 'output_w_reg': 2.4430326159511334e-07, 'output_is_batch': False, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 1s 27us/step - loss: 4.2680 - acc: 0.1842\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 11us/step\n",
      "parameters {'num_hidden_layers': 2, 'batch_size': 32, 'learning_rate': 0.0009684732902796724, 'epochs': 1, 'optimizer': 'adam', 'input_drop_rate': 0.2952232471941791, 'input_num_units': 38, 'input_w_reg': 0.0026921354562820204, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.41563823220032997, 'hidden_num_units': 37, 'hidden_w_reg': 0.09583654934195257, 'hidden_is_batch': False, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.3587414137160263, 'output_num_units': 10, 'output_w_reg': 6.846625109687983e-05, 'output_is_batch': False, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 6s 101us/step - loss: 2.7276 - acc: 0.1014\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 36us/step\n",
      "parameters {'num_hidden_layers': 1, 'batch_size': 40, 'learning_rate': 0.00024425294754375356, 'epochs': 1, 'optimizer': 'rmsprop', 'input_drop_rate': 0.15709310951195676, 'input_num_units': 121, 'input_w_reg': 0.00012698937755434002, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.1859520387769392, 'hidden_num_units': 89, 'hidden_w_reg': 1.53752759260725e-10, 'hidden_is_batch': False, 'hidden_activation': 'tanh', 'output_drop_rate': 0.2353633495231574, 'output_num_units': 10, 'output_w_reg': 0.004329804359880026, 'output_is_batch': True, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.9793 - acc: 0.8024\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 29us/step\n",
      "parameters {'num_hidden_layers': 0, 'batch_size': 94, 'learning_rate': 0.09226128915162482, 'epochs': 1, 'optimizer': 'rmsprop', 'input_drop_rate': 0.1542512298666106, 'input_num_units': 190, 'input_w_reg': 6.487796152136091e-08, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.4564710572719264, 'hidden_num_units': 66, 'hidden_w_reg': 0.004739103610854455, 'hidden_is_batch': False, 'hidden_activation': 'tanh', 'output_drop_rate': 0.07193031378150166, 'output_num_units': 10, 'output_w_reg': 0.02120505233450636, 'output_is_batch': True, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 1.0078 - acc: 0.8354\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 19us/step\n",
      "parameters {'num_hidden_layers': 1, 'batch_size': 23, 'learning_rate': 0.0006701427316644613, 'epochs': 1, 'optimizer': 'sgd', 'input_drop_rate': 0.373592994744566, 'input_num_units': 68, 'input_w_reg': 5.924684616633157e-05, 'input_is_batch': False, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.20576062372086668, 'hidden_num_units': 62, 'hidden_w_reg': 0.002974885295607265, 'hidden_is_batch': False, 'hidden_activation': 'tanh', 'output_drop_rate': 0.19797600039657604, 'output_num_units': 10, 'output_w_reg': 1.1988833698864526e-07, 'output_is_batch': False, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 5s 88us/step - loss: 2.5285 - acc: 0.1315\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 41us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 22, 'learning_rate': 2.7717531711071693e-05, 'epochs': 1, 'optimizer': 'adadelta', 'input_drop_rate': 0.1280918230415508, 'input_num_units': 49, 'input_w_reg': 0.0038143090432932797, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.683275673345424, 'hidden_num_units': 181, 'hidden_w_reg': 0.00012126260840007394, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.41481665173007215, 'output_num_units': 10, 'output_w_reg': 2.1304705763444635e-06, 'output_is_batch': True, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 18s 336us/step - loss: 3.1694 - acc: 0.1019\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 81us/step\n",
      "parameters {'num_hidden_layers': 0, 'batch_size': 73, 'learning_rate': 0.04816565238960468, 'epochs': 1, 'optimizer': 'adam', 'input_drop_rate': 0.4408931549213725, 'input_num_units': 168, 'input_w_reg': 4.5742880108397496e-09, 'input_is_batch': False, 'input_activation': 'relu', 'hidden_drop_rate': 0.47426753448280035, 'hidden_num_units': 87, 'hidden_w_reg': 3.4658503560870193e-07, 'hidden_is_batch': True, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.020154334898368265, 'output_num_units': 10, 'output_w_reg': 0.0024180233166306775, 'output_is_batch': False, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.6611 - acc: 0.8410\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 16us/step\n",
      "parameters {'num_hidden_layers': 4, 'batch_size': 16, 'learning_rate': 1.5338416143333576e-05, 'epochs': 1, 'optimizer': 'adadelta', 'input_drop_rate': 0.13539594937933058, 'input_num_units': 70, 'input_w_reg': 0.0019045750018549848, 'input_is_batch': False, 'input_activation': 'relu', 'hidden_drop_rate': 0.35704411145920645, 'hidden_num_units': 256, 'hidden_w_reg': 1.4273219587170685e-09, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.17539879252232166, 'output_num_units': 10, 'output_w_reg': 1.850005755930935e-06, 'output_is_batch': True, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 22s 397us/step - loss: 3.0436 - acc: 0.0903\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 95us/step\n",
      "parameters {'num_hidden_layers': 1, 'batch_size': 72, 'learning_rate': 1.6773543832418053e-05, 'epochs': 1, 'optimizer': 'adam', 'input_drop_rate': 0.2629951626885069, 'input_num_units': 209, 'input_w_reg': 9.730565215435238e-08, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.4128598411774945, 'hidden_num_units': 57, 'hidden_w_reg': 0.006234174659303128, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.20517692658852632, 'output_num_units': 10, 'output_w_reg': 1.9663221004871017e-07, 'output_is_batch': False, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 3s 57us/step - loss: 2.3084 - acc: 0.4062\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 22us/step\n",
      "parameters {'num_hidden_layers': 4, 'batch_size': 49, 'learning_rate': 0.05081192761987002, 'epochs': 1, 'optimizer': 'rmsprop', 'input_drop_rate': 0.3651455613388206, 'input_num_units': 82, 'input_w_reg': 2.454310886451805e-05, 'input_is_batch': False, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.47627110910458664, 'hidden_num_units': 138, 'hidden_w_reg': 0.00018016050563030988, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.15189926052730945, 'output_num_units': 10, 'output_w_reg': 1.9539437236024138e-09, 'output_is_batch': False, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 6s 112us/step - loss: 2.1226 - acc: 0.5351\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 40us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'batch_size': 16,\n",
       "  'epochs': 1,\n",
       "  'hidden_activation': 'tanh',\n",
       "  'hidden_drop_rate': 0.35704411145920645,\n",
       "  'hidden_is_batch': True,\n",
       "  'hidden_num_units': 256,\n",
       "  'hidden_w_reg': 1.4273219587170685e-09,\n",
       "  'input_activation': 'relu',\n",
       "  'input_drop_rate': 0.13539594937933058,\n",
       "  'input_is_batch': False,\n",
       "  'input_num_units': 70,\n",
       "  'input_w_reg': 0.0019045750018549848,\n",
       "  'learning_rate': 1.5338416143333576e-05,\n",
       "  'num_hidden_layers': 4,\n",
       "  'optimizer': 'adadelta',\n",
       "  'output_activation': 'softmax',\n",
       "  'output_drop_rate': 0.17539879252232166,\n",
       "  'output_is_batch': True,\n",
       "  'output_num_units': 10,\n",
       "  'output_w_reg': 1.850005755930935e-06},\n",
       " 0.0746)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'batch_size': 122,\n",
       "  'epochs': 1,\n",
       "  'hidden_activation': 'relu',\n",
       "  'hidden_drop_rate': 0.41800143601312734,\n",
       "  'hidden_is_batch': False,\n",
       "  'hidden_num_units': 58,\n",
       "  'hidden_w_reg': 1.3843095452312436e-09,\n",
       "  'input_activation': 'relu',\n",
       "  'input_drop_rate': 0.19152239944957644,\n",
       "  'input_is_batch': True,\n",
       "  'input_num_units': 180,\n",
       "  'input_w_reg': 1.75967787780324e-08,\n",
       "  'learning_rate': 0.003043047288864343,\n",
       "  'num_hidden_layers': 0,\n",
       "  'optimizer': 'sgd',\n",
       "  'output_activation': 'softmax',\n",
       "  'output_drop_rate': 0.24792116099023453,\n",
       "  'output_is_batch': False,\n",
       "  'output_num_units': 10,\n",
       "  'output_w_reg': 1.0194675255696844e-07},\n",
       " {'batch_size': 19,\n",
       "  'epochs': 1,\n",
       "  'hidden_activation': 'tanh',\n",
       "  'hidden_drop_rate': 0.03856142201832366,\n",
       "  'hidden_is_batch': False,\n",
       "  'hidden_num_units': 117,\n",
       "  'hidden_w_reg': 4.170240016976096e-08,\n",
       "  'input_activation': 'tanh',\n",
       "  'input_drop_rate': 0.43644352622194327,\n",
       "  'input_is_batch': False,\n",
       "  'input_num_units': 42,\n",
       "  'input_w_reg': 0.0012481399408733633,\n",
       "  'learning_rate': 0.0003216389436988359,\n",
       "  'num_hidden_layers': 2,\n",
       "  'optimizer': 'adadelta',\n",
       "  'output_activation': 'softmax',\n",
       "  'output_drop_rate': 0.20091619671257227,\n",
       "  'output_is_batch': False,\n",
       "  'output_num_units': 10,\n",
       "  'output_w_reg': 6.610875166663479e-10},\n",
       " {'batch_size': 39,\n",
       "  'epochs': 1,\n",
       "  'hidden_activation': 'relu',\n",
       "  'hidden_drop_rate': 0.5165981917343154,\n",
       "  'hidden_is_batch': False,\n",
       "  'hidden_num_units': 192,\n",
       "  'hidden_w_reg': 1.7629457092864517e-06,\n",
       "  'input_activation': 'tanh',\n",
       "  'input_drop_rate': 0.41873977714323823,\n",
       "  'input_is_batch': True,\n",
       "  'input_num_units': 37,\n",
       "  'input_w_reg': 0.01700769754459191,\n",
       "  'learning_rate': 0.0007707263194649018,\n",
       "  'num_hidden_layers': 0,\n",
       "  'optimizer': 'sgd',\n",
       "  'output_activation': 'softmax',\n",
       "  'output_drop_rate': 0.18638426716930567,\n",
       "  'output_is_batch': False,\n",
       "  'output_num_units': 10,\n",
       "  'output_w_reg': 0.0015755452059878301}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt._sampler.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters {'num_hidden_layers': 4, 'batch_size': 42, 'learning_rate': 0.00028985783786979956, 'optimizer': 'sgd', 'input_drop_rate': 0.0683744739733505, 'input_num_units': 164, 'input_w_reg': 2.3580152177448804e-07, 'input_is_batch': True, 'input_activation': 'relu', 'hidden_drop_rate': 0.5749382175908537, 'hidden_num_units': 107, 'hidden_w_reg': 0.03589453327038853, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.08960135174196227, 'output_w_reg': 0.0007725908760472369, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 8s 140us/step - loss: 18.3465 - acc: 0.1036\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 49us/step\n",
      "parameters {'num_hidden_layers': 0, 'batch_size': 23, 'learning_rate': 0.012815775018421094, 'optimizer': 'adam', 'input_drop_rate': 0.02827919776496557, 'input_num_units': 123, 'input_w_reg': 0.0004914563612437838, 'input_is_batch': True, 'input_activation': 'relu', 'hidden_drop_rate': 0.6736427441705218, 'hidden_num_units': 60, 'hidden_w_reg': 2.543160108922293e-10, 'hidden_is_batch': True, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.34136397527943313, 'output_w_reg': 9.854913087144905e-05, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 6s 113us/step - loss: 0.8748 - acc: 0.8487\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 45us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 26, 'learning_rate': 0.0007167212342569305, 'optimizer': 'adadelta', 'input_drop_rate': 0.12626532154355774, 'input_num_units': 125, 'input_w_reg': 0.02520605957301583, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.5709861849725166, 'hidden_num_units': 34, 'hidden_w_reg': 0.030906036378022205, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.4499062978999858, 'output_w_reg': 5.451673111591593e-07, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 17s 308us/step - loss: 13.9957 - acc: 0.0967\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 75us/step\n",
      "parameters {'num_hidden_layers': 1, 'batch_size': 63, 'learning_rate': 0.030905441616055164, 'optimizer': 'adadelta', 'input_drop_rate': 0.4338515562101002, 'input_num_units': 88, 'input_w_reg': 8.819780585441374e-05, 'input_is_batch': False, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.4353171188408734, 'hidden_num_units': 122, 'hidden_w_reg': 6.739058569490413e-06, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.016832790855980106, 'output_w_reg': 0.00043393020031671917, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 3s 54us/step - loss: 2.2437 - acc: 0.2136\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 22us/step\n",
      "parameters {'num_hidden_layers': 0, 'batch_size': 28, 'learning_rate': 0.002415870361345222, 'optimizer': 'adadelta', 'input_drop_rate': 0.07879113445234404, 'input_num_units': 37, 'input_w_reg': 0.00042098587426328516, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.6605902698242603, 'hidden_num_units': 165, 'hidden_w_reg': 6.962247272105129e-09, 'hidden_is_batch': False, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.03904419900480227, 'output_w_reg': 3.7009880371434967e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 2.4571 - acc: 0.1819\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 43us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 26, 'learning_rate': 0.00015928868298464927, 'optimizer': 'adadelta', 'input_drop_rate': 0.02021665671742038, 'input_num_units': 147, 'input_w_reg': 0.0006727772108297842, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.6083720181240507, 'hidden_num_units': 42, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.39284593062700707, 'output_w_reg': 1.2632756660828282e-06, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 17s 315us/step - loss: 26.3709 - acc: 0.1003\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 76us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'adadelta', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.01290604646341628, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 0.1, 'hidden_is_batch': False, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.0, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 16s 291us/step - loss: 111.5158 - acc: 0.0996\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 84us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 128, 'learning_rate': 0.1, 'optimizer': 'rmsprop', 'input_drop_rate': 0.0, 'input_num_units': 256, 'input_w_reg': 3.931774390273764e-05, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.0, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 4s 65us/step - loss: 6.3551 - acc: 0.1948\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 28us/step\n",
      "parameters {'num_hidden_layers': 0, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 256, 'input_w_reg': 0.1, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 10s 176us/step - loss: 40.9463 - acc: 0.1204\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 71us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 128, 'learning_rate': 1e-05, 'optimizer': 'rmsprop', 'input_drop_rate': 0.5, 'input_num_units': 256, 'input_w_reg': 0.1, 'input_is_batch': True, 'input_activation': 'relu', 'hidden_drop_rate': 0.0, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.5, 'output_w_reg': 1.9559358376604882e-08, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 4s 65us/step - loss: 56.7007 - acc: 0.1219\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 28us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.0021178031319522856, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.002589158770156625, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.0, 'output_w_reg': 2.5853225769002848e-08, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 20s 365us/step - loss: 37.6234 - acc: 0.1007\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 105us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'adadelta', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 2.8722806174478596e-08, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 27s 487us/step - loss: 18.6064 - acc: 0.0994\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 104us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.00010911849070218321, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 3.8138052664855576e-05, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.0, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 20s 368us/step - loss: 2.7423 - acc: 0.0992\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 100us/step\n",
      "parameters {'num_hidden_layers': 0, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'adam', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 1e-10, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 10s 179us/step - loss: 1.7955 - acc: 0.4131\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 62us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'adadelta', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 8.552940899039238e-05, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.5, 'output_w_reg': 3.4993703550624235e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 26s 470us/step - loss: 18.7512 - acc: 0.0991\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 110us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'adadelta', 'input_drop_rate': 0.0, 'input_num_units': 256, 'input_w_reg': 5.720373740486968e-05, 'input_is_batch': True, 'input_activation': 'relu', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 26s 471us/step - loss: 21.4458 - acc: 0.0998\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 104us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.1, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.5, 'output_w_reg': 0.1, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 21s 380us/step - loss: 26.1196 - acc: 0.1040\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 165us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'adadelta', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.1, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 1e-10, 'hidden_is_batch': False, 'hidden_activation': 'tanh', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 16s 287us/step - loss: 8.8486 - acc: 0.1003\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 75us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.1, 'optimizer': 'adadelta', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 1e-10, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 1e-10, 'hidden_is_batch': False, 'hidden_activation': 'tanh', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 17s 306us/step - loss: 2.6028 - acc: 0.1033\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 81us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.1, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.1, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': False, 'hidden_activation': 'tanh', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 12s 226us/step - loss: 2.4858 - acc: 0.1063\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 80us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'adadelta', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.0002550561763021452, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.5, 'output_w_reg': 1.6914646070179095e-06, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 27s 491us/step - loss: 18.9421 - acc: 0.1024\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 110us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 2.4159806675406384e-05, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 256, 'input_w_reg': 3.579589286162632e-05, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 21s 389us/step - loss: 128.7048 - acc: 0.0982\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 110us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.1, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 256, 'input_w_reg': 0.1, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.5, 'output_w_reg': 0.1, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 21s 378us/step - loss: 3.7657 - acc: 0.1486\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 108us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.00010485153024168855, 'optimizer': 'rmsprop', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 1.1075240606183763e-05, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 23s 421us/step - loss: 6.5296 - acc: 0.1023\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 112us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.1, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 20s 372us/step - loss: 24.4405 - acc: 0.1002\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 105us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.1, 'optimizer': 'sgd', 'input_drop_rate': 0, 'input_num_units': 32, 'input_w_reg': 0.1, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 6.497916208563327e-08, 'hidden_is_batch': False, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.0, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 12s 222us/step - loss: 2.3576 - acc: 0.1057\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 78us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'adadelta', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.000415579089372406, 'input_is_batch': True, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 27s 490us/step - loss: 18.8278 - acc: 0.1001\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 109us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.0002908760674318228, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 256, 'input_w_reg': 0.1, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.0, 'output_w_reg': 9.812471167637189e-06, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 21s 377us/step - loss: 49.6987 - acc: 0.0981\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 109us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'adadelta', 'input_drop_rate': 0.0, 'input_num_units': 256, 'input_w_reg': 0.1, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.0, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 27s 488us/step - loss: 169.2157 - acc: 0.0994\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 112us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 1e-05, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.0004340037012759154, 'input_is_batch': True, 'input_activation': 'relu', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 21s 383us/step - loss: 18.3243 - acc: 0.1030\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 106us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'batch_size': 16,\n",
       "  'epochs': 1,\n",
       "  'hidden_activation': 'tanh',\n",
       "  'hidden_drop_rate': 0.75,\n",
       "  'hidden_is_batch': True,\n",
       "  'hidden_num_units': 32,\n",
       "  'hidden_w_reg': 0.1,\n",
       "  'input_activation': 'sigmoid',\n",
       "  'input_drop_rate': 0.0,\n",
       "  'input_is_batch': True,\n",
       "  'input_num_units': 32,\n",
       "  'input_w_reg': 8.552940899039238e-05,\n",
       "  'learning_rate': 1e-05,\n",
       "  'num_hidden_layers': 5,\n",
       "  'optimizer': 'adadelta',\n",
       "  'output_activation': 'softmax',\n",
       "  'output_drop_rate': 0.5,\n",
       "  'output_is_batch': True,\n",
       "  'output_num_units': 10,\n",
       "  'output_w_reg': 3.4993703550624235e-10},\n",
       " 0.0614)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = BayesOptimizer(score_func=score_func,\n",
    "                      params_conf=params_conf, is_display=True, timeout=None)\n",
    "opt.search(num_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesOptimizer' object has no attribute 'optimizert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-721638e7b34d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BayesOptimizer' object has no attribute 'optimizert'"
     ]
    }
   ],
   "source": [
    "opt.optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import GPy\n",
    "import GPyOpt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myf(x):\n",
    "    print(x)\n",
    "    return sum((2*x)**2)\n",
    "\n",
    "bounds = [{'name': 'var_1', 'type': 'continuous', 'domain': (-1,1)},\n",
    "         {'name': 'var_1', 'type': 'continuous', 'domain': (-1,1)}]\n",
    "\n",
    "# bounds = [{'name': 'var_1', 'type': 'continuous', 'domain': (-1,1)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.83472294 -0.35045541]]\n",
      "[[-0.81677674 -0.20893279]]\n",
      "[[0.56892437 0.98436479]]\n",
      "[[-0.70499574  0.15934302]]\n",
      "[[ 0.36236546 -0.37212878]]\n",
      "[[ 0.3276707 -0.3794702]]\n",
      "[[ 0.19993882 -0.76537162]]\n",
      "[[ 0.16673283 -0.17536047]]\n",
      "[[-2.46435936e-02 -7.75201312e-05]]\n",
      "[[-1.  1.]]\n",
      "[[0.05523789 0.08312356]]\n",
      "[[-0.0745971  0.0846349]]\n",
      "[[-0.13251386 -0.12509652]]\n",
      "[[-0.0692017   0.49375632]]\n",
      "[[-0.99652227 -0.99553451]]\n",
      "[[-0.28496292 -0.90985205]]\n",
      "[[0.12828897 0.05891816]]\n",
      "[[0.47730358 0.37926197]]\n",
      "[[-0.58558844 -0.02097188]]\n",
      "[[-0.67679943  0.899019  ]]\n"
     ]
    }
   ],
   "source": [
    "max_iter = 15\n",
    "opt = GPyOpt.methods.BayesianOptimization(myf,bounds)\n",
    "opt.run_optimization(max_iter, verbosity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.87769699e-01 -5.22068678e-01]\n",
      " [-2.60640122e-01 -5.92168000e-01]\n",
      " [ 3.62671315e-01  3.08434924e-01]\n",
      " [ 4.23333810e-01 -5.07602750e-01]\n",
      " [ 6.87402157e-01  2.10656733e-01]\n",
      " [ 3.12278334e-01  1.83631054e-01]\n",
      " [ 8.31197264e-04  5.77286352e-02]\n",
      " [-1.00000000e+00  9.75483572e-01]\n",
      " [ 6.73192012e-02 -9.58554176e-02]\n",
      " [-1.00000000e+00 -1.00000000e+00]\n",
      " [-6.75609333e-02 -3.06036996e-02]\n",
      " [ 1.39019074e-02 -7.44473136e-04]\n",
      " [-9.62346335e-01 -2.63916597e-02]\n",
      " [ 9.52792460e-01  9.90318356e-01]\n",
      " [ 3.20600327e-01 -3.70925950e-01]\n",
      " [ 8.19614846e-01 -5.49740227e-01]\n",
      " [ 1.98597971e-02 -4.48193390e-01]\n",
      " [ 8.05345803e-01  7.37027584e-01]\n",
      " [-4.62028321e-01  4.55104405e-01]\n",
      " [-7.58883852e-01  1.00326861e-02]]\n",
      "[ 0.01390191 -0.00074447]\n"
     ]
    }
   ],
   "source": [
    "print(opt.X)\n",
    "print(opt.x_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.Y - np.sum((2 * opt.X) ** 2, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.61410245e-01, 7.33240385e-02, 7.33240385e-02, 7.33240385e-02,\n",
       "       7.33240385e-02, 4.15628331e-04, 4.15628331e-04, 4.15628331e-04,\n",
       "       4.15628331e-04, 4.15628331e-04, 4.15628331e-04, 4.15628331e-04,\n",
       "       4.15628331e-04, 4.15628331e-04, 4.15628331e-04, 4.15628331e-04,\n",
       "       4.15628331e-04, 4.15628331e-04, 4.15628331e-04, 4.15628331e-04])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.Y_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "if [3]:\n",
    "    print(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get('scale', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3010299956639812"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log10(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hedgeable_ai.optimizer.tuner.variables.ContinuousVariable object at 0x7f513b731908>\n",
      "{'name': 'var1', 'type': 'continuous', 'domain': (-5, 5), 'dimensionality': 3}\n",
      "3\n",
      "<hedgeable_ai.optimizer.tuner.variables.DiscreteVariable object at 0x7f513b7477b8>\n",
      "{'name': 'var3', 'type': 'discrete', 'domain': (3, 8, 10), 'dimensionality': 2}\n",
      "2\n",
      "<hedgeable_ai.optimizer.tuner.variables.CategoricalVariable object at 0x7f513b747978>\n",
      "{'name': 'var4', 'type': 'categorical', 'domain': ('hey', 'what up', 'oops'), 'dimensionality': 1}\n",
      "1\n",
      "<hedgeable_ai.optimizer.tuner.variables.IntegerVariable object at 0x7f513b747b38>\n",
      "{'name': 'var5', 'type': 'integer', 'domain': (1, 10), 'scale': 'log'}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from hedgeable_ai.optimizer.tuner import RandomOptimizer\n",
    "\n",
    "\n",
    "mixed_domain =[{'name': 'var1', 'type': 'continuous', 'domain': (-5,5),'dimensionality': 3},\n",
    "               {'name': 'var3', 'type': 'discrete', 'domain': (3,8,10),'dimensionality': 2},\n",
    "               {'name': 'var4', 'type': 'categorical', 'domain': ('hey', 'what up', 'oops'),'dimensionality': 1},\n",
    "               {'name': 'var5', 'type': 'integer', 'domain': (1, 10), 'scale':'log'}]\n",
    "\n",
    "opt = RandomOptimizer(score_func=lambda x: x, params_conf=mixed_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 8, 3, 'hey', 10]\n"
     ]
    }
   ],
   "source": [
    "x = [0., 0., 0., 8., 1., 1., 0., 0., 1.]\n",
    "param = opt.vec2params(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1_1': 0.0,\n",
       " 'var1_2': 0.0,\n",
       " 'var1_3': 0.0,\n",
       " 'var3_1': 8,\n",
       " 'var3_2': 3,\n",
       " 'var4_1': 'hey',\n",
       " 'var5': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 8., 3., 1., 0., 0., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.params2vec(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.design_space.dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.design_space.model_dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
