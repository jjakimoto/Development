{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the good hyperparameters of parameters is one of most imprtant procedures, but pretty much annoying and time consuming. As long as you are working on small subsets of hyperparameters, you may find an optimal hyperparameters after a few trials. That is, however, not the case for complex models like neural network. As basic algirhmts to tune them, we can consider grid, random, and Bayesian optimization. \n",
    "\n",
    "# Background\n",
    "Hyperparameter optimization can mostly be considered as black-box optimization. Black-box optimization is defined as the following:\n",
    "\n",
    "> \"Black Box\" optimization refers to a problem setup in which an optimization algorithm is supposed to optimize (e.g., minimize) an objective function through a so-called black-box interface: the algorithm may query the value f(x) for a point x, but it does not obtain gradient information, and in particular it cannot make any assumptions on the analytic form of f (e.g., being linear or quadratic). We think of such an objective function as being wrapped in a black-box. The goal of optimization is to find an as good as possible value f(x) within a predefined time, often defined by the number of available queries to the black box. Problems of this type regularly appear in practice, e.g., when optimizing parameters of a model that is either in fact hidden in a black box (e.g., a third party software library) or just too complex to be modeled explicitly.\n",
    "\n",
    "> by [Balck-Box Optimization Competition homepage](https://bbcomp.ini.rub.de/).\n",
    "\n",
    "\\* There are some hyperparameter optimization methods to make use of gradient information of models, e.g., [paper1](http://proceedings.mlr.press/v37/maclaurin15.pdf).\n",
    "\n",
    "When optimizing hyperparameters, information available is mostly only score value of defined metrics(e.g., accuracy for classification) with respect each set of hyper parameters. Thus, we query a set of hyperparameters and get a score value as a response. How to make efficient queries depends on which problem you are working on. In this article, we go through the most basic algorithms: grid, random, and Bayesian optimization. Then, we compare their performances on toy problems.\n",
    " \n",
    "\n",
    "# Grid Search\n",
    "Grid search is the simplest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train = mnist.train\n",
    "X = train.images\n",
    "train_X = X\n",
    "train_y = np.expand_dims(train.labels, -1)\n",
    "train_y = OneHotEncoder().fit_transform(train_y)\n",
    "\n",
    "valid = mnist.validation\n",
    "X = valid.images\n",
    "valid_X = X \n",
    "valid_y = np.expand_dims(valid.labels, -1)\n",
    "valid_y = OneHotEncoder().fit_transform(valid_y)\n",
    "\n",
    "test = mnist.test\n",
    "X = test.images\n",
    "test_X = X\n",
    "test_y = test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of the simplicity, we are going to use the following six parameters:\n",
    "\n",
    "- the number of layers\n",
    "- the number of hidden units\n",
    "- learning rate\n",
    "- weight regularizer\n",
    "- optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hedgeable_ai.optimizer.tuner import BayesOptimizer, RandomOptimizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.layers import Activation, Reshape\n",
    "from keras.optimizers import Adam, Adadelta, SGD, RMSprop\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "\n",
    "def get_optimzier(name, **kwargs):\n",
    "    if name == \"rmsprop\":\n",
    "        return RMSprop(**kwargs)\n",
    "    elif name == \"adam\":\n",
    "        return Adam(**kwargs)\n",
    "    elif name == \"sgd\":\n",
    "        return SGD(**kwargs)\n",
    "    elif name == \"adadelta\":\n",
    "        return Adadelta(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(name)\n",
    "\n",
    "\n",
    "def construct_NN(params):\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((784,), input_shape=(784,)))\n",
    "    \n",
    "    def update_model(_model, _params, name):\n",
    "        _model.add(Dropout(_params[name + \"_drop_rate\"]))\n",
    "        _model.add(Dense(units=_params[name + \"_num_units\"],\n",
    "                    activation=None,\n",
    "                    kernel_regularizer=l2(_params[name + \"_w_reg\"])))\n",
    "        if _params[name + \"_is_batch\"]:\n",
    "            _model.add(BatchNormalization())\n",
    "        if _params[name + \"_activation\"] is not None:\n",
    "            _model.add(Activation(_params[name + \"_activation\"]))\n",
    "        return _model\n",
    "    \n",
    "    # Add input layer    \n",
    "    model = update_model(model, params, \"input\")\n",
    "    # Add hidden layer\n",
    "    for i in range(params[\"num_hidden_layers\"]):\n",
    "        model = update_model(model, params, \"hidden\")\n",
    "    # Add output layer\n",
    "    model = update_model(model, params, \"output\")\n",
    "    optimizer = get_optimzier(params[\"optimizer\"],\n",
    "                              lr=params[\"learning_rate\"])\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "        \n",
    "\n",
    "def score_func(params):\n",
    "    print(\"parameters\", params)\n",
    "    model = construct_NN(params)\n",
    "    model.fit(train_X, train_y,\n",
    "              epochs=params[\"epochs\"],\n",
    "              batch_size=params[\"batch_size\"], verbose=1)\n",
    "    print(\"###################\", model.metrics_names)\n",
    "    score = model.evaluate(valid_X, valid_y,\n",
    "                  batch_size=params[\"batch_size\"])\n",
    "    idx = model.metrics_names.index(\"acc\")\n",
    "    score = score[idx]\n",
    "    return score\n",
    "\n",
    "params_conf = [\n",
    "    {\"name\": \"num_hidden_layers\", \"type\": \"integer\",\n",
    "     \"domain\": (0, 5)},\n",
    "    {\"name\": \"batch_size\", \"type\": \"integer\",\n",
    "     \"domain\": (16, 128), \"scale\": \"log\"},\n",
    "    {\"name\": \"learning_rate\", \"type\": \"continuous\",\n",
    "     \"domain\": (1e-5, 1e-1), \"scale\": \"log\"},\n",
    "    {\"name\": \"epochs\", \"type\": \"fixed\",\n",
    "     \"domain\": 1, \"scale\": \"log\"},\n",
    "    {\"name\": \"optimizer\", \"type\": \"categorical\",\n",
    "     \"domain\": (\"rmsprop\", \"sgd\", \"adam\", \"adadelta\")},\n",
    "    \n",
    "    {\"name\": \"input_drop_rate\", \"type\": \"continuous\",\n",
    "     \"domain\": (0, 0.5)},\n",
    "    {\"name\": \"input_num_units\", \"type\": \"integer\",\n",
    "     \"domain\": (32, 256), \"scale\": \"log\"},\n",
    "    {\"name\": \"input_w_reg\", \"type\": \"continuous\",\n",
    "     \"domain\": (1e-10, 1e-1), \"scale\": \"log\"},\n",
    "    {\"name\": \"input_is_batch\", \"type\": \"categorical\",\n",
    "     \"domain\": (True, False)},\n",
    "    {\"name\": \"input_activation\", \"type\": \"categorical\",\n",
    "     \"domain\": (\"relu\", \"sigmoid\", \"tanh\")},\n",
    "    \n",
    "    {\"name\": \"hidden_drop_rate\", \"type\": \"continuous\",\n",
    "     \"domain\": (0, 0.75)},\n",
    "    {\"name\": \"hidden_num_units\", \"type\": \"integer\",\n",
    "     \"domain\": (32, 256), \"scale\": \"log\"},\n",
    "    {\"name\": \"hidden_w_reg\", \"type\": \"continuous\",\n",
    "     \"domain\": (1e-10, 1e-1), \"scale\": \"log\"},\n",
    "    {\"name\": \"hidden_is_batch\", \"type\": \"categorical\",\n",
    "     \"domain\": (True, False)},\n",
    "    {\"name\": \"hidden_activation\", \"type\": \"categorical\",\n",
    "     \"domain\": (\"relu\", \"sigmoid\", \"tanh\")},\n",
    "    \n",
    "    {\"name\": \"output_drop_rate\", \"type\": \"continuous\",\n",
    "     \"domain\": (0, 0.5)},\n",
    "    {\"name\": \"output_num_units\", \"type\": \"fixed\",\n",
    "     \"domain\": 10},\n",
    "    {\"name\": \"output_w_reg\", \"type\": \"continuous\",\n",
    "     \"domain\": (1e-10, 1e-1), \"scale\": \"log\"},\n",
    "    {\"name\": \"output_is_batch\", \"type\": \"categorical\",\n",
    "     \"domain\": (True, False)},\n",
    "    {\"name\": \"output_activation\", \"type\": \"fixed\",\n",
    "     \"domain\": \"softmax\"},\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters {'num_hidden_layers': 2, 'batch_size': 42, 'learning_rate': 0.00022006788694377882, 'optimizer': 'adam', 'input_drop_rate': 0.35467419743622763, 'input_num_units': 124, 'input_w_reg': 5.709830768718531e-09, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.07209537065445323, 'hidden_num_units': 70, 'hidden_w_reg': 3.5107073277929543e-10, 'hidden_is_batch': False, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.051332911116528934, 'output_w_reg': 0.0003106810758127791, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 5s 91us/step - loss: 1.1529 - acc: 0.6937\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 38us/step\n",
      "parameters {'num_hidden_layers': 1, 'batch_size': 45, 'learning_rate': 0.003951099787714526, 'optimizer': 'sgd', 'input_drop_rate': 0.23940999905996968, 'input_num_units': 158, 'input_w_reg': 0.02991934294546592, 'input_is_batch': False, 'input_activation': 'relu', 'hidden_drop_rate': 0.7494779222548213, 'hidden_num_units': 65, 'hidden_w_reg': 4.427585243987588e-08, 'hidden_is_batch': True, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.40806371948226655, 'output_w_reg': 0.01119409057281482, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 8.4297 - acc: 0.1951\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 38us/step\n",
      "parameters {'num_hidden_layers': 0, 'batch_size': 32, 'learning_rate': 0.006613566445556018, 'optimizer': 'adadelta', 'input_drop_rate': 0.007437771402504234, 'input_num_units': 32, 'input_w_reg': 2.8009851783827477e-08, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.020119654487289557, 'hidden_num_units': 191, 'hidden_w_reg': 3.3672646334465e-08, 'hidden_is_batch': False, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.4057172828612462, 'output_w_reg': 0.03286826812977394, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 4s 64us/step - loss: 2.8100 - acc: 0.1377\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 40us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 41, 'learning_rate': 0.01373415722432346, 'optimizer': 'adadelta', 'input_drop_rate': 0.1628347708932194, 'input_num_units': 200, 'input_w_reg': 0.0006727094819071566, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.482972788244507, 'hidden_num_units': 82, 'hidden_w_reg': 5.3613332813158275e-05, 'hidden_is_batch': False, 'hidden_activation': 'tanh', 'output_drop_rate': 0.1417873113821791, 'output_w_reg': 6.481667501580351e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 9s 162us/step - loss: 2.9034 - acc: 0.1091\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 84us/step\n",
      "parameters {'num_hidden_layers': 0, 'batch_size': 110, 'learning_rate': 0.005683867934862388, 'optimizer': 'sgd', 'input_drop_rate': 0.049979973125460875, 'input_num_units': 61, 'input_w_reg': 1.211984034773052e-07, 'input_is_batch': False, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.18260573062610128, 'hidden_num_units': 62, 'hidden_w_reg': 0.04670214062249037, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.40655527795731117, 'output_w_reg': 1.183500759198102e-08, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 2s 38us/step - loss: 2.3148 - acc: 0.1530\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 22us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 57, 'learning_rate': 0.015031639949983137, 'optimizer': 'sgd', 'input_drop_rate': 0.26821067323884773, 'input_num_units': 222, 'input_w_reg': 0.004697486002420803, 'input_is_batch': False, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.618673060207438, 'hidden_num_units': 124, 'hidden_w_reg': 4.550310816981835e-05, 'hidden_is_batch': True, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.07620182426060446, 'output_w_reg': 4.0673254742386875e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 9s 155us/step - loss: 3.9089 - acc: 0.1002\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 60us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 49, 'learning_rate': 0.0231224368670036, 'optimizer': 'adadelta', 'input_drop_rate': 0.2780251871218074, 'input_num_units': 256, 'input_w_reg': 0.023287696570613293, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.6677703923696064, 'hidden_num_units': 140, 'hidden_w_reg': 4.3648722372694945e-05, 'hidden_is_batch': False, 'hidden_activation': 'tanh', 'output_drop_rate': 0.006569228248284301, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 10s 173us/step - loss: 8.9343 - acc: 0.0990\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 58us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 86, 'learning_rate': 0.024655071180642446, 'optimizer': 'sgd', 'input_drop_rate': 0.36369713166109463, 'input_num_units': 256, 'input_w_reg': 0.047487065705072176, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.7489259097905985, 'hidden_num_units': 208, 'hidden_w_reg': 0.00013113532459646431, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.004431681019208899, 'output_w_reg': 1e-10, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 10s 175us/step - loss: 8.3350 - acc: 0.1510\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 75us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 27, 'learning_rate': 0.0006152322492225295, 'optimizer': 'sgd', 'input_drop_rate': 0.3705632211701956, 'input_num_units': 256, 'input_w_reg': 0.09106467179282901, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 141, 'hidden_w_reg': 8.426100019837905e-06, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 15s 280us/step - loss: 30.8230 - acc: 0.1000\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 102us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.08581736844802079, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.05236125600134828, 'input_is_batch': False, 'input_activation': 'relu', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 9.65301388109791e-07, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 21s 385us/step - loss: 2.5176 - acc: 0.1063\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 124us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.006365958471566507, 'optimizer': 'sgd', 'input_drop_rate': 0.5, 'input_num_units': 32, 'input_w_reg': 0.0718145436197944, 'input_is_batch': False, 'input_activation': 'relu', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 1.875406777548788e-05, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 12s 217us/step - loss: 3.1295 - acc: 0.1228\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 78us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 128, 'learning_rate': 0.0011448070929924383, 'optimizer': 'rmsprop', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 0.07377797538480767, 'input_is_batch': True, 'input_activation': 'relu', 'hidden_drop_rate': 0.0, 'hidden_num_units': 256, 'hidden_w_reg': 3.966745567267411e-06, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.5, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 6s 118us/step - loss: 0.9453 - acc: 0.9010\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 59us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.03198311252912324, 'optimizer': 'sgd', 'input_drop_rate': 0.49897736080553173, 'input_num_units': 219, 'input_w_reg': 0.03774976345643623, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 70, 'hidden_w_reg': 2.743188899161214e-05, 'hidden_is_batch': True, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.0, 'output_w_reg': 1.1211068896181518e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 18s 330us/step - loss: 3.1159 - acc: 0.1055\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 115us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.004603228828464524, 'optimizer': 'sgd', 'input_drop_rate': 0.5, 'input_num_units': 256, 'input_w_reg': 0.029446842831837163, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 92, 'hidden_w_reg': 0.0003087034531144477, 'hidden_is_batch': True, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.0, 'output_w_reg': 1.3389338492807732e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 19s 343us/step - loss: 7.7439 - acc: 0.1015\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 124us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 18, 'learning_rate': 0.1, 'optimizer': 'sgd', 'input_drop_rate': 0.0, 'input_num_units': 256, 'input_w_reg': 0.01285672201924632, 'input_is_batch': False, 'input_activation': 'relu', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 3.55687175000112e-05, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.0, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 25s 459us/step - loss: 2.3979 - acc: 0.2739\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 160us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 77, 'learning_rate': 0.009272753680405749, 'optimizer': 'sgd', 'input_drop_rate': 0.5, 'input_num_units': 256, 'input_w_reg': 0.030635528574267108, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 72, 'hidden_w_reg': 6.118154797157797e-05, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 2.1721670470120024e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 6s 114us/step - loss: 10.6129 - acc: 0.1123\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 54us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.03016232876790991, 'optimizer': 'sgd', 'input_drop_rate': 0.5, 'input_num_units': 32, 'input_w_reg': 0.1, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 47, 'hidden_w_reg': 1.5465971006048952e-06, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 1.321367159487102e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 12s 217us/step - loss: 2.5478 - acc: 0.1238\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 79us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 26, 'learning_rate': 0.04436563144139646, 'optimizer': 'rmsprop', 'input_drop_rate': 0.5, 'input_num_units': 256, 'input_w_reg': 0.01320839257349354, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 43, 'hidden_w_reg': 0.00023747655184953303, 'hidden_is_batch': True, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.0, 'output_w_reg': 1.6162212193778217e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 12s 226us/step - loss: 3.6827 - acc: 0.1056\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 79us/step\n",
      "parameters {'num_hidden_layers': 4, 'batch_size': 16, 'learning_rate': 0.0006832203741935487, 'optimizer': 'sgd', 'input_drop_rate': 0.5, 'input_num_units': 256, 'input_w_reg': 0.1, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 4.241012029953535e-05, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 15s 281us/step - loss: 27.7393 - acc: 0.1004\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 94us/step\n",
      "parameters {'num_hidden_layers': 4, 'batch_size': 16, 'learning_rate': 0.03958343284897313, 'optimizer': 'sgd', 'input_drop_rate': 0.5, 'input_num_units': 32, 'input_w_reg': 0.1, 'input_is_batch': False, 'input_activation': 'tanh', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 0.00010626804466042775, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 1e-10, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 19s 349us/step - loss: 2.5104 - acc: 0.1882\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 116us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.0040907147064868365, 'optimizer': 'rmsprop', 'input_drop_rate': 0.5, 'input_num_units': 256, 'input_w_reg': 0.1, 'input_is_batch': False, 'input_activation': 'relu', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 0.00020642042029913015, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 1.5372947370335603e-09, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 32s 578us/step - loss: 2.7945 - acc: 0.1887\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 165us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.1, 'optimizer': 'rmsprop', 'input_drop_rate': 0.5, 'input_num_units': 32, 'input_w_reg': 1e-10, 'input_is_batch': True, 'input_activation': 'relu', 'hidden_drop_rate': 0.75, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.5, 'output_w_reg': 0.1, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 13s 237us/step - loss: 3.8430 - acc: 0.1025\n",
      "################### ['loss', 'acc']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 79us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 128, 'learning_rate': 0.1, 'optimizer': 'rmsprop', 'input_drop_rate': 0.5, 'input_num_units': 256, 'input_w_reg': 1e-10, 'input_is_batch': True, 'input_activation': 'relu', 'hidden_drop_rate': 0.0, 'hidden_num_units': 256, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.5, 'output_w_reg': 0.1, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 7s 129us/step - loss: 89.1975 - acc: 0.1055\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 60us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.1, 'optimizer': 'rmsprop', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 1e-10, 'input_is_batch': True, 'input_activation': 'relu', 'hidden_drop_rate': 0.5248793199981784, 'hidden_num_units': 256, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.5, 'output_w_reg': 0.1, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 21s 390us/step - loss: 71.4140 - acc: 0.1001\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 136us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 128, 'learning_rate': 0.1, 'optimizer': 'rmsprop', 'input_drop_rate': 0.4135829566482579, 'input_num_units': 256, 'input_w_reg': 1e-10, 'input_is_batch': True, 'input_activation': 'relu', 'hidden_drop_rate': 0.75, 'hidden_num_units': 94, 'hidden_w_reg': 0.1, 'hidden_is_batch': False, 'hidden_activation': 'sigmoid', 'output_drop_rate': 0.0, 'output_w_reg': 0.1, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 4s 70us/step - loss: 18.0612 - acc: 0.1022\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 33us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 22, 'learning_rate': 0.1, 'optimizer': 'adam', 'input_drop_rate': 0.5, 'input_num_units': 32, 'input_w_reg': 1e-10, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 0.1, 'hidden_is_batch': False, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 0.1, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 16s 284us/step - loss: 3.9596 - acc: 0.1009\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 92us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 128, 'learning_rate': 0.1, 'optimizer': 'adam', 'input_drop_rate': 0.0, 'input_num_units': 34, 'input_w_reg': 1e-10, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 38, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 0.1, 'output_is_batch': True, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 3s 62us/step - loss: 3.4944 - acc: 0.1045\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 37us/step\n",
      "parameters {'num_hidden_layers': 2, 'batch_size': 16, 'learning_rate': 0.1, 'optimizer': 'adadelta', 'input_drop_rate': 0.0, 'input_num_units': 32, 'input_w_reg': 1e-10, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 0.1, 'hidden_is_batch': False, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 0.1, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 10s 179us/step - loss: 5.4353 - acc: 0.1139\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 76us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 5.6825244549269546e-05, 'optimizer': 'adadelta', 'input_drop_rate': 0.5, 'input_num_units': 32, 'input_w_reg': 1e-10, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.75, 'hidden_num_units': 256, 'hidden_w_reg': 0.1, 'hidden_is_batch': False, 'hidden_activation': 'relu', 'output_drop_rate': 0.0, 'output_w_reg': 0.1, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 21s 376us/step - loss: 113.3106 - acc: 0.1024\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 1s 109us/step\n",
      "parameters {'num_hidden_layers': 5, 'batch_size': 16, 'learning_rate': 0.1, 'optimizer': 'adadelta', 'input_drop_rate': 0.5, 'input_num_units': 32, 'input_w_reg': 1e-10, 'input_is_batch': True, 'input_activation': 'sigmoid', 'hidden_drop_rate': 0.0, 'hidden_num_units': 32, 'hidden_w_reg': 0.1, 'hidden_is_batch': True, 'hidden_activation': 'tanh', 'output_drop_rate': 0.0, 'output_w_reg': 0.1, 'output_is_batch': False, 'epochs': 1, 'output_num_units': 10, 'output_activation': 'softmax'}\n",
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 13s 236us/step - loss: 7.2813 - acc: 0.5652\n",
      "################### ['loss', 'acc']\n",
      "5000/5000 [==============================] - 0s 79us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'batch_size': 22,\n",
       "  'epochs': 1,\n",
       "  'hidden_activation': 'relu',\n",
       "  'hidden_drop_rate': 0.75,\n",
       "  'hidden_is_batch': False,\n",
       "  'hidden_num_units': 256,\n",
       "  'hidden_w_reg': 0.1,\n",
       "  'input_activation': 'sigmoid',\n",
       "  'input_drop_rate': 0.5,\n",
       "  'input_is_batch': True,\n",
       "  'input_num_units': 32,\n",
       "  'input_w_reg': 1e-10,\n",
       "  'learning_rate': 0.1,\n",
       "  'num_hidden_layers': 5,\n",
       "  'optimizer': 'adam',\n",
       "  'output_activation': 'softmax',\n",
       "  'output_drop_rate': 0.0,\n",
       "  'output_is_batch': True,\n",
       "  'output_num_units': 10,\n",
       "  'output_w_reg': 0.1},\n",
       " 0.08680000252127647)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = BayesOptimizer(score_func=score_func,\n",
    "                      params_conf=params_conf, is_display=True, timeout=None)\n",
    "opt.search(num_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesOptimizer' object has no attribute 'optimizert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-721638e7b34d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BayesOptimizer' object has no attribute 'optimizert'"
     ]
    }
   ],
   "source": [
    "opt.optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import GPy\n",
    "import GPyOpt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myf(x):\n",
    "    print(x)\n",
    "    return sum((2*x)**2)\n",
    "\n",
    "bounds = [{'name': 'var_1', 'type': 'continuous', 'domain': (-1,1)},\n",
    "         {'name': 'var_1', 'type': 'continuous', 'domain': (-1,1)}]\n",
    "\n",
    "# bounds = [{'name': 'var_1', 'type': 'continuous', 'domain': (-1,1)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.83472294 -0.35045541]]\n",
      "[[-0.81677674 -0.20893279]]\n",
      "[[0.56892437 0.98436479]]\n",
      "[[-0.70499574  0.15934302]]\n",
      "[[ 0.36236546 -0.37212878]]\n",
      "[[ 0.3276707 -0.3794702]]\n",
      "[[ 0.19993882 -0.76537162]]\n",
      "[[ 0.16673283 -0.17536047]]\n",
      "[[-2.46435936e-02 -7.75201312e-05]]\n",
      "[[-1.  1.]]\n",
      "[[0.05523789 0.08312356]]\n",
      "[[-0.0745971  0.0846349]]\n",
      "[[-0.13251386 -0.12509652]]\n",
      "[[-0.0692017   0.49375632]]\n",
      "[[-0.99652227 -0.99553451]]\n",
      "[[-0.28496292 -0.90985205]]\n",
      "[[0.12828897 0.05891816]]\n",
      "[[0.47730358 0.37926197]]\n",
      "[[-0.58558844 -0.02097188]]\n",
      "[[-0.67679943  0.899019  ]]\n"
     ]
    }
   ],
   "source": [
    "max_iter = 15\n",
    "opt = GPyOpt.methods.BayesianOptimization(myf,bounds)\n",
    "opt.run_optimization(max_iter, verbosity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.87769699e-01 -5.22068678e-01]\n",
      " [-2.60640122e-01 -5.92168000e-01]\n",
      " [ 3.62671315e-01  3.08434924e-01]\n",
      " [ 4.23333810e-01 -5.07602750e-01]\n",
      " [ 6.87402157e-01  2.10656733e-01]\n",
      " [ 3.12278334e-01  1.83631054e-01]\n",
      " [ 8.31197264e-04  5.77286352e-02]\n",
      " [-1.00000000e+00  9.75483572e-01]\n",
      " [ 6.73192012e-02 -9.58554176e-02]\n",
      " [-1.00000000e+00 -1.00000000e+00]\n",
      " [-6.75609333e-02 -3.06036996e-02]\n",
      " [ 1.39019074e-02 -7.44473136e-04]\n",
      " [-9.62346335e-01 -2.63916597e-02]\n",
      " [ 9.52792460e-01  9.90318356e-01]\n",
      " [ 3.20600327e-01 -3.70925950e-01]\n",
      " [ 8.19614846e-01 -5.49740227e-01]\n",
      " [ 1.98597971e-02 -4.48193390e-01]\n",
      " [ 8.05345803e-01  7.37027584e-01]\n",
      " [-4.62028321e-01  4.55104405e-01]\n",
      " [-7.58883852e-01  1.00326861e-02]]\n",
      "[ 0.01390191 -0.00074447]\n"
     ]
    }
   ],
   "source": [
    "print(opt.X)\n",
    "print(opt.x_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.Y - np.sum((2 * opt.X) ** 2, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.61410245e-01, 7.33240385e-02, 7.33240385e-02, 7.33240385e-02,\n",
       "       7.33240385e-02, 4.15628331e-04, 4.15628331e-04, 4.15628331e-04,\n",
       "       4.15628331e-04, 4.15628331e-04, 4.15628331e-04, 4.15628331e-04,\n",
       "       4.15628331e-04, 4.15628331e-04, 4.15628331e-04, 4.15628331e-04,\n",
       "       4.15628331e-04, 4.15628331e-04, 4.15628331e-04, 4.15628331e-04])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.Y_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "if [3]:\n",
    "    print(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get('scale', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3010299956639812"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log10(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hedgeable_ai.optimizer.tuner.variables.ContinuousVariable object at 0x7f513b731908>\n",
      "{'name': 'var1', 'type': 'continuous', 'domain': (-5, 5), 'dimensionality': 3}\n",
      "3\n",
      "<hedgeable_ai.optimizer.tuner.variables.DiscreteVariable object at 0x7f513b7477b8>\n",
      "{'name': 'var3', 'type': 'discrete', 'domain': (3, 8, 10), 'dimensionality': 2}\n",
      "2\n",
      "<hedgeable_ai.optimizer.tuner.variables.CategoricalVariable object at 0x7f513b747978>\n",
      "{'name': 'var4', 'type': 'categorical', 'domain': ('hey', 'what up', 'oops'), 'dimensionality': 1}\n",
      "1\n",
      "<hedgeable_ai.optimizer.tuner.variables.IntegerVariable object at 0x7f513b747b38>\n",
      "{'name': 'var5', 'type': 'integer', 'domain': (1, 10), 'scale': 'log'}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from hedgeable_ai.optimizer.tuner import RandomOptimizer\n",
    "\n",
    "\n",
    "mixed_domain =[{'name': 'var1', 'type': 'continuous', 'domain': (-5,5),'dimensionality': 3},\n",
    "               {'name': 'var3', 'type': 'discrete', 'domain': (3,8,10),'dimensionality': 2},\n",
    "               {'name': 'var4', 'type': 'categorical', 'domain': ('hey', 'what up', 'oops'),'dimensionality': 1},\n",
    "               {'name': 'var5', 'type': 'integer', 'domain': (1, 10), 'scale':'log'}]\n",
    "\n",
    "opt = RandomOptimizer(score_func=lambda x: x, params_conf=mixed_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 8, 3, 'hey', 10]\n"
     ]
    }
   ],
   "source": [
    "x = [0., 0., 0., 8., 1., 1., 0., 0., 1.]\n",
    "param = opt.vec2params(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1_1': 0.0,\n",
       " 'var1_2': 0.0,\n",
       " 'var1_3': 0.0,\n",
       " 'var3_1': 8,\n",
       " 'var3_2': 3,\n",
       " 'var4_1': 'hey',\n",
       " 'var5': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 8., 3., 1., 0., 0., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.params2vec(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.design_space.dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.design_space.model_dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
